{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHWfPGWKseWA"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAxXUW6useWB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import random\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Layer, Dense, Embedding, Dropout\n",
        "\n",
        "\n",
        "RANDOM_SEED = 1\n",
        "tf.random.set_seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b2ftui4seWC"
      },
      "outputs": [],
      "source": [
        "def text_normalize(text):\n",
        "    text = text.lower()\n",
        "    text = text.strip()\n",
        "    text = re.sub(r'[^\\w\\s\\n]', '', text)\n",
        "    text = text.replace('\\n\\n', '\\n')\n",
        "    text = '\\n'.join(['<start> ' + line + ' <end>' for line in text.split('\\n') if line != '' and len(line.split()) == 5])\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E82RYaMjseWC"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "MAX_SEQ_LEN = 7\n",
        "VOCAB_SIZE = 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X57QIbBqseWD"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = './data-set1.csv'\n",
        "\n",
        "df = pd.read_csv(DATASET_PATH, index_col=0)\n",
        "df['poem_content'] = df['poem_content'].apply(lambda p: text_normalize(p))\n",
        "# df['poem_content'] = df['poem_content'].astype(str).apply(lambda p: text_normalize(p))\n",
        "corpus = df['poem_content'].to_numpy()\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for idx, row in df.iterrows():\n",
        "    lines = row['poem_content'].split('\\n')\n",
        "    lines = [line for line in lines if line != '']\n",
        "    for idx in range(0, len(lines) - 1):\n",
        "        input_sentence = lines[idx]\n",
        "        output_sentence = lines[idx+1]\n",
        "\n",
        "        X.append(input_sentence)\n",
        "        y.append(output_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uw-sYENzseWD",
        "outputId": "ef5bafab-a4be-4f85-eb71-4eef191c88a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> hầu hết các đồ vật <end> => <start> ta muốn đều đắt tiền <end>\n",
            "Input: <start> ta muốn đều đắt tiền <end> => <start> một khi không có được <end>\n",
            "Input: <start> một khi không có được <end> => <start> ta cảm thấy buồn phiền <end>\n",
            "Input: <start> ta cảm thấy buồn phiền <end> => <start> trong khi cái thực sự <end>\n",
            "Input: <start> trong khi cái thực sự <end> => <start> làm ta vui ở đời <end>\n",
            "Input: <start> làm ta vui ở đời <end> => <start> hoàn toàn không tốn kém <end>\n",
            "Input: <start> hoàn toàn không tốn kém <end> => <start> là tình yêu tiếng cười <end>\n",
            "Input: <start> hiện tại anh đang sống <end> => <start> không được để phí hoài <end>\n",
            "Input: <start> không được để phí hoài <end> => <start> vì nỗi buồn quá khứ <end>\n",
            "Input: <start> vì nỗi buồn quá khứ <end> => <start> và sợ hãi tương lai <end>\n"
          ]
        }
      ],
      "source": [
        "for idx in range(len(X))[:10]:\n",
        "    print(f'Input: {X[idx]} => {y[idx]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcKouw9CseWD"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, filters='', oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcinSQ1oseWD"
      },
      "outputs": [],
      "source": [
        "def prepare_output_sequences(y_sequences):\n",
        "    y_inputs = pad_sequences([y_seq[:-1] for y_seq in y_sequences], maxlen=MAX_SEQ_LEN, truncating='pre', padding='post')\n",
        "    y_outputs = pad_sequences([y_seq[1:] for y_seq in y_sequences], maxlen=MAX_SEQ_LEN, truncating='pre', padding='post')\n",
        "\n",
        "    return y_inputs, y_outputs\n",
        "\n",
        "X_sequences = tokenizer.texts_to_sequences(X)\n",
        "X_padded_sequences = pad_sequences(X_sequences, maxlen=MAX_SEQ_LEN, truncating='pre', padding='post')\n",
        "\n",
        "y_sequences = tokenizer.texts_to_sequences(y)\n",
        "y_inputs, y_outputs = prepare_output_sequences(y_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjrUMTxDseWD"
      },
      "outputs": [],
      "source": [
        "n_samples = len(X_padded_sequences)\n",
        "train_len = int(n_samples * 0.7)\n",
        "val_len = int(n_samples * 0.2)\n",
        "test_len = n_samples - train_len - val_len\n",
        "\n",
        "# Shuffle\n",
        "np.random.seed(1)\n",
        "idxs = np.arange(n_samples)\n",
        "idxs = np.random.permutation(idxs)\n",
        "\n",
        "X_padded_sequences = X_padded_sequences[idxs]\n",
        "y_inputs = y_inputs[idxs]\n",
        "y_outputs = y_outputs[idxs]\n",
        "\n",
        "# Split the data into train, validation, and test sets\n",
        "X_train_seq, y_train_input, y_train_output = X_padded_sequences[:train_len], y_inputs[:train_len], y_outputs[:train_len]\n",
        "X_val_seq, y_val_input, y_val_output = X_padded_sequences[train_len:train_len+val_len], y_inputs[train_len:train_len+val_len], y_outputs[train_len:train_len+val_len]\n",
        "X_test_seq, y_test_input, y_test_output = X_padded_sequences[train_len+val_len:], y_inputs[train_len+val_len:], y_outputs[train_len+val_len:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nnu4fO1VseWE"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(((X_train_seq, y_train_input), y_train_output)).batch(BATCH_SIZE)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices(((X_val_seq, y_val_input), y_val_output)).batch(BATCH_SIZE)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(((X_test_seq, y_test_input), y_test_output)).batch(BATCH_SIZE)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RDnzBh3VseWE",
        "outputId": "7bfe6367-57b2-4113-d79a-534791f70eaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[135 646 180  62 270   4   0]\n",
            " [ 14 467   6 257 136   4   0]\n",
            " [117 990  34 156 418   4   0]\n",
            " [  5 317 712 150 713   4   0]\n",
            " [ 22  16  24  22  54   4   0]\n",
            " [102 101 384 294 550   4   0]\n",
            " [442  86 220 265 657   4   0]\n",
            " [281  28  92 477  41   4   0]\n",
            " [184 365 366 367 780   4   0]\n",
            " [ 32  10 105 384 602   4   0]\n",
            " [ 29 107  72  79  77   4   0]\n",
            " [253   9 186  34 226   4   0]\n",
            " [ 26 379  61 257  36   4   0]\n",
            " [ 15  66 150 218  62   4   0]\n",
            " [ 51  97  15  81 123   4   0]\n",
            " [ 51  97  15  81 123   4   0]\n",
            " [ 72 289 115 240 190   4   0]\n",
            " [414  12  51 838 839   4   0]\n",
            " [ 49  84  58  12  25   4   0]\n",
            " [ 52  76 222 474 475   4   0]\n",
            " [ 64  27 268 331  41   4   0]\n",
            " [763 362  17 225 224   4   0]\n",
            " [  8 249 167 668 669   4   0]\n",
            " [488 489 226  74  16   4   0]\n",
            " [429 323  42 248  30   4   0]\n",
            " [ 21 230  14 735 736   4   0]\n",
            " [  6 186 738 497  94   4   0]\n",
            " [ 37  80 157  59  57   4   0]\n",
            " [ 31  91  39 118  69   4   0]\n",
            " [ 23  45  17 196 305   4   0]\n",
            " [ 67 119 342 327 654   4   0]\n",
            " [ 24 375 376 519 520   4   0]], shape=(32, 7), dtype=int32)\n",
            "(<tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3,  19,  28,  92,  76, 213,   4],\n",
            "       [  3, 354,  14,  23, 223, 466,   4],\n",
            "       [  3,  24, 793,  79, 497, 370,   4],\n",
            "       [  3, 358,  14, 162, 156, 711,   4],\n",
            "       [  3, 122,  73, 680, 299, 681,   4],\n",
            "       [  3,  73, 101,  83,  43, 193,   4],\n",
            "       [  3,  19, 219, 330, 217, 174,   4],\n",
            "       [  3, 476,  12,  55,  93,  80,   4],\n",
            "       [  3, 184, 365, 366, 367, 278,   4],\n",
            "       [  3,  32,  10, 601, 316,  74,   4],\n",
            "       [  3,   7,  13,  36, 103,  42,   4],\n",
            "       [  3,  44, 185,  50, 203, 469,   4],\n",
            "       [  3,  28, 131,  96, 410, 411,   4],\n",
            "       [  3, 125, 636, 151, 637, 173,   4],\n",
            "       [  3,   5,  26, 444, 170, 274,   4],\n",
            "       [  3,   5,  26, 444, 170, 274,   4],\n",
            "       [  3,  34, 113, 189, 533, 163,   4],\n",
            "       [  3, 406,  57,  50, 836, 837,   4],\n",
            "       [  3,  51,  97,  15,  81, 123,   4],\n",
            "       [  3,  12,  55,   8,   5, 233,   4],\n",
            "       [  3,  19, 106,  78,  93, 628,   4],\n",
            "       [  3, 761, 762, 503, 197, 504,   4],\n",
            "       [  3, 273, 667, 425,  22,  65,   4],\n",
            "       [  3, 273,  61, 155, 228, 487,   4],\n",
            "       [  3, 128, 146,  30, 262, 322,   4],\n",
            "       [  3,  53,  37, 422,  63,  48,   4],\n",
            "       [  3, 280, 252, 737, 336,  32,   4],\n",
            "       [  3, 771, 363,  48,  78,  84,   4],\n",
            "       [  3,  71,  37,   7,  16, 256,   4],\n",
            "       [  3, 279, 144, 164, 179, 506,   4],\n",
            "       [  3, 260, 653,  62,  28,  92,   4],\n",
            "       [  3,  29, 127,  43, 235, 518,   4]], dtype=int32)>, <tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 135, 646, 180,  62, 270,   0],\n",
            "       [  3,  14, 467,   6, 257, 136,   0],\n",
            "       [  3, 117, 990,  34, 156, 418,   0],\n",
            "       [  3,   5, 317, 712, 150, 713,   0],\n",
            "       [  3,  22,  16,  24,  22,  54,   0],\n",
            "       [  3, 102, 101, 384, 294, 550,   0],\n",
            "       [  3, 442,  86, 220, 265, 657,   0],\n",
            "       [  3, 281,  28,  92, 477,  41,   0],\n",
            "       [  3, 184, 365, 366, 367, 780,   0],\n",
            "       [  3,  32,  10, 105, 384, 602,   0],\n",
            "       [  3,  29, 107,  72,  79,  77,   0],\n",
            "       [  3, 253,   9, 186,  34, 226,   0],\n",
            "       [  3,  26, 379,  61, 257,  36,   0],\n",
            "       [  3,  15,  66, 150, 218,  62,   0],\n",
            "       [  3,  51,  97,  15,  81, 123,   0],\n",
            "       [  3,  51,  97,  15,  81, 123,   0],\n",
            "       [  3,  72, 289, 115, 240, 190,   0],\n",
            "       [  3, 414,  12,  51, 838, 839,   0],\n",
            "       [  3,  49,  84,  58,  12,  25,   0],\n",
            "       [  3,  52,  76, 222, 474, 475,   0],\n",
            "       [  3,  64,  27, 268, 331,  41,   0],\n",
            "       [  3, 763, 362,  17, 225, 224,   0],\n",
            "       [  3,   8, 249, 167, 668, 669,   0],\n",
            "       [  3, 488, 489, 226,  74,  16,   0],\n",
            "       [  3, 429, 323,  42, 248,  30,   0],\n",
            "       [  3,  21, 230,  14, 735, 736,   0],\n",
            "       [  3,   6, 186, 738, 497,  94,   0],\n",
            "       [  3,  37,  80, 157,  59,  57,   0],\n",
            "       [  3,  31,  91,  39, 118,  69,   0],\n",
            "       [  3,  23,  45,  17, 196, 305,   0],\n",
            "       [  3,  67, 119, 342, 327, 654,   0],\n",
            "       [  3,  24, 375, 376, 519, 520,   0]], dtype=int32)>)\n",
            "tf.Tensor(\n",
            "[[ 45   5  56 572 166   4   0]\n",
            " [  5  71 880  14 171   4   0]\n",
            " [ 15 196 634 218  62   4   0]\n",
            " [ 43 149  10 146 325   4   0]\n",
            " [ 19 106  78  28 215   4   0]\n",
            " [230 746  20 747 748   4   0]\n",
            " [ 40  41  89 437  72   4   0]\n",
            " [398  23  65 193 147   4   0]\n",
            " [629 630 631 311 326   4   0]\n",
            " [199  37 256 129  95   4   0]\n",
            " [164  39  17 159 298   4   0]\n",
            " [ 90 714  90 348 207   4   0]\n",
            " [504 987 359 139 789   4   0]\n",
            " [260 419 102 644 198   4   0]\n",
            " [ 29 127  43 235 518   4   0]\n",
            " [  9 188 232 512  81   4   0]\n",
            " [148  34  11 129  95   4   0]\n",
            " [109 157 981 982 603   4   0]\n",
            " [611 419 405 177 172   4   0]\n",
            " [587 311 200  73 588   4   0]\n",
            " [122  73 680 299 681   4   0]\n",
            " [  7  32  73 360 107   4   0]\n",
            " [358  59  68 216 281   4   0]\n",
            " [ 19 214  86 220 345   4   0]\n",
            " [442  14   6 983 984   4   0]\n",
            " [ 19 140  86 220 345   4   0]\n",
            " [ 22 507 230 784  98   4   0]\n",
            " [236 576   8 198 199   4   0]\n",
            " [ 79 767   6   5 768   4   0]\n",
            " [ 44 185  50 203 469   4   0]\n",
            " [ 15   9 308 309  81   4   0]\n",
            " [ 33  38  60 684 685   4   0]], shape=(32, 7), dtype=int32)\n",
            "(<tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3,  60,  56, 571, 248, 307,   4],\n",
            "       [  3, 398,  23,  65, 193, 147,   4],\n",
            "       [  3, 218, 632, 407, 633,  61,   4],\n",
            "       [  3, 324,   6, 211, 164,   9,   4],\n",
            "       [  3, 214, 622, 623, 439, 624,   4],\n",
            "       [  3, 139, 110, 744,  82, 745,   4],\n",
            "       [  3,  73, 160, 232, 243, 244,   4],\n",
            "       [  3,  17, 404,  83,  11, 879,   4],\n",
            "       [  3,  64,  27, 268, 331,  41,   4],\n",
            "       [  3,  48, 734,  95, 109, 157,   4],\n",
            "       [  3, 564, 134,  11,  30,   9,   4],\n",
            "       [  3,   5, 317, 712, 150, 713,   4],\n",
            "       [  3, 369, 369, 342,  94, 160,   4],\n",
            "       [  3, 337, 338,  28, 215, 107,   4],\n",
            "       [  3,   5,  42, 112, 517, 374,   4],\n",
            "       [  3, 510, 158,  70, 511, 231,   4],\n",
            "       [  3,   7, 720, 495,  21,  37,   4],\n",
            "       [  3,  37, 980, 356, 118,  27,   4],\n",
            "       [  3,  25, 144, 417, 418, 609,   4],\n",
            "       [  3,  62,  30, 168,  12, 586,   4],\n",
            "       [  3, 677, 678, 300,  30, 679,   4],\n",
            "       [  3, 723, 409, 357, 724, 725,   4],\n",
            "       [  3,  98, 172,  31, 360,  74,   4],\n",
            "       [  3, 119, 665, 108,  78, 319,   4],\n",
            "       [  3, 109, 157, 981, 982, 603,   4],\n",
            "       [  3,  15, 211, 666,  58,  94,   4],\n",
            "       [  3, 914, 284, 915, 916, 917,   4],\n",
            "       [  3, 197, 198,  45, 574, 575,   4],\n",
            "       [  3,  36,  75, 129,  95,  77,   4],\n",
            "       [  3,  80, 468, 355, 168, 208,   4],\n",
            "       [  3,   5, 135, 308, 309,  65,   4],\n",
            "       [  3,   8, 276, 682, 683, 154,   4]], dtype=int32)>, <tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3,  45,   5,  56, 572, 166,   0],\n",
            "       [  3,   5,  71, 880,  14, 171,   0],\n",
            "       [  3,  15, 196, 634, 218,  62,   0],\n",
            "       [  3,  43, 149,  10, 146, 325,   0],\n",
            "       [  3,  19, 106,  78,  28, 215,   0],\n",
            "       [  3, 230, 746,  20, 747, 748,   0],\n",
            "       [  3,  40,  41,  89, 437,  72,   0],\n",
            "       [  3, 398,  23,  65, 193, 147,   0],\n",
            "       [  3, 629, 630, 631, 311, 326,   0],\n",
            "       [  3, 199,  37, 256, 129,  95,   0],\n",
            "       [  3, 164,  39,  17, 159, 298,   0],\n",
            "       [  3,  90, 714,  90, 348, 207,   0],\n",
            "       [  3, 504, 987, 359, 139, 789,   0],\n",
            "       [  3, 260, 419, 102, 644, 198,   0],\n",
            "       [  3,  29, 127,  43, 235, 518,   0],\n",
            "       [  3,   9, 188, 232, 512,  81,   0],\n",
            "       [  3, 148,  34,  11, 129,  95,   0],\n",
            "       [  3, 109, 157, 981, 982, 603,   0],\n",
            "       [  3, 611, 419, 405, 177, 172,   0],\n",
            "       [  3, 587, 311, 200,  73, 588,   0],\n",
            "       [  3, 122,  73, 680, 299, 681,   0],\n",
            "       [  3,   7,  32,  73, 360, 107,   0],\n",
            "       [  3, 358,  59,  68, 216, 281,   0],\n",
            "       [  3,  19, 214,  86, 220, 345,   0],\n",
            "       [  3, 442,  14,   6, 983, 984,   0],\n",
            "       [  3,  19, 140,  86, 220, 345,   0],\n",
            "       [  3,  22, 507, 230, 784,  98,   0],\n",
            "       [  3, 236, 576,   8, 198, 199,   0],\n",
            "       [  3,  79, 767,   6,   5, 768,   0],\n",
            "       [  3,  44, 185,  50, 203, 469,   0],\n",
            "       [  3,  15,   9, 308, 309,  81,   0],\n",
            "       [  3,  33,  38,  60, 684, 685,   0]], dtype=int32)>)\n",
            "tf.Tensor(\n",
            "[[116  57 117  85 191   4   0]\n",
            " [529 530  59 531 379   4   0]\n",
            " [135 646 180  62 270   4   0]\n",
            " [128 180 250 904 905   4   0]\n",
            " [118 289  47 709 710   4   0]\n",
            " [  8 695 448 149   6   4   0]\n",
            " [130  50 544  27  49   4   0]\n",
            " [167   5  56 391 297   4   0]\n",
            " [ 11  10 160 233 372   4   0]\n",
            " [ 11  49  55 121 279   4   0]\n",
            " [ 52  76 222 474 475   4   0]\n",
            " [ 11  13  55 453 234   4   0]\n",
            " [158  98  25 536 537   4   0]\n",
            " [184 365 366 367 278   4   0]\n",
            " [ 66 139 312 312  34   4   0]\n",
            " [ 80 468 355 168 208   4   0]\n",
            " [ 35 166 370 988 989   4   0]\n",
            " [ 21   9 111  56  23   4   0]\n",
            " [ 89   7 438  22   6   4   0]\n",
            " [498  21 502 952 953   4   0]\n",
            " [121 594 202  35  18   4   0]\n",
            " [101 242  65 553  33   4   0]\n",
            " [ 73 160 232 243 244   4   0]\n",
            " [ 43 149  10 146 325   4   0]\n",
            " [ 71 182 927 270 124   4   0]\n",
            " [271 204 343 364 344   4   0]\n",
            " [498 140  20 739 740   4   0]\n",
            " [145   5 445  50 310   4   0]\n",
            " [568 569 247   6 118   4   0]\n",
            " [715  64 716 717 494   4   0]\n",
            " [950 787 176 792 507   4   0]\n",
            " [139 110 744  82 745   4   0]], shape=(32, 7), dtype=int32)\n",
            "(<tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3,  72, 289, 115, 240, 190,   4],\n",
            "       [  3,  23,  58,  14, 162, 378,   4],\n",
            "       [  3,  19,  28,  92,  76, 213,   4],\n",
            "       [  3,  37, 781, 116, 217,  20,   4],\n",
            "       [  3, 708, 414, 357, 493, 229,   4],\n",
            "       [  3, 403,  45,   5,   7, 346,   4],\n",
            "       [  3, 381,  13,  64, 129, 543,   4],\n",
            "       [  3,  60, 196, 573,  38,  63,   4],\n",
            "       [  3,   9, 371,  71,  43, 159,   4],\n",
            "       [  3,  11,  13,  55, 453, 234,   4],\n",
            "       [  3,  12,  55,   8,   5, 233,   4],\n",
            "       [  3,  12,  55, 451, 452, 278,   4],\n",
            "       [  3,  51,  97,  58,  51,  97,   4],\n",
            "       [  3, 358,  59,  68, 216, 281,   4],\n",
            "       [  3, 589, 590, 138, 591, 104,   4],\n",
            "       [  3,  14, 467,   6, 257, 136,   4],\n",
            "       [  3, 126, 197, 259,  69, 505,   4],\n",
            "       [  3,  11,  10, 160, 233, 372,   4],\n",
            "       [  3,   5,  91,  40,   7,  41,   4],\n",
            "       [  3, 501, 126,  31, 364, 951,   4],\n",
            "       [  3, 169, 593, 121, 202, 253,   4],\n",
            "       [  3, 131,  24, 243, 244,  86,   4],\n",
            "       [  3,  41,   8,  52,  16, 436,   4],\n",
            "       [  3, 324,   6, 211, 164,   9,   4],\n",
            "       [  3, 263, 787, 926, 266, 168,   4],\n",
            "       [  3,  76,  98,  12, 770,  67,   4],\n",
            "       [  3,   6, 186, 738, 497,  94,   4],\n",
            "       [  3,  33,  38,  60, 684, 685,   4],\n",
            "       [  3,  60, 103, 566, 304, 567,   4],\n",
            "       [  3,  90, 714,  90, 348, 207,   4],\n",
            "       [  3,  75, 782,  34, 948, 949,   4],\n",
            "       [  3, 741, 742,  17,  74, 743,   4]], dtype=int32)>, <tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 116,  57, 117,  85, 191,   0],\n",
            "       [  3, 529, 530,  59, 531, 379,   0],\n",
            "       [  3, 135, 646, 180,  62, 270,   0],\n",
            "       [  3, 128, 180, 250, 904, 905,   0],\n",
            "       [  3, 118, 289,  47, 709, 710,   0],\n",
            "       [  3,   8, 695, 448, 149,   6,   0],\n",
            "       [  3, 130,  50, 544,  27,  49,   0],\n",
            "       [  3, 167,   5,  56, 391, 297,   0],\n",
            "       [  3,  11,  10, 160, 233, 372,   0],\n",
            "       [  3,  11,  49,  55, 121, 279,   0],\n",
            "       [  3,  52,  76, 222, 474, 475,   0],\n",
            "       [  3,  11,  13,  55, 453, 234,   0],\n",
            "       [  3, 158,  98,  25, 536, 537,   0],\n",
            "       [  3, 184, 365, 366, 367, 278,   0],\n",
            "       [  3,  66, 139, 312, 312,  34,   0],\n",
            "       [  3,  80, 468, 355, 168, 208,   0],\n",
            "       [  3,  35, 166, 370, 988, 989,   0],\n",
            "       [  3,  21,   9, 111,  56,  23,   0],\n",
            "       [  3,  89,   7, 438,  22,   6,   0],\n",
            "       [  3, 498,  21, 502, 952, 953,   0],\n",
            "       [  3, 121, 594, 202,  35,  18,   0],\n",
            "       [  3, 101, 242,  65, 553,  33,   0],\n",
            "       [  3,  73, 160, 232, 243, 244,   0],\n",
            "       [  3,  43, 149,  10, 146, 325,   0],\n",
            "       [  3,  71, 182, 927, 270, 124,   0],\n",
            "       [  3, 271, 204, 343, 364, 344,   0],\n",
            "       [  3, 498, 140,  20, 739, 740,   0],\n",
            "       [  3, 145,   5, 445,  50, 310,   0],\n",
            "       [  3, 568, 569, 247,   6, 118,   0],\n",
            "       [  3, 715,  64, 716, 717, 494,   0],\n",
            "       [  3, 950, 787, 176, 792, 507,   0],\n",
            "       [  3, 139, 110, 744,  82, 745,   0]], dtype=int32)>)\n",
            "tf.Tensor(\n",
            "[[153  39 153 884 885   4   0]\n",
            " [335 219  30 639 152   4   0]\n",
            " [ 76  98  12 770  67   4   0]\n",
            " [ 40  17   6 695 448   4   0]\n",
            " [  6 186 738 497  94   4   0]\n",
            " [463 464 239  27 465   4   0]\n",
            " [279 144 164 179 506   4   0]\n",
            " [ 81 123 182  31  42   4   0]\n",
            " [771 363  48  78  84   4   0]\n",
            " [813  88 814 123 815   4   0]\n",
            " [  7  13  36 103  42   4   0]\n",
            " [188 577 392 199 578   4   0]\n",
            " [ 44 458 459 223  69   4   0]\n",
            " [368 125 158 276 154   4   0]\n",
            " [ 48 734  95 109 157   4   0]\n",
            " [  5 412 192 413 835   4   0]\n",
            " [ 11  10 160 233 372   4   0]\n",
            " [202 127  43 596 597   4   0]\n",
            " [442  86 220 265 657   4   0]\n",
            " [218 632 407 633  61   4   0]\n",
            " [  8 265 266  22  23   4   0]\n",
            " [585 394 301 120 252   4   0]\n",
            " [133  21 449  39 194   4   0]\n",
            " [337 338  28 215 107   4   0]\n",
            " [ 40 221  68  46 142   4   0]\n",
            " [158  98  25 536 537   4   0]\n",
            " [324   6 211 164   9   4   0]\n",
            " [ 10 245  21 932 126   4   0]\n",
            " [ 60 249  21 165  25   4   0]\n",
            " [214 134 625 626  27   4   0]\n",
            " [383  52 424 862 320   4   0]\n",
            " [957  27 183  94 160   4   0]], shape=(32, 7), dtype=int32)\n",
            "(<tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 882, 883,  54, 194, 395,   4],\n",
            "       [  3,  19, 108, 102,  51, 334,   4],\n",
            "       [  3,  14, 139,  50,   5, 184,   4],\n",
            "       [  3,   8, 695, 448, 149,   6,   4],\n",
            "       [  3, 280, 252, 737, 336,  32,   4],\n",
            "       [  3, 225, 353,  35, 152, 462,   4],\n",
            "       [  3,  33,  45,  29, 145, 176,   4],\n",
            "       [  3, 161, 672, 673, 179, 152,   4],\n",
            "       [  3, 271, 204, 343, 364, 344,   4],\n",
            "       [  3, 811, 166, 247, 812, 256,   4],\n",
            "       [  3, 463, 464, 239,  27, 465,   4],\n",
            "       [  3,  15,   9, 308, 309,  81,   4],\n",
            "       [  3, 110,  49, 185,  44,  77,   4],\n",
            "       [  3, 945, 946,  80, 263, 947,   4],\n",
            "       [  3,  31,  91,  39, 118,  69,   4],\n",
            "       [  3, 175,  10, 176, 296,  64,   4],\n",
            "       [  3,   9, 371,  71,  43, 159,   4],\n",
            "       [  3,  53,  87,  66, 201, 595,   4],\n",
            "       [  3,  19, 219, 330, 217, 174,   4],\n",
            "       [  3,  19, 259,  93, 329,  62,   4],\n",
            "       [  3,   7,  91,   5,   7,  41,   4],\n",
            "       [  3, 583, 584,  61,  53, 304,   4],\n",
            "       [  3,   8,   5,  22, 106,  81,   4],\n",
            "       [  3, 440, 643,  79, 173, 134,   4],\n",
            "       [  3, 686, 687, 180, 250, 447,   4],\n",
            "       [  3,  51,  97,  58,  51,  97,   4],\n",
            "       [  3,   9,  43,  10,  75,  71,   4],\n",
            "       [  3, 210, 788,  35,  18,  20,   4],\n",
            "       [  3, 167,   5,  56, 391, 297,   4],\n",
            "       [  3,  19, 106,  78,  28, 215,   4],\n",
            "       [  3, 169, 387,  28, 613, 861,   4],\n",
            "       [  3, 153, 284,  79, 109, 956,   4]], dtype=int32)>, <tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 153,  39, 153, 884, 885,   0],\n",
            "       [  3, 335, 219,  30, 639, 152,   0],\n",
            "       [  3,  76,  98,  12, 770,  67,   0],\n",
            "       [  3,  40,  17,   6, 695, 448,   0],\n",
            "       [  3,   6, 186, 738, 497,  94,   0],\n",
            "       [  3, 463, 464, 239,  27, 465,   0],\n",
            "       [  3, 279, 144, 164, 179, 506,   0],\n",
            "       [  3,  81, 123, 182,  31,  42,   0],\n",
            "       [  3, 771, 363,  48,  78,  84,   0],\n",
            "       [  3, 813,  88, 814, 123, 815,   0],\n",
            "       [  3,   7,  13,  36, 103,  42,   0],\n",
            "       [  3, 188, 577, 392, 199, 578,   0],\n",
            "       [  3,  44, 458, 459, 223,  69,   0],\n",
            "       [  3, 368, 125, 158, 276, 154,   0],\n",
            "       [  3,  48, 734,  95, 109, 157,   0],\n",
            "       [  3,   5, 412, 192, 413, 835,   0],\n",
            "       [  3,  11,  10, 160, 233, 372,   0],\n",
            "       [  3, 202, 127,  43, 596, 597,   0],\n",
            "       [  3, 442,  86, 220, 265, 657,   0],\n",
            "       [  3, 218, 632, 407, 633,  61,   0],\n",
            "       [  3,   8, 265, 266,  22,  23,   0],\n",
            "       [  3, 585, 394, 301, 120, 252,   0],\n",
            "       [  3, 133,  21, 449,  39, 194,   0],\n",
            "       [  3, 337, 338,  28, 215, 107,   0],\n",
            "       [  3,  40, 221,  68,  46, 142,   0],\n",
            "       [  3, 158,  98,  25, 536, 537,   0],\n",
            "       [  3, 324,   6, 211, 164,   9,   0],\n",
            "       [  3,  10, 245,  21, 932, 126,   0],\n",
            "       [  3,  60, 249,  21, 165,  25,   0],\n",
            "       [  3, 214, 134, 625, 626,  27,   0],\n",
            "       [  3, 383,  52, 424, 862, 320,   0],\n",
            "       [  3, 957,  27, 183,  94, 160,   0]], dtype=int32)>)\n",
            "tf.Tensor(\n",
            "[[619 328 108 290 620   4   0]\n",
            " [175  67  24 175 446   4   0]\n",
            " [ 53 661 180 124 341   4   0]\n",
            " [ 68 642 151 336 178   4   0]\n",
            " [ 60  56 571 248 307   4   0]\n",
            " [ 90 403  45 603  28   4   0]\n",
            " [ 71  37   7  16 256   4   0]\n",
            " [ 73 101  83  43 193   4   0]\n",
            " [358  14 162 156 711   4   0]\n",
            " [ 82 701 702 703 222   4   0]\n",
            " [194 295 387 388 558   4   0]\n",
            " [118  12 721 722 178   4   0]\n",
            " [729  12 730 270 124   4   0]\n",
            " [ 48   9  26 769 147   4   0]\n",
            " [ 23   5  22 291 542   4   0]\n",
            " [358  59  68 216 281   4   0]\n",
            " [153 272 340 660 443   4   0]\n",
            " [  9 188 232 512  81   4   0]\n",
            " [  8 670 671 112 291   4   0]\n",
            " [ 18 314 285  18 201   4   0]\n",
            " [171 317 347 254 494   4   0]\n",
            " [ 62  30 168  12 586   4   0]\n",
            " [ 67 119 330 217 174   4   0]\n",
            " [ 96 177   8  68  46   4   0]\n",
            " [133   6   9 148  59   4   0]\n",
            " [ 44 185  50 203 469   4   0]\n",
            " [254 313  13  25  36   4   0]\n",
            " [145   5 445  50 310   4   0]\n",
            " [ 40  29 229  29 229   4   0]\n",
            " [  6  45  85 823 257   4   0]\n",
            " [ 40  41  89 437  72   4   0]\n",
            " [  5 674 104 675  31   4   0]], shape=(32, 7), dtype=int32)\n",
            "(<tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3,  19,  28,  92, 327, 213,   4],\n",
            "       [  3,  15,  27,  47, 348, 337,   4],\n",
            "       [  3, 153, 272, 340, 660, 443,   4],\n",
            "       [  3, 102, 640, 206, 641, 264,   4],\n",
            "       [  3, 306,   5,  56, 195, 570,   4],\n",
            "       [  3, 141,   6, 402, 205, 142,   4],\n",
            "       [  3,  17, 361, 123, 361,  88,   4],\n",
            "       [  3,  12, 101,  83, 549, 293,   4],\n",
            "       [  3, 118, 289,  47, 709, 710,   4],\n",
            "       [  3, 410, 698, 153, 699, 700,   4],\n",
            "       [  3,  24,  34, 555, 556, 557,   4],\n",
            "       [  3, 148,  34,  11, 129,  95,   4],\n",
            "       [  3, 175, 727,  27, 728,  69,   4],\n",
            "       [  3,  40,  29, 229,  29, 229,   4],\n",
            "       [  3, 237,  25, 117,  85, 191,   4],\n",
            "       [  3,  98, 172,  31, 360,  74,   4],\n",
            "       [  3, 272, 181,  10, 658, 659,   4],\n",
            "       [  3, 510, 158,  70, 511, 231,   4],\n",
            "       [  3,  40,  26, 167, 149,  76,   4],\n",
            "       [  3, 121, 594, 202,  35,  18,   4],\n",
            "       [  3, 117, 990,  34, 156, 418,   4],\n",
            "       [  3, 585, 394, 301, 120, 252,   4],\n",
            "       [  3, 627, 216,  93, 329, 124,   4],\n",
            "       [  3, 175,  67,  24, 175, 446,   4],\n",
            "       [  3, 263,  30,  24, 430, 264,   4],\n",
            "       [  3,  80, 468, 355, 168, 208,   4],\n",
            "       [  3, 103,  14, 171, 172,  31,   4],\n",
            "       [  3,  33,  38,  60, 684, 685,   4],\n",
            "       [  3,  79, 767,   6,   5, 768,   4],\n",
            "       [  3, 821, 174, 822, 314,  56,   4],\n",
            "       [  3,  73, 160, 232, 243, 244,   4],\n",
            "       [  3, 100, 315,  24,  93, 183,   4]], dtype=int32)>, <tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 619, 328, 108, 290, 620,   0],\n",
            "       [  3, 175,  67,  24, 175, 446,   0],\n",
            "       [  3,  53, 661, 180, 124, 341,   0],\n",
            "       [  3,  68, 642, 151, 336, 178,   0],\n",
            "       [  3,  60,  56, 571, 248, 307,   0],\n",
            "       [  3,  90, 403,  45, 603,  28,   0],\n",
            "       [  3,  71,  37,   7,  16, 256,   0],\n",
            "       [  3,  73, 101,  83,  43, 193,   0],\n",
            "       [  3, 358,  14, 162, 156, 711,   0],\n",
            "       [  3,  82, 701, 702, 703, 222,   0],\n",
            "       [  3, 194, 295, 387, 388, 558,   0],\n",
            "       [  3, 118,  12, 721, 722, 178,   0],\n",
            "       [  3, 729,  12, 730, 270, 124,   0],\n",
            "       [  3,  48,   9,  26, 769, 147,   0],\n",
            "       [  3,  23,   5,  22, 291, 542,   0],\n",
            "       [  3, 358,  59,  68, 216, 281,   0],\n",
            "       [  3, 153, 272, 340, 660, 443,   0],\n",
            "       [  3,   9, 188, 232, 512,  81,   0],\n",
            "       [  3,   8, 670, 671, 112, 291,   0],\n",
            "       [  3,  18, 314, 285,  18, 201,   0],\n",
            "       [  3, 171, 317, 347, 254, 494,   0],\n",
            "       [  3,  62,  30, 168,  12, 586,   0],\n",
            "       [  3,  67, 119, 330, 217, 174,   0],\n",
            "       [  3,  96, 177,   8,  68,  46,   0],\n",
            "       [  3, 133,   6,   9, 148,  59,   0],\n",
            "       [  3,  44, 185,  50, 203, 469,   0],\n",
            "       [  3, 254, 313,  13,  25,  36,   0],\n",
            "       [  3, 145,   5, 445,  50, 310,   0],\n",
            "       [  3,  40,  29, 229,  29, 229,   0],\n",
            "       [  3,   6,  45,  85, 823, 257,   0],\n",
            "       [  3,  40,  41,  89, 437,  72,   0],\n",
            "       [  3,   5, 674, 104, 675,  31,   0]], dtype=int32)>)\n",
            "tf.Tensor(\n",
            "[[126 178 316 496  20   4   0]\n",
            " [526 527  14 528  27   4   0]\n",
            " [ 44 185  50 203 469   4   0]\n",
            " [169 387  28 613 861   4   0]\n",
            " [110  49 185  44  77   4   0]\n",
            " [  7  32  73 360 107   4   0]\n",
            " [128 114  96 288 239   4   0]\n",
            " [ 70 245 389  11 298   4   0]\n",
            " [131 383  52  15 132   4   0]\n",
            " [ 24 793  79 497 370   4   0]\n",
            " [ 36  75 129  95  77   4   0]\n",
            " [754 156  21 338 755   4   0]\n",
            " [ 19  28  92 327 213   4   0]\n",
            " [ 19 106  78 332 635   4   0]\n",
            " [ 29 428 111  77   5   4   0]\n",
            " [ 15  17   6 305 165   4   0]\n",
            " [ 32  11  17 190 431   4   0]\n",
            " [  5 141 810  22 390   4   0]\n",
            " [ 81 123 182  31  42   4   0]\n",
            " [339 151 174 212 143   4   0]\n",
            " [ 14 162 107 318 807   4   0]\n",
            " [908 408 909 411 910   4   0]\n",
            " [ 24  34 555 556 557   4   0]\n",
            " [ 52  76 222 474 475   4   0]\n",
            " [432   5 135 148  59   4   0]\n",
            " [589 590 138 591 104   4   0]\n",
            " [397  87  35 100 315   4   0]\n",
            " [ 12  25 107 235  50   4   0]\n",
            " [763 362  17 225 224   4   0]\n",
            " [ 36  70  13 114 351   4   0]\n",
            " [197 198  45 574 575   4   0]\n",
            " [  6 855 260 261 856   4   0]], shape=(32, 7), dtype=int32)\n",
            "(<tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3,  21, 230,  14, 735, 736,   4],\n",
            "       [  3, 112, 523,  50, 524, 525,   4],\n",
            "       [  3,  80, 468, 355, 168, 208,   4],\n",
            "       [  3,   6,   9, 204, 860, 423,   4],\n",
            "       [  3,  36,  70,  13, 114, 277,   4],\n",
            "       [  3, 723, 409, 357, 724, 725,   4],\n",
            "       [  3, 237, 238,  26, 287, 522,   4],\n",
            "       [  3, 194, 295,  21, 560, 561,   4],\n",
            "       [  3,  10, 546, 547, 548, 100,   4],\n",
            "       [  3,  35, 166, 370, 988, 989,   4],\n",
            "       [  3,  63, 363,  48, 765, 766,   4],\n",
            "       [  3, 749, 750, 751, 752, 753,   4],\n",
            "       [  3,  15,  66, 618, 326, 267,   4],\n",
            "       [  3, 423, 121, 400, 302, 303,   4],\n",
            "       [  3, 427,   7, 192,  75, 147,   4],\n",
            "       [  3, 568, 569, 247,   6, 118,   4],\n",
            "       [  3, 133,   6,   9, 148,  59,   4],\n",
            "       [  3, 141,  75,  21, 809, 173,   4],\n",
            "       [  3, 161, 672, 673, 179, 152,   4],\n",
            "       [  3,  19, 140,  86, 220, 345,   4],\n",
            "       [  3,  12,  25, 107, 235,  50,   4],\n",
            "       [  3,   6, 105, 782, 907,  34,   4],\n",
            "       [  3,  10, 386,  44, 159, 554,   4],\n",
            "       [  3,  12,  55,   8,   5, 233,   4],\n",
            "       [  3,  32,  11,  17, 190, 431,   4],\n",
            "       [  3, 587, 311, 200,  73, 588,   4],\n",
            "       [  3, 170,  10,  13,  39,  98,   4],\n",
            "       [  3,  12,  23,   6, 235, 806,   4],\n",
            "       [  3, 761, 762, 503, 197, 504,   4],\n",
            "       [  3,  80, 456, 457,  31, 350,   4],\n",
            "       [  3,  60, 249,  21, 165,  25,   4],\n",
            "       [  3, 145,  90, 420,  43, 598,   4]], dtype=int32)>, <tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 126, 178, 316, 496,  20,   0],\n",
            "       [  3, 526, 527,  14, 528,  27,   0],\n",
            "       [  3,  44, 185,  50, 203, 469,   0],\n",
            "       [  3, 169, 387,  28, 613, 861,   0],\n",
            "       [  3, 110,  49, 185,  44,  77,   0],\n",
            "       [  3,   7,  32,  73, 360, 107,   0],\n",
            "       [  3, 128, 114,  96, 288, 239,   0],\n",
            "       [  3,  70, 245, 389,  11, 298,   0],\n",
            "       [  3, 131, 383,  52,  15, 132,   0],\n",
            "       [  3,  24, 793,  79, 497, 370,   0],\n",
            "       [  3,  36,  75, 129,  95,  77,   0],\n",
            "       [  3, 754, 156,  21, 338, 755,   0],\n",
            "       [  3,  19,  28,  92, 327, 213,   0],\n",
            "       [  3,  19, 106,  78, 332, 635,   0],\n",
            "       [  3,  29, 428, 111,  77,   5,   0],\n",
            "       [  3,  15,  17,   6, 305, 165,   0],\n",
            "       [  3,  32,  11,  17, 190, 431,   0],\n",
            "       [  3,   5, 141, 810,  22, 390,   0],\n",
            "       [  3,  81, 123, 182,  31,  42,   0],\n",
            "       [  3, 339, 151, 174, 212, 143,   0],\n",
            "       [  3,  14, 162, 107, 318, 807,   0],\n",
            "       [  3, 908, 408, 909, 411, 910,   0],\n",
            "       [  3,  24,  34, 555, 556, 557,   0],\n",
            "       [  3,  52,  76, 222, 474, 475,   0],\n",
            "       [  3, 432,   5, 135, 148,  59,   0],\n",
            "       [  3, 589, 590, 138, 591, 104,   0],\n",
            "       [  3, 397,  87,  35, 100, 315,   0],\n",
            "       [  3,  12,  25, 107, 235,  50,   0],\n",
            "       [  3, 763, 362,  17, 225, 224,   0],\n",
            "       [  3,  36,  70,  13, 114, 351,   0],\n",
            "       [  3, 197, 198,  45, 574, 575,   0],\n",
            "       [  3,   6, 855, 260, 261, 856,   0]], dtype=int32)>)\n",
            "tf.Tensor(\n",
            "[[179 433 122 116   9   4   0]\n",
            " [551 101 385 552  16   4   0]\n",
            " [ 28 131  96 410 411   4   0]\n",
            " [824 825  24  96 605   4   0]\n",
            " [ 90 177  96  90  38   4   0]\n",
            " [ 40  29 229  29 229   4   0]\n",
            " [ 12 101  83 549 293   4   0]\n",
            " [225 353  35 152 462   4   0]\n",
            " [882 883  54 194 395   4   0]\n",
            " [ 44 458 459 223  69   4   0]\n",
            " [221 774 449 775 776   4   0]\n",
            " [ 53  87  66 201 595   4   0]\n",
            " [715  64 716 717 494   4   0]\n",
            " [253   9 186  34 226   4   0]\n",
            " [161  14 162 377  57   4   0]\n",
            " [485 486 155  94 144   4   0]\n",
            " [131  24 243 244  86   4   0]\n",
            " [ 12  10   5   7  42   4   0]\n",
            " [ 67 119 342 327 654   4   0]\n",
            " [906  54  11 137 261   4   0]\n",
            " [ 19  28  92 327 213   4   0]\n",
            " [237  25 117  85 191   4   0]\n",
            " [380 532  21 161  63   4   0]\n",
            " [ 26 402 876 141 614   4   0]\n",
            " [ 32  10   9 801  35   4   0]\n",
            " [ 58  17 139 450 184   4   0]\n",
            " [  5 347 676  14 171   4   0]\n",
            " [ 51  97  58  51  97   4   0]\n",
            " [324 149 444  11  23   4   0]\n",
            " [125 636 151 637 173   4   0]\n",
            " [488 489 226  74  16   4   0]\n",
            " [ 20 126 759 499 500   4   0]], shape=(32, 7), dtype=int32)\n",
            "(<tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3,  43, 149,  10, 146, 325,   4],\n",
            "       [  3, 102, 101, 384, 294, 550,   4],\n",
            "       [  3,  87,  89, 307, 259, 132,   4],\n",
            "       [  3,   6,  45,  85, 823, 257,   4],\n",
            "       [  3, 277,  31,  33,  38, 246,   4],\n",
            "       [  3,  79, 767,   6,   5, 768,   4],\n",
            "       [  3, 131, 383,  52,  15, 132,   4],\n",
            "       [  3,  88, 460, 461, 318, 274,   4],\n",
            "       [  3, 392,  45,  24, 120, 346,   4],\n",
            "       [  3, 110,  49, 185,  44,  77,   4],\n",
            "       [  3,  54, 772,  88, 415, 773,   4],\n",
            "       [  3, 254, 313,  13,  25,  36,   4],\n",
            "       [  3,  90, 714,  90, 348, 207,   4],\n",
            "       [  3,  44, 185,  50, 203, 469,   4],\n",
            "       [  3, 526, 527,  14, 528,  27,   4],\n",
            "       [  3, 482, 483, 183,  69, 484,   4],\n",
            "       [  3, 551, 101, 385, 552,  16,   4],\n",
            "       [  3,   9, 188, 232, 512,  81,   4],\n",
            "       [  3, 260, 653,  62,  28,  92,   4],\n",
            "       [  3, 128, 180, 250, 904, 905,   4],\n",
            "       [  3,  15,  66, 618, 326, 267,   4],\n",
            "       [  3, 116,  27, 290, 541,  99,   4],\n",
            "       [  3, 529, 530,  59, 531, 379,   4],\n",
            "       [  3, 874, 875, 692,  78,  16,   4],\n",
            "       [  3,  32,  10,   9,  26, 399,   4],\n",
            "       [  3, 900, 411, 901, 408,  39,   4],\n",
            "       [  3,   5, 674, 104, 675,  31,   4],\n",
            "       [  3, 192,  83, 241, 534, 535,   4],\n",
            "       [  3,  98,  65,   7, 135,   7,   4],\n",
            "       [  3,  19, 106,  78, 332, 635,   4],\n",
            "       [  3, 273,  61, 155, 228, 487,   4],\n",
            "       [  3, 756, 757,  18, 758, 130,   4]], dtype=int32)>, <tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 179, 433, 122, 116,   9,   0],\n",
            "       [  3, 551, 101, 385, 552,  16,   0],\n",
            "       [  3,  28, 131,  96, 410, 411,   0],\n",
            "       [  3, 824, 825,  24,  96, 605,   0],\n",
            "       [  3,  90, 177,  96,  90,  38,   0],\n",
            "       [  3,  40,  29, 229,  29, 229,   0],\n",
            "       [  3,  12, 101,  83, 549, 293,   0],\n",
            "       [  3, 225, 353,  35, 152, 462,   0],\n",
            "       [  3, 882, 883,  54, 194, 395,   0],\n",
            "       [  3,  44, 458, 459, 223,  69,   0],\n",
            "       [  3, 221, 774, 449, 775, 776,   0],\n",
            "       [  3,  53,  87,  66, 201, 595,   0],\n",
            "       [  3, 715,  64, 716, 717, 494,   0],\n",
            "       [  3, 253,   9, 186,  34, 226,   0],\n",
            "       [  3, 161,  14, 162, 377,  57,   0],\n",
            "       [  3, 485, 486, 155,  94, 144,   0],\n",
            "       [  3, 131,  24, 243, 244,  86,   0],\n",
            "       [  3,  12,  10,   5,   7,  42,   0],\n",
            "       [  3,  67, 119, 342, 327, 654,   0],\n",
            "       [  3, 906,  54,  11, 137, 261,   0],\n",
            "       [  3,  19,  28,  92, 327, 213,   0],\n",
            "       [  3, 237,  25, 117,  85, 191,   0],\n",
            "       [  3, 380, 532,  21, 161,  63,   0],\n",
            "       [  3,  26, 402, 876, 141, 614,   0],\n",
            "       [  3,  32,  10,   9, 801,  35,   0],\n",
            "       [  3,  58,  17, 139, 450, 184,   0],\n",
            "       [  3,   5, 347, 676,  14, 171,   0],\n",
            "       [  3,  51,  97,  58,  51,  97,   0],\n",
            "       [  3, 324, 149, 444,  11,  23,   0],\n",
            "       [  3, 125, 636, 151, 637, 173,   0],\n",
            "       [  3, 488, 489, 226,  74,  16,   0],\n",
            "       [  3,  20, 126, 759, 499, 500,   0]], dtype=int32)>)\n",
            "tf.Tensor(\n",
            "[[235 209 992 696 993   4   0]\n",
            " [133  65  71 299 300   4   0]\n",
            " [ 17 361 123 361  88   4   0]\n",
            " [ 11  49  55 121 279   4   0]\n",
            " [ 15  66 618 326 267   4   0]\n",
            " [  5  91  40   7  41   4   0]\n",
            " [ 17 404  83  11 879   4   0]\n",
            " [499 500 966 183 224   4   0]\n",
            " [498 140  20 739 740   4   0]\n",
            " [128 114  96 288 239   4   0]\n",
            " [852 171 241 853 161   4   0]\n",
            " [  5  42 112 517 374   4   0]\n",
            " [ 36  70  13 114 351   4   0]\n",
            " [ 37 913 492 104  44   4   0]\n",
            " [ 62  30 168  12 586   4   0]\n",
            " [253   9 186  34 226   4   0]\n",
            " [358  14 162 156 711   4   0]\n",
            " [ 48   9  26 769 147   4   0]\n",
            " [ 13   5 110  20 187   4   0]\n",
            " [100 315  24  93 183   4   0]\n",
            " [281  28  92 477  41   4   0]\n",
            " [ 82   6 954  20 144   4   0]\n",
            " [ 67 119 330 217 174   4   0]\n",
            " [ 19 108 102  51 334   4   0]\n",
            " [ 61 176  72 891 100   4   0]\n",
            " [ 32  10   9 599 600   4   0]\n",
            " [476  12  55  93  80   4   0]\n",
            " [ 24  34 555 556 557   4   0]\n",
            " [292 104 505  11  34   4   0]\n",
            " [ 13  39  49  95  57   4   0]\n",
            " [ 60 103 566 304 567   4   0]\n",
            " [ 39  58  57  85 191   4   0]], shape=(32, 7), dtype=int32)\n",
            "(<tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 225, 353,  35, 397, 991,   4],\n",
            "       [  3,  70, 245, 389,  11, 298,   4],\n",
            "       [  3, 731, 732,  72, 130, 733,   4],\n",
            "       [  3,  11,  13,  55, 453, 234,   4],\n",
            "       [  3, 615, 616, 617, 212, 143,   4],\n",
            "       [  3,   8, 265, 266,  22,  23,   4],\n",
            "       [  3, 878, 398,  25, 255, 611,   4],\n",
            "       [  3,  48, 211, 228, 493, 790,   4],\n",
            "       [  3,   6, 186, 738, 497,  94,   4],\n",
            "       [  3, 237, 238,  26, 287, 522,   4],\n",
            "       [  3,  87, 169, 607, 100, 851,   4],\n",
            "       [  3, 515, 516,  49,  83,  84,   4],\n",
            "       [  3,  80, 456, 457,  31, 350,   4],\n",
            "       [  3,  82, 911, 912,  63, 193,   4],\n",
            "       [  3, 585, 394, 301, 120, 252,   4],\n",
            "       [  3,  44, 185,  50, 203, 469,   4],\n",
            "       [  3, 118, 289,  47, 709, 710,   4],\n",
            "       [  3,  40,  29, 229,  29, 229,   4],\n",
            "       [  3, 113, 187, 169,   7, 115,   4],\n",
            "       [  3,  33,  38,  85, 205, 105,   4],\n",
            "       [  3, 476,  12,  55,  93,  80,   4],\n",
            "       [  3, 498,  21, 502, 952, 953,   4],\n",
            "       [  3, 627, 216,  93, 329, 124,   4],\n",
            "       [  3, 638, 333, 213,  61, 267,   4],\n",
            "       [  3, 696, 443, 889, 890,  16,   4],\n",
            "       [  3,  32,  10,   9, 801,  35,   4],\n",
            "       [  3,  52,  76, 222, 474, 475,   4],\n",
            "       [  3,  10, 386,  44, 159, 554,   4],\n",
            "       [  3,  48,   9,  26, 769, 147,   4],\n",
            "       [  3,  46,  64,  18, 231, 320,   4],\n",
            "       [  3, 390,   5,  75, 565, 246,   4],\n",
            "       [  3, 130,  50, 544,  27,  49,   4]], dtype=int32)>, <tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 235, 209, 992, 696, 993,   0],\n",
            "       [  3, 133,  65,  71, 299, 300,   0],\n",
            "       [  3,  17, 361, 123, 361,  88,   0],\n",
            "       [  3,  11,  49,  55, 121, 279,   0],\n",
            "       [  3,  15,  66, 618, 326, 267,   0],\n",
            "       [  3,   5,  91,  40,   7,  41,   0],\n",
            "       [  3,  17, 404,  83,  11, 879,   0],\n",
            "       [  3, 499, 500, 966, 183, 224,   0],\n",
            "       [  3, 498, 140,  20, 739, 740,   0],\n",
            "       [  3, 128, 114,  96, 288, 239,   0],\n",
            "       [  3, 852, 171, 241, 853, 161,   0],\n",
            "       [  3,   5,  42, 112, 517, 374,   0],\n",
            "       [  3,  36,  70,  13, 114, 351,   0],\n",
            "       [  3,  37, 913, 492, 104,  44,   0],\n",
            "       [  3,  62,  30, 168,  12, 586,   0],\n",
            "       [  3, 253,   9, 186,  34, 226,   0],\n",
            "       [  3, 358,  14, 162, 156, 711,   0],\n",
            "       [  3,  48,   9,  26, 769, 147,   0],\n",
            "       [  3,  13,   5, 110,  20, 187,   0],\n",
            "       [  3, 100, 315,  24,  93, 183,   0],\n",
            "       [  3, 281,  28,  92, 477,  41,   0],\n",
            "       [  3,  82,   6, 954,  20, 144,   0],\n",
            "       [  3,  67, 119, 330, 217, 174,   0],\n",
            "       [  3,  19, 108, 102,  51, 334,   0],\n",
            "       [  3,  61, 176,  72, 891, 100,   0],\n",
            "       [  3,  32,  10,   9, 599, 600,   0],\n",
            "       [  3, 476,  12,  55,  93,  80,   0],\n",
            "       [  3,  24,  34, 555, 556, 557,   0],\n",
            "       [  3, 292, 104, 505,  11,  34,   0],\n",
            "       [  3,  13,  39,  49,  95,  57,   0],\n",
            "       [  3,  60, 103, 566, 304, 567,   0],\n",
            "       [  3,  39,  58,  57,  85, 191,   0]], dtype=int32)>)\n",
            "tf.Tensor(\n",
            "[[110  49 185  44  77   4   0]\n",
            " [ 15 343 344 655 271   4   0]\n",
            " [275  63  48 193 147   4   0]\n",
            " [ 23  99  11 349 478   4   0]\n",
            " [476  12  55  93  80   4   0]\n",
            " [ 73 101  83  43 193   4   0]\n",
            " [ 36  75 129  95  77   4   0]\n",
            " [161  14 162 377  57   4   0]\n",
            " [ 30 647 340 648 181   4   0]\n",
            " [161 672 673 179 152   4   0]\n",
            " [ 36  70  13 114 277   4   0]\n",
            " [351 259  17 342  94   4   0]\n",
            " [115 608 919 166  47   4   0]\n",
            " [ 48 211 228 493 790   4   0]\n",
            " [579 119 136 137 250   4   0]\n",
            " [ 37 275 764  14  25   4   0]\n",
            " [708 414 357 493 229   4   0]\n",
            " [ 71  37   7  16 256   4   0]\n",
            " [154 471 472 473  16   4   0]\n",
            " [729  12 730 270 124   4   0]\n",
            " [945 946  80 263 947   4   0]\n",
            " [ 75 782  34 948 949   4   0]\n",
            " [381  13  64 129 543   4   0]\n",
            " [ 45   5  56 572 166   4   0]\n",
            " [  5 317 712 150 713   4   0]\n",
            " [110  49 185  44  77   4   0]\n",
            " [585 394 301 120 252   4   0]\n",
            " [ 76 372 897  66 418   4   0]\n",
            " [ 82 701 702 703 222   4   0]\n",
            " [ 37 781 116 217  20   4   0]\n",
            " [ 19 219 330 217 174   4   0]\n",
            " [ 32  10  54 599 600   4   0]], shape=(32, 7), dtype=int32)\n",
            "(<tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3,  36,  70,  13, 114, 277,   4],\n",
            "       [  3,  67, 119, 342, 327, 654,   4],\n",
            "       [  3, 424,  14, 127, 925, 181,   4],\n",
            "       [  3, 187,  99,  11, 115,  18,   4],\n",
            "       [  3,  52,  76, 222, 474, 475,   4],\n",
            "       [  3,  12, 101,  83, 549, 293,   4],\n",
            "       [  3,  63, 363,  48, 765, 766,   4],\n",
            "       [  3, 526, 527,  14, 528,  27,   4],\n",
            "       [  3, 135, 646, 180,  62, 270,   4],\n",
            "       [  3,  51,  97,  15,  81, 123,   4],\n",
            "       [  3,  36,  70,  13, 114, 351,   4],\n",
            "       [  3,  37,  31,  59,  16, 271,   4],\n",
            "       [  3,   7,  12,  18, 785, 786,   4],\n",
            "       [  3, 424,  14, 127, 147, 193,   4],\n",
            "       [  3, 188, 577, 392, 199, 578,   4],\n",
            "       [  3, 763, 362,  17, 225, 224,   4],\n",
            "       [  3, 706, 707,  56, 132, 282,   4],\n",
            "       [  3,  17, 361, 123, 361,  88,   4],\n",
            "       [  3, 227, 227, 189, 470, 356,   4],\n",
            "       [  3, 175, 727,  27, 728,  69,   4],\n",
            "       [  3,  18, 440, 115, 369, 369,   4],\n",
            "       [  3, 368, 125, 158, 276, 154,   4],\n",
            "       [  3, 112,  38,  63,  26, 242,   4],\n",
            "       [  3,  60,  56, 571, 248, 307,   4],\n",
            "       [  3, 358,  14, 162, 156, 711,   4],\n",
            "       [  3,  36,  70,  13, 114, 277,   4],\n",
            "       [  3, 583, 584,  61,  53, 304,   4],\n",
            "       [  3, 165, 895,  89, 896,  50,   4],\n",
            "       [  3, 410, 698, 153, 699, 700,   4],\n",
            "       [  3, 166,  47, 903, 132, 126,   4],\n",
            "       [  3, 120, 269, 656, 173,  57,   4],\n",
            "       [  3,  32,  10,  54, 306, 796,   4]], dtype=int32)>, <tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 110,  49, 185,  44,  77,   0],\n",
            "       [  3,  15, 343, 344, 655, 271,   0],\n",
            "       [  3, 275,  63,  48, 193, 147,   0],\n",
            "       [  3,  23,  99,  11, 349, 478,   0],\n",
            "       [  3, 476,  12,  55,  93,  80,   0],\n",
            "       [  3,  73, 101,  83,  43, 193,   0],\n",
            "       [  3,  36,  75, 129,  95,  77,   0],\n",
            "       [  3, 161,  14, 162, 377,  57,   0],\n",
            "       [  3,  30, 647, 340, 648, 181,   0],\n",
            "       [  3, 161, 672, 673, 179, 152,   0],\n",
            "       [  3,  36,  70,  13, 114, 277,   0],\n",
            "       [  3, 351, 259,  17, 342,  94,   0],\n",
            "       [  3, 115, 608, 919, 166,  47,   0],\n",
            "       [  3,  48, 211, 228, 493, 790,   0],\n",
            "       [  3, 579, 119, 136, 137, 250,   0],\n",
            "       [  3,  37, 275, 764,  14,  25,   0],\n",
            "       [  3, 708, 414, 357, 493, 229,   0],\n",
            "       [  3,  71,  37,   7,  16, 256,   0],\n",
            "       [  3, 154, 471, 472, 473,  16,   0],\n",
            "       [  3, 729,  12, 730, 270, 124,   0],\n",
            "       [  3, 945, 946,  80, 263, 947,   0],\n",
            "       [  3,  75, 782,  34, 948, 949,   0],\n",
            "       [  3, 381,  13,  64, 129, 543,   0],\n",
            "       [  3,  45,   5,  56, 572, 166,   0],\n",
            "       [  3,   5, 317, 712, 150, 713,   0],\n",
            "       [  3, 110,  49, 185,  44,  77,   0],\n",
            "       [  3, 585, 394, 301, 120, 252,   0],\n",
            "       [  3,  76, 372, 897,  66, 418,   0],\n",
            "       [  3,  82, 701, 702, 703, 222,   0],\n",
            "       [  3,  37, 781, 116, 217,  20,   0],\n",
            "       [  3,  19, 219, 330, 217, 174,   0],\n",
            "       [  3,  32,  10,  54, 599, 600,   0]], dtype=int32)>)\n",
            "tf.Tensor(\n",
            "[[463 464 239  27 465   4   0]\n",
            " [202 127  43 596 597   4   0]\n",
            " [  6   5 690 691 221   4   0]\n",
            " [ 46 413  28 215 150   4   0]\n",
            " [ 24 375 376 519 520   4   0]\n",
            " [ 68  18 480 258 481   4   0]\n",
            " [488 489 226  74  16   4   0]\n",
            " [245  35 924 368 125   4   0]\n",
            " [236 400   8 204 317   4   0]\n",
            " [154 471 472 473  16   4   0]\n",
            " [ 88 460 461 318 274   4   0]\n",
            " [ 19 662 663 288 664   4   0]\n",
            " [ 19  28  92  76 213   4   0]\n",
            " [513 285   5 373 514   4   0]\n",
            " [409 207 607 829 830   4   0]\n",
            " [186   6 230 784  84   4   0]\n",
            " [170 921  74 922 923   4   0]\n",
            " [ 29   5   6 969 970   4   0]\n",
            " [218 632 407 633  61   4   0]\n",
            " [175 727  27 728  69   4   0]\n",
            " [354  14  23 223 466   4   0]\n",
            " [  5  91  40   7  41   4   0]\n",
            " [131  24 243 244  86   4   0]\n",
            " [ 89 976 977 182 495   4   0]\n",
            " [ 19 106  78  93 628   4   0]\n",
            " [122  73 680 299 681   4   0]\n",
            " [398  23 598  22  54   4   0]\n",
            " [587 311 200  73 588   4   0]\n",
            " [194 295  21 560 561   4   0]\n",
            " [101 242  65 553  33   4   0]\n",
            " [ 21   9 111  56  23   4   0]\n",
            " [131 383  52  15 132   4   0]], shape=(32, 7), dtype=int32)\n",
            "(<tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 225, 353,  35, 152, 462,   4],\n",
            "       [  3,  53,  87,  66, 201, 595,   4],\n",
            "       [  3,   8, 262, 871,  86,  51,   4],\n",
            "       [  3, 629, 630, 631, 311, 326,   4],\n",
            "       [  3,  29, 127,  43, 235, 518,   4],\n",
            "       [  3, 479, 182,  84, 206, 138,   4],\n",
            "       [  3, 273,  61, 155, 228, 487,   4],\n",
            "       [  3, 170, 921,  74, 922, 923,   4],\n",
            "       [  3,  17, 391,  83, 805, 254,   4],\n",
            "       [  3, 227, 227, 189, 470, 356,   4],\n",
            "       [  3,  20, 224,  35, 280, 352,   4],\n",
            "       [  3,  53, 661, 180, 124, 341,   4],\n",
            "       [  3, 151, 339, 332, 212, 645,   4],\n",
            "       [  3,  21,   9, 111,  56,  23,   4],\n",
            "       [  3, 827, 828, 606, 258,  43,   4],\n",
            "       [  3, 245,  35, 924, 368, 125,   4],\n",
            "       [  3,  40, 322,  20, 197, 920,   4],\n",
            "       [  3,  60, 156, 362, 152, 228,   4],\n",
            "       [  3,  19, 259,  93, 329,  62,   4],\n",
            "       [  3, 283,  67, 170, 726, 207,   4],\n",
            "       [  3,   7,  13,  36, 103,  42,   4],\n",
            "       [  3,   8, 265, 266,  22,  23,   4],\n",
            "       [  3, 551, 101, 385, 552,  16,   4],\n",
            "       [  3,  40, 406, 794, 276, 975,   4],\n",
            "       [  3,  67, 119, 330, 217, 174,   4],\n",
            "       [  3, 677, 678, 300,  30, 679,   4],\n",
            "       [  3, 795,  89, 122,   8, 105,   4],\n",
            "       [  3,  62,  30, 168,  12, 586,   4],\n",
            "       [  3,  70,  74, 559, 296, 297,   4],\n",
            "       [  3, 131,  24, 243, 244,  86,   4],\n",
            "       [  3,  11,  10, 160, 233, 372,   4],\n",
            "       [  3,  10, 546, 547, 548, 100,   4]], dtype=int32)>, <tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 463, 464, 239,  27, 465,   0],\n",
            "       [  3, 202, 127,  43, 596, 597,   0],\n",
            "       [  3,   6,   5, 690, 691, 221,   0],\n",
            "       [  3,  46, 413,  28, 215, 150,   0],\n",
            "       [  3,  24, 375, 376, 519, 520,   0],\n",
            "       [  3,  68,  18, 480, 258, 481,   0],\n",
            "       [  3, 488, 489, 226,  74,  16,   0],\n",
            "       [  3, 245,  35, 924, 368, 125,   0],\n",
            "       [  3, 236, 400,   8, 204, 317,   0],\n",
            "       [  3, 154, 471, 472, 473,  16,   0],\n",
            "       [  3,  88, 460, 461, 318, 274,   0],\n",
            "       [  3,  19, 662, 663, 288, 664,   0],\n",
            "       [  3,  19,  28,  92,  76, 213,   0],\n",
            "       [  3, 513, 285,   5, 373, 514,   0],\n",
            "       [  3, 409, 207, 607, 829, 830,   0],\n",
            "       [  3, 186,   6, 230, 784,  84,   0],\n",
            "       [  3, 170, 921,  74, 922, 923,   0],\n",
            "       [  3,  29,   5,   6, 969, 970,   0],\n",
            "       [  3, 218, 632, 407, 633,  61,   0],\n",
            "       [  3, 175, 727,  27, 728,  69,   0],\n",
            "       [  3, 354,  14,  23, 223, 466,   0],\n",
            "       [  3,   5,  91,  40,   7,  41,   0],\n",
            "       [  3, 131,  24, 243, 244,  86,   0],\n",
            "       [  3,  89, 976, 977, 182, 495,   0],\n",
            "       [  3,  19, 106,  78,  93, 628,   0],\n",
            "       [  3, 122,  73, 680, 299, 681,   0],\n",
            "       [  3, 398,  23, 598,  22,  54,   0],\n",
            "       [  3, 587, 311, 200,  73, 588,   0],\n",
            "       [  3, 194, 295,  21, 560, 561,   0],\n",
            "       [  3, 101, 242,  65, 553,  33,   0],\n",
            "       [  3,  21,   9, 111,  56,  23,   0],\n",
            "       [  3, 131, 383,  52,  15, 132,   0]], dtype=int32)>)\n",
            "tf.Tensor(\n",
            "[[424  14 127 925 181   4   0]\n",
            " [ 19 108  28  92 334   4   0]\n",
            " [165 359 719 131 136   4   0]\n",
            " [ 34 113 189 533 163   4   0]\n",
            " [ 79 767   6   5 768   4   0]\n",
            " [221 774 449 775 776   4   0]\n",
            " [432   5 135 148  59   4   0]\n",
            " [  8 249 167 668 669   4   0]\n",
            " [694 172 287 306  86   4   0]\n",
            " [ 64  27 268 331  41   4   0]\n",
            " [638 333 213  61 267   4   0]\n",
            " [ 20 238 195  46  32   4   0]\n",
            " [  8 265 266  22  23   4   0]\n",
            " [225 353  35 152 462   4   0]\n",
            " [221 145 690 691   6   4   0]\n",
            " [112 523  50 524 525   4   0]\n",
            " [141  75  21 809 173   4   0]\n",
            " [110 958  44 508 125   4   0]\n",
            " [506 985  94 503 362   4   0]\n",
            " [ 80 468 355 168 208   4   0]\n",
            " [ 19 259  93 329  62   4   0]\n",
            " [151 339 332 212 645   4   0]\n",
            " [432   5 135 148  59   4   0]\n",
            " [169 593 121 202 253   4   0]\n",
            " [ 67 612  20 928 929   4   0]\n",
            " [  5  26 444 170 274   4   0]\n",
            " [ 87  89 307 259 132   4   0]\n",
            " [280 252 737 336  32   4   0]\n",
            " [  7  12  18 785 786   4   0]\n",
            " [254 313  13  25  36   4   0]\n",
            " [120 275  85 205 105   4   0]\n",
            " [ 14 467   6 257 136   4   0]], shape=(32, 7), dtype=int32)\n",
            "(<tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 186,   6, 230, 784,  84,   4],\n",
            "       [  3, 649, 176, 102, 333, 134,   4],\n",
            "       [  3, 421,  25, 718,  25, 117,   4],\n",
            "       [  3, 380, 532,  21, 161,  63,   4],\n",
            "       [  3,  36,  75, 129,  95,  77,   4],\n",
            "       [  3,  54, 772,  88, 415, 773,   4],\n",
            "       [  3,  32,  11,  17, 190, 431,   4],\n",
            "       [  3, 273, 667, 425,  22,  65,   4],\n",
            "       [  3,  40, 450, 149,  89,   8,   4],\n",
            "       [  3,  19, 106,  78,  93, 628,   4],\n",
            "       [  3,  15,  66, 150, 218,  62,   4],\n",
            "       [  3,  13,   5, 110,  20, 187,   4],\n",
            "       [  3,   7,  91,   5,   7,  41,   4],\n",
            "       [  3,  88, 460, 461, 318, 274,   4],\n",
            "       [  3,   6,   5, 690, 691, 221,   4],\n",
            "       [  3, 128, 114,  96, 288, 239,   4],\n",
            "       [  3, 808, 188,  21, 404, 203,   4],\n",
            "       [  3, 957,  27, 183,  94, 160,   4],\n",
            "       [  3, 442,  14,   6, 983, 984,   4],\n",
            "       [  3,  14, 467,   6, 257, 136,   4],\n",
            "       [  3,  46, 413,  28, 215, 150,   4],\n",
            "       [  3, 260, 419, 102, 644, 198,   4],\n",
            "       [  3,  32,  11,  17, 190, 431,   4],\n",
            "       [  3,  88, 396,  13, 200, 592,   4],\n",
            "       [  3,  71, 182, 927, 270, 124,   4],\n",
            "       [  3, 141,   7, 346,  25, 142,   4],\n",
            "       [  3, 833, 190,  51,  39, 296,   4],\n",
            "       [  3, 126, 178, 316, 496,  20,   4],\n",
            "       [  3, 117, 918,  56, 393, 350,   4],\n",
            "       [  3, 103,  14, 171, 172,  31,   4],\n",
            "       [  3,   5, 347, 676,  14, 171,   4],\n",
            "       [  3, 354,  14,  23, 223, 466,   4]], dtype=int32)>, <tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 424,  14, 127, 925, 181,   0],\n",
            "       [  3,  19, 108,  28,  92, 334,   0],\n",
            "       [  3, 165, 359, 719, 131, 136,   0],\n",
            "       [  3,  34, 113, 189, 533, 163,   0],\n",
            "       [  3,  79, 767,   6,   5, 768,   0],\n",
            "       [  3, 221, 774, 449, 775, 776,   0],\n",
            "       [  3, 432,   5, 135, 148,  59,   0],\n",
            "       [  3,   8, 249, 167, 668, 669,   0],\n",
            "       [  3, 694, 172, 287, 306,  86,   0],\n",
            "       [  3,  64,  27, 268, 331,  41,   0],\n",
            "       [  3, 638, 333, 213,  61, 267,   0],\n",
            "       [  3,  20, 238, 195,  46,  32,   0],\n",
            "       [  3,   8, 265, 266,  22,  23,   0],\n",
            "       [  3, 225, 353,  35, 152, 462,   0],\n",
            "       [  3, 221, 145, 690, 691,   6,   0],\n",
            "       [  3, 112, 523,  50, 524, 525,   0],\n",
            "       [  3, 141,  75,  21, 809, 173,   0],\n",
            "       [  3, 110, 958,  44, 508, 125,   0],\n",
            "       [  3, 506, 985,  94, 503, 362,   0],\n",
            "       [  3,  80, 468, 355, 168, 208,   0],\n",
            "       [  3,  19, 259,  93, 329,  62,   0],\n",
            "       [  3, 151, 339, 332, 212, 645,   0],\n",
            "       [  3, 432,   5, 135, 148,  59,   0],\n",
            "       [  3, 169, 593, 121, 202, 253,   0],\n",
            "       [  3,  67, 612,  20, 928, 929,   0],\n",
            "       [  3,   5,  26, 444, 170, 274,   0],\n",
            "       [  3,  87,  89, 307, 259, 132,   0],\n",
            "       [  3, 280, 252, 737, 336,  32,   0],\n",
            "       [  3,   7,  12,  18, 785, 786,   0],\n",
            "       [  3, 254, 313,  13,  25,  36,   0],\n",
            "       [  3, 120, 275,  85, 205, 105,   0],\n",
            "       [  3,  14, 467,   6, 257, 136,   0]], dtype=int32)>)\n",
            "tf.Tensor(\n",
            "[[ 48 108 114 445 140   4   0]\n",
            " [ 70  74 559 296 297   4   0]\n",
            " [306   5  56 195 570   4   0]\n",
            " [463 464 239  27 465   4   0]\n",
            " [874 875 692  78  16   4   0]\n",
            " [368 125  36 790 269   4   0]\n",
            " [268 416 130 621 269   4   0]\n",
            " [731 732  72 130 733   4   0]\n",
            " [ 13 412 110 113 286   4   0]\n",
            " [260 419 102 644 198   4   0]\n",
            " [ 40 386  65 407 206   4   0]\n",
            " [307  31 146   8   6   4   0]\n",
            " [ 40 450 149  89   8   4   0]\n",
            " [686 687 180 250 447   4   0]\n",
            " [ 98 172  31 360  74   4   0]\n",
            " [ 88 460 461 318 274   4   0]\n",
            " [199  37 256 129  95   4   0]\n",
            " [485 486 155  94 144   4   0]\n",
            " [397  87  35 100 315   4   0]\n",
            " [280 252 737 336  32   4   0]\n",
            " [440 643  79 173 134   4   0]\n",
            " [749 750 751 752 753   4   0]\n",
            " [ 98  65   7 135   7   4   0]\n",
            " [161 672 673 179 152   4   0]\n",
            " [ 13 412 110 113 286   4   0]\n",
            " [192  83 241 534 535   4   0]\n",
            " [306   5  56 195 570   4   0]\n",
            " [170  10  13  39  98   4   0]\n",
            " [325 692  78   6  33   4   0]\n",
            " [878 398  25 255 611   4   0]\n",
            " [529 530  59 531 379   4   0]\n",
            " [  7  13  36 103  42   4   0]], shape=(32, 7), dtype=int32)\n",
            "(<tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 382,  37, 936, 133, 355,   4],\n",
            "       [  3, 194, 295, 387, 388, 558,   4],\n",
            "       [  3,  15,  17,   6, 305, 165,   4],\n",
            "       [  3, 225, 353,  35, 152, 462,   4],\n",
            "       [  3,  29,  33,  38, 872, 873,   4],\n",
            "       [  3, 941, 942, 155,  20,  18,   4],\n",
            "       [  3, 619, 328, 108, 290, 620,   4],\n",
            "       [  3, 729,  12, 730, 270, 124,   4],\n",
            "       [  3,  20, 238, 195,  46,  32,   4],\n",
            "       [  3, 337, 338,  28, 215, 107,   4],\n",
            "       [  3, 314, 405, 255, 820, 120,   4],\n",
            "       [  3,   6, 122, 858, 859, 378,   4],\n",
            "       [  3, 694, 172, 287,   8, 450,   4],\n",
            "       [  3,  96, 177,   8,  68,  46,   4],\n",
            "       [  3, 777, 778, 779,  39,  58,   4],\n",
            "       [  3,  20, 224,  35, 280, 352,   4],\n",
            "       [  3,  48, 734,  95, 109, 157,   4],\n",
            "       [  3, 482, 483, 183,  69, 484,   4],\n",
            "       [  3, 170,  10,  13,  39,  98,   4],\n",
            "       [  3, 126, 178, 316, 496,  20,   4],\n",
            "       [  3,  68, 642, 151, 336, 178,   4],\n",
            "       [  3, 230, 746,  20, 747, 748,   4],\n",
            "       [  3, 321, 371, 877,  79,  47,   4],\n",
            "       [  3,  51,  97,  15,  81, 123,   4],\n",
            "       [  3,  20, 238, 195,  46,  32,   4],\n",
            "       [  3, 116,  57, 117,  85, 191,   4],\n",
            "       [  3,  15,  17,   6, 305, 165,   4],\n",
            "       [  3,  18, 314, 285,  18, 201,   4],\n",
            "       [  3,  26, 402, 876, 141, 614,   4],\n",
            "       [  3, 324, 149, 444,  11,  23,   4],\n",
            "       [  3,  23,  58,  14, 162, 378,   4],\n",
            "       [  3,  44, 458, 459, 223,  69,   4]], dtype=int32)>, <tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3,  48, 108, 114, 445, 140,   0],\n",
            "       [  3,  70,  74, 559, 296, 297,   0],\n",
            "       [  3, 306,   5,  56, 195, 570,   0],\n",
            "       [  3, 463, 464, 239,  27, 465,   0],\n",
            "       [  3, 874, 875, 692,  78,  16,   0],\n",
            "       [  3, 368, 125,  36, 790, 269,   0],\n",
            "       [  3, 268, 416, 130, 621, 269,   0],\n",
            "       [  3, 731, 732,  72, 130, 733,   0],\n",
            "       [  3,  13, 412, 110, 113, 286,   0],\n",
            "       [  3, 260, 419, 102, 644, 198,   0],\n",
            "       [  3,  40, 386,  65, 407, 206,   0],\n",
            "       [  3, 307,  31, 146,   8,   6,   0],\n",
            "       [  3,  40, 450, 149,  89,   8,   0],\n",
            "       [  3, 686, 687, 180, 250, 447,   0],\n",
            "       [  3,  98, 172,  31, 360,  74,   0],\n",
            "       [  3,  88, 460, 461, 318, 274,   0],\n",
            "       [  3, 199,  37, 256, 129,  95,   0],\n",
            "       [  3, 485, 486, 155,  94, 144,   0],\n",
            "       [  3, 397,  87,  35, 100, 315,   0],\n",
            "       [  3, 280, 252, 737, 336,  32,   0],\n",
            "       [  3, 440, 643,  79, 173, 134,   0],\n",
            "       [  3, 749, 750, 751, 752, 753,   0],\n",
            "       [  3,  98,  65,   7, 135,   7,   0],\n",
            "       [  3, 161, 672, 673, 179, 152,   0],\n",
            "       [  3,  13, 412, 110, 113, 286,   0],\n",
            "       [  3, 192,  83, 241, 534, 535,   0],\n",
            "       [  3, 306,   5,  56, 195, 570,   0],\n",
            "       [  3, 170,  10,  13,  39,  98,   0],\n",
            "       [  3, 325, 692,  78,   6,  33,   0],\n",
            "       [  3, 878, 398,  25, 255, 611,   0],\n",
            "       [  3, 529, 530,  59, 531, 379,   0],\n",
            "       [  3,   7,  13,  36, 103,  42,   0]], dtype=int32)>)\n",
            "tf.Tensor(\n",
            "[[164  39  17 159 298   4   0]\n",
            " [650 651  62 124 341   4   0]\n",
            " [ 22  87 803 804  65   4   0]\n",
            " [268 416 130 621 269   4   0]\n",
            " [381  13  64 129 543   4   0]\n",
            " [771 363  48  78  84   4   0]\n",
            " [208 219 441 181 150   4   0]\n",
            " [314 405 255 820 120   4   0]\n",
            " [  5 347 676  14 171   4   0]\n",
            " [ 89   7 438  22   6   4   0]\n",
            " [ 76  98  12 770  67   4   0]\n",
            " [188 577 392 199 578   4   0]\n",
            " [ 27 109 157 200 347   4   0]\n",
            " [  8  33  38  82 234   4   0]\n",
            " [638 333 213  61 267   4   0]\n",
            " [  6 105 185  34 783   4   0]\n",
            " [324   6 211 164   9   4   0]\n",
            " [ 37 275 764  14  25   4   0]\n",
            " [141   7 346  25 142   4   0]\n",
            " [ 15 343 344 655 271   4   0]\n",
            " [197 198  45 574 575   4   0]\n",
            " [ 29 428 111  77   5   4   0]\n",
            " [ 68  18 480 258 481   4   0]\n",
            " [501 126  31 364 951   4   0]\n",
            " [  6 142   5 608 834   4   0]\n",
            " [ 17 361 123 361  88   4   0]\n",
            " [260 653  62  28  92   4   0]\n",
            " [ 44 458 459 223  69   4   0]\n",
            " [  9 371  71  43 159   4   0]\n",
            " [ 14 139  50   5 184   4   0]\n",
            " [  8 146 689 268   9   4   0]\n",
            " [145  90 420  43 598   4   0]], shape=(32, 7), dtype=int32)\n",
            "(<tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 564, 134,  11,  30,   9,   4],\n",
            "       [  3,  19, 108,  28,  92, 334,   4],\n",
            "       [  3, 255,  65, 374, 385,  87,   4],\n",
            "       [  3, 619, 328, 108, 290, 620,   4],\n",
            "       [  3, 112,  38,  63,  26, 242,   4],\n",
            "       [  3, 271, 204, 343, 364, 344,   4],\n",
            "       [  3, 650, 651,  62, 124, 341,   4],\n",
            "       [  3, 406, 816, 817, 818, 819,   4],\n",
            "       [  3,   5, 674, 104, 675,  31,   4],\n",
            "       [  3,   5,  91,  40,   7,  41,   4],\n",
            "       [  3,  14, 139,  50,   5, 184,   4],\n",
            "       [  3,  15,   9, 308, 309,  81,   4],\n",
            "       [  3, 933, 934, 359, 380, 789,   4],\n",
            "       [  3, 513, 285,   5, 373, 514,   4],\n",
            "       [  3,  15,  66, 150, 218,  62,   4],\n",
            "       [  3,  37, 913, 492, 104,  44,   4],\n",
            "       [  3,   9,  43,  10,  75,  71,   4],\n",
            "       [  3, 763, 362,  17, 225, 224,   4],\n",
            "       [  3,  49,  84,  58,  12,  25,   4],\n",
            "       [  3,  67, 119, 342, 327, 654,   4],\n",
            "       [  3,  60, 249,  21, 165,  25,   4],\n",
            "       [  3, 427,   7, 192,  75, 147,   4],\n",
            "       [  3, 479, 182,  84, 206, 138,   4],\n",
            "       [  3, 950, 787, 176, 792, 507,   4],\n",
            "       [  3,  26, 379,  61, 257,  36,   4],\n",
            "       [  3, 731, 732,  72, 130, 733,   4],\n",
            "       [  3,  15, 335, 652, 328, 331,   4],\n",
            "       [  3, 110,  49, 185,  44,  77,   4],\n",
            "       [  3,  12,  10,   5,   7,  42,   4],\n",
            "       [  3, 292, 104, 505,  11,  34,   4],\n",
            "       [  3, 694, 172, 287, 306,  86,   4],\n",
            "       [  3,   6, 854, 188,  90, 420,   4]], dtype=int32)>, <tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 164,  39,  17, 159, 298,   0],\n",
            "       [  3, 650, 651,  62, 124, 341,   0],\n",
            "       [  3,  22,  87, 803, 804,  65,   0],\n",
            "       [  3, 268, 416, 130, 621, 269,   0],\n",
            "       [  3, 381,  13,  64, 129, 543,   0],\n",
            "       [  3, 771, 363,  48,  78,  84,   0],\n",
            "       [  3, 208, 219, 441, 181, 150,   0],\n",
            "       [  3, 314, 405, 255, 820, 120,   0],\n",
            "       [  3,   5, 347, 676,  14, 171,   0],\n",
            "       [  3,  89,   7, 438,  22,   6,   0],\n",
            "       [  3,  76,  98,  12, 770,  67,   0],\n",
            "       [  3, 188, 577, 392, 199, 578,   0],\n",
            "       [  3,  27, 109, 157, 200, 347,   0],\n",
            "       [  3,   8,  33,  38,  82, 234,   0],\n",
            "       [  3, 638, 333, 213,  61, 267,   0],\n",
            "       [  3,   6, 105, 185,  34, 783,   0],\n",
            "       [  3, 324,   6, 211, 164,   9,   0],\n",
            "       [  3,  37, 275, 764,  14,  25,   0],\n",
            "       [  3, 141,   7, 346,  25, 142,   0],\n",
            "       [  3,  15, 343, 344, 655, 271,   0],\n",
            "       [  3, 197, 198,  45, 574, 575,   0],\n",
            "       [  3,  29, 428, 111,  77,   5,   0],\n",
            "       [  3,  68,  18, 480, 258, 481,   0],\n",
            "       [  3, 501, 126,  31, 364, 951,   0],\n",
            "       [  3,   6, 142,   5, 608, 834,   0],\n",
            "       [  3,  17, 361, 123, 361,  88,   0],\n",
            "       [  3, 260, 653,  62,  28,  92,   0],\n",
            "       [  3,  44, 458, 459, 223,  69,   0],\n",
            "       [  3,   9, 371,  71,  43, 159,   0],\n",
            "       [  3,  14, 139,  50,   5, 184,   0],\n",
            "       [  3,   8, 146, 689, 268,   9,   0],\n",
            "       [  3, 145,  90, 420,  43, 598,   0]], dtype=int32)>)\n",
            "tf.Tensor(\n",
            "[[423 121 400 302 303   4   0]\n",
            " [564 134  11  30   9   4   0]\n",
            " [230 746  20 747 748   4   0]\n",
            " [ 52 614 120 863 425   4   0]\n",
            " [ 34 113 189 533 163   4   0]\n",
            " [ 76 203 105 106   9   4   0]\n",
            " [864 293  24 178 865   4   0]\n",
            " [ 53 661 180 124 341   4   0]\n",
            " [ 19 108  28  92 334   4   0]\n",
            " [ 40  26 167 149  76   4   0]\n",
            " [169  29  52  73 116   4   0]\n",
            " [210 245 276  21   6   4   0]\n",
            " [ 36  70  13 114 277   4   0]\n",
            " [427   7 192  75 147   4   0]\n",
            " [ 15 335 652 328 331   4   0]\n",
            " [ 90 714  90 348 207   4   0]\n",
            " [  6 105 782 907  34   4   0]\n",
            " [ 37  80 157  59  57   4   0]\n",
            " [225 353  35 397 991   4   0]\n",
            " [112 523  50 524 525   4   0]\n",
            " [ 87 169 607 100 851   4   0]\n",
            " [629 630 631 311 326   4   0]\n",
            " [ 41   8  52  16 436   4   0]\n",
            " [  8 262 871  86  51   4   0]\n",
            " [153 272 340 660 443   4   0]\n",
            " [427   7 192  75 147   4   0]\n",
            " [368 125 204 930  88   4   0]\n",
            " [116  27 290 541  99   4   0]\n",
            " [ 12 101  83 549 293   4   0]\n",
            " [103  14 171 172  31   4   0]\n",
            " [ 33  45  29 145 176   4   0]\n",
            " [109 454 209 455  47   4   0]], shape=(32, 7), dtype=int32)\n",
            "(<tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3,  15, 196, 634, 218,  62,   4],\n",
            "       [  3,  10,  82, 301, 562, 563,   4],\n",
            "       [  3, 139, 110, 744,  82, 745,   4],\n",
            "       [  3, 383,  52, 424, 862, 320,   4],\n",
            "       [  3, 380, 532,  21, 161,  63,   4],\n",
            "       [  3,  32,  10, 797, 242, 602,   4],\n",
            "       [  3, 169,  29,  52,  73, 116,   4],\n",
            "       [  3, 153, 272, 340, 660, 443,   4],\n",
            "       [  3, 649, 176, 102, 333, 134,   4],\n",
            "       [  3,   8, 249, 167, 668, 669,   4],\n",
            "       [  3, 209, 388, 613,  26,  31,   4],\n",
            "       [  3, 959, 394, 794, 417, 960,   4],\n",
            "       [  3,  36,  70,  13, 114, 351,   4],\n",
            "       [  3, 321, 138, 104,  11,  53,   4],\n",
            "       [  3, 208, 219, 441, 181, 150,   4],\n",
            "       [  3,   5, 317, 712, 150, 713,   4],\n",
            "       [  3, 906,  54,  11, 137, 261,   4],\n",
            "       [  3, 771, 363,  48,  78,  84,   4],\n",
            "       [  3,  72, 154, 144, 352, 354,   4],\n",
            "       [  3, 128, 114,  96, 288, 239,   4],\n",
            "       [  3,  24, 189, 848, 849, 850,   4],\n",
            "       [  3,  64,  27, 268, 331,  41,   4],\n",
            "       [  3,  91,   8,  52, 434, 435,   4],\n",
            "       [  3,  64, 689, 389, 293, 870,   4],\n",
            "       [  3, 272, 181,  10, 658, 659,   4],\n",
            "       [  3, 321, 138, 104,  11,  53,   4],\n",
            "       [  3,  67, 612,  20, 928, 929,   4],\n",
            "       [  3,  26, 538, 127, 539, 540,   4],\n",
            "       [  3, 131, 383,  52,  15, 132,   4],\n",
            "       [  3, 397,  87,  35, 100, 315,   4],\n",
            "       [  3,  66,  45,  29, 145,  99,   4],\n",
            "       [  3,  11,  49,  55, 121, 279,   4]], dtype=int32)>, <tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 423, 121, 400, 302, 303,   0],\n",
            "       [  3, 564, 134,  11,  30,   9,   0],\n",
            "       [  3, 230, 746,  20, 747, 748,   0],\n",
            "       [  3,  52, 614, 120, 863, 425,   0],\n",
            "       [  3,  34, 113, 189, 533, 163,   0],\n",
            "       [  3,  76, 203, 105, 106,   9,   0],\n",
            "       [  3, 864, 293,  24, 178, 865,   0],\n",
            "       [  3,  53, 661, 180, 124, 341,   0],\n",
            "       [  3,  19, 108,  28,  92, 334,   0],\n",
            "       [  3,  40,  26, 167, 149,  76,   0],\n",
            "       [  3, 169,  29,  52,  73, 116,   0],\n",
            "       [  3, 210, 245, 276,  21,   6,   0],\n",
            "       [  3,  36,  70,  13, 114, 277,   0],\n",
            "       [  3, 427,   7, 192,  75, 147,   0],\n",
            "       [  3,  15, 335, 652, 328, 331,   0],\n",
            "       [  3,  90, 714,  90, 348, 207,   0],\n",
            "       [  3,   6, 105, 782, 907,  34,   0],\n",
            "       [  3,  37,  80, 157,  59,  57,   0],\n",
            "       [  3, 225, 353,  35, 397, 991,   0],\n",
            "       [  3, 112, 523,  50, 524, 525,   0],\n",
            "       [  3,  87, 169, 607, 100, 851,   0],\n",
            "       [  3, 629, 630, 631, 311, 326,   0],\n",
            "       [  3,  41,   8,  52,  16, 436,   0],\n",
            "       [  3,   8, 262, 871,  86,  51,   0],\n",
            "       [  3, 153, 272, 340, 660, 443,   0],\n",
            "       [  3, 427,   7, 192,  75, 147,   0],\n",
            "       [  3, 368, 125, 204, 930,  88,   0],\n",
            "       [  3, 116,  27, 290, 541,  99,   0],\n",
            "       [  3,  12, 101,  83, 549, 293,   0],\n",
            "       [  3, 103,  14, 171, 172,  31,   0],\n",
            "       [  3,  33,  45,  29, 145, 176,   0],\n",
            "       [  3, 109, 454, 209, 455,  47,   0]], dtype=int32)>)\n",
            "tf.Tensor(\n",
            "[[102 101 384 294 550   4   0]\n",
            " [ 26 538 127 539 540   4   0]\n",
            " [339 151 174 212 143   4   0]\n",
            " [125 636 151 637 173   4   0]\n",
            " [959 394 794 417 960   4   0]\n",
            " [175  10 176 296  64   4   0]\n",
            " [  8 265 266  22  23   4   0]\n",
            " [ 21  42 422 420 249   4   0]\n",
            " [ 89   7 438  22   6   4   0]\n",
            " [ 19 108 102  51 334   4   0]\n",
            " [ 15  66 618 326 267   4   0]\n",
            " [392  45  24 120 346   4   0]\n",
            " [ 14 139  50   5 184   4   0]\n",
            " [754 156  21 338 755   4   0]\n",
            " [109 157 955 364  53   4   0]\n",
            " [627 216  93 329 124   4   0]\n",
            " [619 328 108 290 620   4   0]\n",
            " [194 295 387 388 558   4   0]\n",
            " [263 787 926 266 168   4   0]\n",
            " [100 315  24  93 183   4   0]\n",
            " [267 971 140 509 126   4   0]\n",
            " [ 32  10  54 306 796   4   0]\n",
            " [972 973  50 974 781   4   0]\n",
            " [ 72 154 144 352 354   4   0]\n",
            " [937 938  20 272 939   4   0]\n",
            " [ 37  31  59  16 271   4   0]\n",
            " [179 433 122 116   9   4   0]\n",
            " [  9 371  71  43 159   4   0]\n",
            " [118  12 721 722 178   4   0]\n",
            " [ 19 214  86 220 345   4   0]\n",
            " [ 79 439 967 154 968   4   0]\n",
            " [ 13   8 313  64 395   4   0]], shape=(32, 7), dtype=int32)\n",
            "(<tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3,  73, 101,  83,  43, 193,   4],\n",
            "       [  3, 158,  98,  25, 536, 537,   4],\n",
            "       [  3,  19, 140,  86, 220, 345,   4],\n",
            "       [  3,  19, 106,  78, 332, 635,   4],\n",
            "       [  3, 508, 125,   7, 209, 783,   4],\n",
            "       [  3,   6, 142,   5, 608, 834,   4],\n",
            "       [  3,   7,  91,   5,   7,  41,   4],\n",
            "       [  3, 307,  31, 146,   8,   6,   4],\n",
            "       [  3,   5,  91,  40,   7,  41,   4],\n",
            "       [  3, 638, 333, 213,  61, 267,   4],\n",
            "       [  3, 615, 616, 617, 212, 143,   4],\n",
            "       [  3, 693, 373,  24, 693, 159,   4],\n",
            "       [  3, 292, 104, 505,  11,  34,   4],\n",
            "       [  3, 749, 750, 751, 752, 753,   4],\n",
            "       [  3,  48,  79,  20, 111,  84,   4],\n",
            "       [  3, 214, 134, 625, 626,  27,   4],\n",
            "       [  3,  19,  28,  92, 327, 213,   4],\n",
            "       [  3,  24,  34, 555, 556, 557,   4],\n",
            "       [  3, 128,   7,  18, 785, 786,   4],\n",
            "       [  3,  33,  38,  85, 205, 105,   4],\n",
            "       [  3,  10, 109, 157, 284, 128,   4],\n",
            "       [  3,  32,  10,  54,  26, 399,   4],\n",
            "       [  3, 508, 125,  71, 137,   6,   4],\n",
            "       [  3, 171, 317, 347, 254, 494,   4],\n",
            "       [  3,  48, 108, 114, 445, 140,   4],\n",
            "       [  3, 109, 157, 955, 364,  53,   4],\n",
            "       [  3,  43, 149,  10, 146, 325,   4],\n",
            "       [  3,  12,  10,   5,   7,  42,   4],\n",
            "       [  3, 148,  34,  11, 129,  95,   4],\n",
            "       [  3, 119, 665, 108,  78, 319,   4],\n",
            "       [  3, 499, 500, 966, 183, 224,   4],\n",
            "       [  3,  53,  87,   8,  18, 201,   4]], dtype=int32)>, <tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 102, 101, 384, 294, 550,   0],\n",
            "       [  3,  26, 538, 127, 539, 540,   0],\n",
            "       [  3, 339, 151, 174, 212, 143,   0],\n",
            "       [  3, 125, 636, 151, 637, 173,   0],\n",
            "       [  3, 959, 394, 794, 417, 960,   0],\n",
            "       [  3, 175,  10, 176, 296,  64,   0],\n",
            "       [  3,   8, 265, 266,  22,  23,   0],\n",
            "       [  3,  21,  42, 422, 420, 249,   0],\n",
            "       [  3,  89,   7, 438,  22,   6,   0],\n",
            "       [  3,  19, 108, 102,  51, 334,   0],\n",
            "       [  3,  15,  66, 618, 326, 267,   0],\n",
            "       [  3, 392,  45,  24, 120, 346,   0],\n",
            "       [  3,  14, 139,  50,   5, 184,   0],\n",
            "       [  3, 754, 156,  21, 338, 755,   0],\n",
            "       [  3, 109, 157, 955, 364,  53,   0],\n",
            "       [  3, 627, 216,  93, 329, 124,   0],\n",
            "       [  3, 619, 328, 108, 290, 620,   0],\n",
            "       [  3, 194, 295, 387, 388, 558,   0],\n",
            "       [  3, 263, 787, 926, 266, 168,   0],\n",
            "       [  3, 100, 315,  24,  93, 183,   0],\n",
            "       [  3, 267, 971, 140, 509, 126,   0],\n",
            "       [  3,  32,  10,  54, 306, 796,   0],\n",
            "       [  3, 972, 973,  50, 974, 781,   0],\n",
            "       [  3,  72, 154, 144, 352, 354,   0],\n",
            "       [  3, 937, 938,  20, 272, 939,   0],\n",
            "       [  3,  37,  31,  59,  16, 271,   0],\n",
            "       [  3, 179, 433, 122, 116,   9,   0],\n",
            "       [  3,   9, 371,  71,  43, 159,   0],\n",
            "       [  3, 118,  12, 721, 722, 178,   0],\n",
            "       [  3,  19, 214,  86, 220, 345,   0],\n",
            "       [  3,  79, 439, 967, 154, 968,   0],\n",
            "       [  3,  13,   8, 313,  64, 395,   0]], dtype=int32)>)\n",
            "tf.Tensor(\n",
            "[[281  28  92 477  41   4   0]\n",
            " [210 788  35  18  20   4   0]\n",
            " [380 532  21 161  63   4   0]\n",
            " [354  14  23 223 466   4   0]\n",
            " [ 23  45  17 196 305   4   0]\n",
            " [ 15 196 634 218  62   4   0]\n",
            " [130  50 544  27  49   4   0]\n",
            " [  7  91   5   7  41   4   0]\n",
            " [485 486 155  94 144   4   0]\n",
            " [ 36  70  13 114 277   4   0]\n",
            " [526 527  14 528  27   4   0]\n",
            " [564 134  11  30   9   4   0]\n",
            " [210 788  35 961 507   4   0]\n",
            " [ 12  10   5   7  42   4   0]\n",
            " [  7  13  36 103  42   4   0]\n",
            " [ 23   5  22 291 542   4   0]\n",
            " [ 29 127  43 235 518   4   0]\n",
            " [ 26  51  97 141   5   4   0]\n",
            " [121 594 202  35  18   4   0]\n",
            " [892 893 222 610 319   4   0]\n",
            " [141   6 402 205 142   4   0]\n",
            " [677 678 300  30 679   4   0]\n",
            " [ 32  10   9  26 399   4   0]\n",
            " [ 90 177  96  90  38   4   0]\n",
            " [209 388 613  26  31   4   0]\n",
            " [508 125   7 209 783   4   0]\n",
            " [279 144 164 179 506   4   0]\n",
            " [ 39  58  57  85 191   4   0]\n",
            " [237 238  26 287 522   4   0]\n",
            " [119 665 108  78 319   4   0]\n",
            " [337 338  28 215 107   4   0]\n",
            " [ 29 428 111  77   5   4   0]], shape=(32, 7), dtype=int32)\n",
            "(<tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 476,  12,  55,  93,  80,   4],\n",
            "       [  3, 931,  16, 140, 137, 261,   4],\n",
            "       [  3, 529, 530,  59, 531, 379,   4],\n",
            "       [  3,   7,  13,  36, 103,  42,   4],\n",
            "       [  3, 279, 144, 164, 179, 506,   4],\n",
            "       [  3, 218, 632, 407, 633,  61,   4],\n",
            "       [  3, 381,  13,  64, 129, 543,   4],\n",
            "       [  3,  40,  41,  89, 437,  72,   4],\n",
            "       [  3, 482, 483, 183,  69, 484,   4],\n",
            "       [  3,  36,  70,  13, 114, 351,   4],\n",
            "       [  3, 112, 523,  50, 524, 525,   4],\n",
            "       [  3,  10,  82, 301, 562, 563,   4],\n",
            "       [  3, 210, 245, 276,  21,   6,   4],\n",
            "       [  3,   9, 188, 232, 512,  81,   4],\n",
            "       [  3,  44, 458, 459, 223,  69,   4],\n",
            "       [  3, 237,  25, 117,  85, 191,   4],\n",
            "       [  3,   5,  42, 112, 517, 374,   4],\n",
            "       [  3,  81, 123, 182,  31,  42,   4],\n",
            "       [  3, 169, 593, 121, 202, 253,   4],\n",
            "       [  3,  61, 176,  72, 891, 100,   4],\n",
            "       [  3,  60,   7,  53,  63,   6,   4],\n",
            "       [  3, 120, 275,  85, 205, 105,   4],\n",
            "       [  3, 122, 800, 140, 105,  16,   4],\n",
            "       [  3, 277,  31,  33,  38, 246,   4],\n",
            "       [  3,  52, 614, 120, 863, 425,   4],\n",
            "       [  3,  48, 108, 793, 375, 376,   4],\n",
            "       [  3,  33,  45,  29, 145, 176,   4],\n",
            "       [  3, 130,  50, 544,  27,  49,   4],\n",
            "       [  3, 236, 158, 113, 521, 286,   4],\n",
            "       [  3,  19, 662, 663, 288, 664,   4],\n",
            "       [  3, 440, 643,  79, 173, 134,   4],\n",
            "       [  3, 427,   7, 192,  75, 147,   4]], dtype=int32)>, <tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
            "array([[  3, 281,  28,  92, 477,  41,   0],\n",
            "       [  3, 210, 788,  35,  18,  20,   0],\n",
            "       [  3, 380, 532,  21, 161,  63,   0],\n",
            "       [  3, 354,  14,  23, 223, 466,   0],\n",
            "       [  3,  23,  45,  17, 196, 305,   0],\n",
            "       [  3,  15, 196, 634, 218,  62,   0],\n",
            "       [  3, 130,  50, 544,  27,  49,   0],\n",
            "       [  3,   7,  91,   5,   7,  41,   0],\n",
            "       [  3, 485, 486, 155,  94, 144,   0],\n",
            "       [  3,  36,  70,  13, 114, 277,   0],\n",
            "       [  3, 526, 527,  14, 528,  27,   0],\n",
            "       [  3, 564, 134,  11,  30,   9,   0],\n",
            "       [  3, 210, 788,  35, 961, 507,   0],\n",
            "       [  3,  12,  10,   5,   7,  42,   0],\n",
            "       [  3,   7,  13,  36, 103,  42,   0],\n",
            "       [  3,  23,   5,  22, 291, 542,   0],\n",
            "       [  3,  29, 127,  43, 235, 518,   0],\n",
            "       [  3,  26,  51,  97, 141,   5,   0],\n",
            "       [  3, 121, 594, 202,  35,  18,   0],\n",
            "       [  3, 892, 893, 222, 610, 319,   0],\n",
            "       [  3, 141,   6, 402, 205, 142,   0],\n",
            "       [  3, 677, 678, 300,  30, 679,   0],\n",
            "       [  3,  32,  10,   9,  26, 399,   0],\n",
            "       [  3,  90, 177,  96,  90,  38,   0],\n",
            "       [  3, 209, 388, 613,  26,  31,   0],\n",
            "       [  3, 508, 125,   7, 209, 783,   0],\n",
            "       [  3, 279, 144, 164, 179, 506,   0],\n",
            "       [  3,  39,  58,  57,  85, 191,   0],\n",
            "       [  3, 237, 238,  26, 287, 522,   0],\n",
            "       [  3, 119, 665, 108,  78, 319,   0],\n",
            "       [  3, 337, 338,  28, 215, 107,   0],\n",
            "       [  3,  29, 428, 111,  77,   5,   0]], dtype=int32)>)\n",
            "tf.Tensor(\n",
            "[[ 69 246 986 217 509   4   0]\n",
            " [ 21 688 216 294 195   4   0]\n",
            " [ 22  16  24  22  54   4   0]\n",
            " [649 176 102 333 134   4   0]\n",
            " [369 369 342  94 160   4   0]\n",
            " [  8   5  22 106  81   4   0]\n",
            " [ 29 107  72  79  77   4   0]\n",
            " [ 66 139 312 312  34   4   0]\n",
            " [184 365 366 367 780   4   0]\n",
            " [933 934 359 380 789   4   0]\n",
            " [120 275  85 205 105   4   0]\n",
            " [579 119 136 137 250   4   0]\n",
            " [978 979  34 792 496   4   0]\n",
            " [840 609  60 841 842   4   0]\n",
            " [693 373  24 693 159   4   0]\n",
            " [568 569 247   6 118   4   0]\n",
            " [ 15 335 652 328 331   4   0]\n",
            " [ 32  10 601 316  74   4   0]\n",
            " [102 640 206 641 264   4   0]\n",
            " [  5 674 104 675  31   4   0]\n",
            " [ 48 734  95 109 157   4   0]\n",
            " [ 70  74 559 296 297   4   0]\n",
            " [ 60 249  21 165  25   4   0]\n",
            " [ 15  17   6 305 165   4   0]\n",
            " [151 339 332 212 645   4   0]\n",
            " [761 762 503 197 504   4   0]\n",
            " [  5  91  40   7  41   4   0]\n",
            " [ 19 106  78  93 628   4   0]\n",
            " [200 401  35 107 381   4   0]\n",
            " [ 40  26 167 149  76   4   0]\n",
            " [ 98 172  31 360  74   4   0]], shape=(31, 7), dtype=int32)\n",
            "(<tf.Tensor: shape=(31, 7), dtype=int32, numpy=\n",
            "array([[  3, 506, 985,  94, 503, 362,   4],\n",
            "       [  3,  40, 221,  68,  46, 142,   4],\n",
            "       [  3, 122,  73, 680, 299, 681,   4],\n",
            "       [  3,  30, 647, 340, 648, 181,   4],\n",
            "       [  3,  69, 246, 986, 217, 509,   4],\n",
            "       [  3, 247, 881,  54, 167,  86,   4],\n",
            "       [  3,   7,  13,  36, 103,  42,   4],\n",
            "       [  3, 589, 590, 138, 591, 104,   4],\n",
            "       [  3, 184, 365, 366, 367, 278,   4],\n",
            "       [  3,  10, 245,  21, 932, 126,   4],\n",
            "       [  3,   5, 347, 676,  14, 171,   4],\n",
            "       [  3, 188, 577, 392, 199, 578,   4],\n",
            "       [  3,  89, 976, 977, 182, 495,   4],\n",
            "       [  3, 414,  12,  51, 838, 839,   4],\n",
            "       [  3, 133,  21, 449,  39, 194,   4],\n",
            "       [  3,  60, 103, 566, 304, 567,   4],\n",
            "       [  3, 208, 219, 441, 181, 150,   4],\n",
            "       [  3,  32,  10,   9, 599, 600,   4],\n",
            "       [  3, 335, 219,  30, 639, 152,   4],\n",
            "       [  3, 100, 315,  24,  93, 183,   4],\n",
            "       [  3,  31,  91,  39, 118,  69,   4],\n",
            "       [  3, 194, 295, 387, 388, 558,   4],\n",
            "       [  3, 167,   5,  56, 391, 297,   4],\n",
            "       [  3, 568, 569, 247,   6, 118,   4],\n",
            "       [  3, 260, 419, 102, 644, 198,   4],\n",
            "       [  3, 156, 401, 760, 501, 502,   4],\n",
            "       [  3,   8, 265, 266,  22,  23,   4],\n",
            "       [  3,  67, 119, 330, 217, 174,   4],\n",
            "       [  3,  14, 162, 107, 318, 807,   4],\n",
            "       [  3,   8, 249, 167, 668, 669,   4],\n",
            "       [  3, 777, 778, 779,  39,  58,   4]], dtype=int32)>, <tf.Tensor: shape=(31, 7), dtype=int32, numpy=\n",
            "array([[  3,  69, 246, 986, 217, 509,   0],\n",
            "       [  3,  21, 688, 216, 294, 195,   0],\n",
            "       [  3,  22,  16,  24,  22,  54,   0],\n",
            "       [  3, 649, 176, 102, 333, 134,   0],\n",
            "       [  3, 369, 369, 342,  94, 160,   0],\n",
            "       [  3,   8,   5,  22, 106,  81,   0],\n",
            "       [  3,  29, 107,  72,  79,  77,   0],\n",
            "       [  3,  66, 139, 312, 312,  34,   0],\n",
            "       [  3, 184, 365, 366, 367, 780,   0],\n",
            "       [  3, 933, 934, 359, 380, 789,   0],\n",
            "       [  3, 120, 275,  85, 205, 105,   0],\n",
            "       [  3, 579, 119, 136, 137, 250,   0],\n",
            "       [  3, 978, 979,  34, 792, 496,   0],\n",
            "       [  3, 840, 609,  60, 841, 842,   0],\n",
            "       [  3, 693, 373,  24, 693, 159,   0],\n",
            "       [  3, 568, 569, 247,   6, 118,   0],\n",
            "       [  3,  15, 335, 652, 328, 331,   0],\n",
            "       [  3,  32,  10, 601, 316,  74,   0],\n",
            "       [  3, 102, 640, 206, 641, 264,   0],\n",
            "       [  3,   5, 674, 104, 675,  31,   0],\n",
            "       [  3,  48, 734,  95, 109, 157,   0],\n",
            "       [  3,  70,  74, 559, 296, 297,   0],\n",
            "       [  3,  60, 249,  21, 165,  25,   0],\n",
            "       [  3,  15,  17,   6, 305, 165,   0],\n",
            "       [  3, 151, 339, 332, 212, 645,   0],\n",
            "       [  3, 761, 762, 503, 197, 504,   0],\n",
            "       [  3,   5,  91,  40,   7,  41,   0],\n",
            "       [  3,  19, 106,  78,  93, 628,   0],\n",
            "       [  3, 200, 401,  35, 107, 381,   0],\n",
            "       [  3,  40,  26, 167, 149,  76,   0],\n",
            "       [  3,  98, 172,  31, 360,  74,   0]], dtype=int32)>)\n"
          ]
        }
      ],
      "source": [
        "for i, j in train_ds:\n",
        "    print(j)\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jng2_x5lseWE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xArxZkMrseWE"
      },
      "source": [
        "## Nháp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TnBH21UdseWE",
        "outputId": "65b9067a-d2c0-4b60-ca27-c8e52aa2dc8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[  2 713 177  79 515]\n",
            " [  2   8 209 232 522]\n",
            " [  2  11  10   4   6]\n",
            " ...\n",
            " [  2  98 161  30 324]\n",
            " [  2 284  60  66 210]\n",
            " [  2 169 325 369 343]], shape=(776, 5), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[  2 713 177  79 515]\n",
            " [  2   8 209 232 522]\n",
            " [  2  11  10   4   6]\n",
            " ...\n",
            " [  2  98 161  30 324]\n",
            " [  2 284  60  66 210]\n",
            " [  2 169 325 369 343]], shape=(776, 5), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "maxlen = 5\n",
        "vocab_size = VOCAB_SIZE = 5000\n",
        "\n",
        "\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    # standardize=text_normalize,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=maxlen,\n",
        ")\n",
        "vectorize_layer.adapt(corpus)\n",
        "vectorized_sequences = vectorize_layer(X)\n",
        "print(vectorized_sequences)\n",
        "vectorized_sequences = vectorize_layer(X)\n",
        "print(vectorized_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvSD70OWseWE",
        "outputId": "62a7e737-9986-4ffc-9658-169a04bce582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[205 916 380 282 718]\n",
            " [205 211 412 435 725]\n",
            " [205 214 213 207 209]\n",
            " ...\n",
            " [205 301 364 233 527]\n",
            " [205 487 263 269 413]\n",
            " [205 372 528 572 546]]\n"
          ]
        }
      ],
      "source": [
        "START_TOKEN = 101\n",
        "END_TOKEN = 102\n",
        "\n",
        "# Thêm các token đặc biệt vào đầu và cuối mỗi chuỗi\n",
        "sequences_with_special_tokens = [\n",
        "    [START_TOKEN] + seq + [END_TOKEN]\n",
        "    for seq in vectorized_sequences\n",
        "]\n",
        "\n",
        "# Thêm padding vào dữ liệu token\n",
        "padded_sequences = pad_sequences(sequences_with_special_tokens, padding='post', value=0)\n",
        "\n",
        "print(padded_sequences)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UPNV2EeseWF"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HBDHa93seWF"
      },
      "source": [
        "## Learned Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxLK54mBseWF"
      },
      "outputs": [],
      "source": [
        "class LearnedPositionalEmbedding(Layer):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super().__init__()\n",
        "        self.token_embedding = Embedding(vocab_size, d_model, mask_zero=True)\n",
        "        self.pos_embedding = Embedding(vocab_size, d_model, mask_zero=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        x = self.token_embedding(x)\n",
        "        pos = self.pos_embedding(positions)\n",
        "        x = x + pos\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0IdvgEDseWF"
      },
      "source": [
        "#### Nháp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TITF8182seWF"
      },
      "outputs": [],
      "source": [
        "token_embedding = Embedding(200, 5, mask_zero=True)\n",
        "pos_embedding = Embedding(4, 5, mask_zero=True)\n",
        "\n",
        "\n",
        "\n",
        "arr = np.array([[2, 43, 64, 2, 0], [2, 43, 64, 2, 0]])\n",
        "arr = tf.convert_to_tensor(arr)\n",
        "len = tf.shape(arr)[-1]\n",
        "# positions = tf.range(start=0, limit=len, delta=1)\n",
        "# pos_embedding(positions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ISpUqrbseWF",
        "outputId": "2ee62ca5-8076-480d-d977-a8af3cd9c652"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 5, 4), dtype=float32, numpy=\n",
              "array([[[ 0.03791033,  0.07307654,  0.00085772, -0.04303437],\n",
              "        [-0.03054502,  0.01317374,  0.02801207,  0.0688414 ],\n",
              "        [ 0.0350856 , -0.01020268, -0.03094573,  0.08283221],\n",
              "        [ 0.05233429,  0.01663573, -0.01136755,  0.03040729],\n",
              "        [ 0.00346883,  0.04577436, -0.01387558, -0.06228261]],\n",
              "\n",
              "       [[ 0.03791033,  0.07307654,  0.00085772, -0.04303437],\n",
              "        [-0.03054502,  0.01317374,  0.02801207,  0.0688414 ],\n",
              "        [ 0.0350856 , -0.01020268, -0.03094573,  0.08283221],\n",
              "        [ 0.05233429,  0.01663573, -0.01136755,  0.03040729],\n",
              "        [ 0.00346883,  0.04577436, -0.01387558, -0.06228261]]],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layer = LearnedPositionalEmbedding(100, 4)\n",
        "layer(arr.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSBg0mR9seWF"
      },
      "source": [
        "## Sinusoidal Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Th4NsPDEseWF"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(length, depth):\n",
        "    depth = depth/2\n",
        "\n",
        "    positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "    depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
        "\n",
        "    angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "    angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "    pos_encoding = np.concatenate(\n",
        "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "        axis=-1)\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "class SinusoidalPositionalEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
        "\n",
        "    def compute_mask(self, *args, **kwargs):\n",
        "        return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "    def call(self, x):\n",
        "        length = tf.shape(x)[1]\n",
        "        x = self.embedding(x)\n",
        "        # This factor sets the relative scale of the embedding and positonal_encoding.\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class SinusoidalPositionalEmbedding(Layer):\n",
        "#     def __init__(self, *, vocab_size, d_model):\n",
        "#         super().__init__()\n",
        "#         if vocab_size is None:\n",
        "#             input_shape = d_model\n",
        "#         else:\n",
        "#             input_shape = vocab_size\n",
        "\n",
        "#         self.d_model = d_model\n",
        "\n",
        "#         # Compute the positional encodings once in the constructor.\n",
        "#         position = tf.range(input_shape)[:, tf.newaxis]\n",
        "#         div_term = tf.exp(tf.range(0, d_model, 2) * -(tf.math.log(10000.0) / d_model))\n",
        "#         pe = tf.zeros(shape=(input_shape, d_model))\n",
        "#         pe[:, 0::2] = tf.sin(position * div_term)\n",
        "#         pe[:, 1::2] = tf.cos(position * div_term)\n",
        "#         self.pos_encoding = pe[tf.newaxis, :, :]\n",
        "\n",
        "#     def call(self, x):\n",
        "#         # Since the dimensions of x and pos_encoding may differ,\n",
        "#         # we pad the pos_encoding to match the length of x\n",
        "#         length = tf.shape(x)[1]\n",
        "#         x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "#         padded_pos_encoding = tf.pad(self.pos_encoding, [[0, 0], [0, length-tf.shape(self.pos_encoding)[1]], [0, 0]])\n",
        "#         x = x + padded_pos_encoding[:, :length, :]\n",
        "#         return x"
      ],
      "metadata": {
        "id": "WEXg8kuUt0U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2BRnKVYseWF"
      },
      "source": [
        "#### Nháp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lDFE0LXseWF",
        "outputId": "1f5fa75f-ea54-4601-d38f-d336d1b3a708"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 5, 4), dtype=float32, numpy=\n",
              "array([[[ 0.01254196,  0.02091851,  1.0011637 ,  1.0328945 ],\n",
              "        [ 0.86834276, -0.0498974 ,  0.46717137,  1.0835687 ],\n",
              "        [ 0.9615055 ,  0.11208229, -0.39046505,  0.9692169 ],\n",
              "        [ 0.15366197,  0.05091401, -0.98882884,  1.0324446 ],\n",
              "        [-0.6814366 ,  0.02076598, -0.6144975 ,  1.0163382 ]],\n",
              "\n",
              "       [[ 0.01254196,  0.02091851,  1.0011637 ,  1.0328945 ],\n",
              "        [ 0.86834276, -0.0498974 ,  0.46717137,  1.0835687 ],\n",
              "        [ 0.9615055 ,  0.11208229, -0.39046505,  0.9692169 ],\n",
              "        [ 0.15366197,  0.05091401, -0.98882884,  1.0324446 ],\n",
              "        [-0.6814366 ,  0.02076598, -0.6144975 ,  1.0163382 ]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "l = SinusoidalPositionalEmbedding(100, 4)\n",
        "arr = np.array([[2, 43, 64, 2, 0], [2, 43, 64, 2, 0]])\n",
        "arr = tf.convert_to_tensor(arr)\n",
        "l(arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mUVknp7seWF"
      },
      "source": [
        "## Base Self-attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIerhh9useWG"
      },
      "outputs": [],
      "source": [
        "class BaseAttention(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        self.multihead = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "        self.add = tf.keras.layers.Add()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIDdVL9YseWG"
      },
      "source": [
        "## Cross-attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9v-Wlyb3seWG"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(BaseAttention):\n",
        "    def call(self, x, context):\n",
        "        out_put, scores = self.multihead(\n",
        "            query=x,\n",
        "            value=context,\n",
        "            key=context,\n",
        "            return_attention_scores=True)\n",
        "\n",
        "        self.attention_scores = scores\n",
        "\n",
        "        x = self.add([x, out_put])\n",
        "        return self.layernorm(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlKV63cYseWG"
      },
      "source": [
        "#### Nháp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAmvqdicseWG",
        "outputId": "28afd0fc-7280-447a-a180-c86b218cceaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0.21232034 0.18255974 0.21485221 0.1788626  0.21140505]\n",
            "   [0.073286   0.14252862 0.3329414  0.11701349 0.3342305 ]\n",
            "   [0.23401469 0.22498412 0.14746809 0.24371831 0.14981481]\n",
            "   [0.36998218 0.1875155  0.11549442 0.21384495 0.11316297]\n",
            "   [0.20887628 0.2212073  0.1677036  0.23190716 0.17030561]]\n",
            "\n",
            "  [[0.17774892 0.31501913 0.1490758  0.10378786 0.25436828]\n",
            "   [0.2447398  0.1718101  0.13147347 0.27369794 0.17827867]\n",
            "   [0.24135087 0.10497415 0.12549293 0.40093675 0.12724534]\n",
            "   [0.16262043 0.28726637 0.19932269 0.10679477 0.24399574]\n",
            "   [0.21678881 0.12738472 0.18353868 0.32344913 0.1488387 ]]]], shape=(1, 2, 5, 5), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of CrossAttention\n",
        "test_scores = CrossAttention(\n",
        "    num_heads=2,\n",
        "    key_dim=4 // 2,\n",
        "    value_dim=4 // 2,\n",
        ")\n",
        "\n",
        "# Call the call method to compute attention and store the scores\n",
        "output = test_scores(v, v)\n",
        "\n",
        "# Access the attention_scores from the instance\n",
        "scores = test_scores.attention_scores\n",
        "\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzn9_AarseWG"
      },
      "source": [
        "## Causal Self-attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQLQSNRYseWG"
      },
      "outputs": [],
      "source": [
        "class CausalSelfAttention(BaseAttention):\n",
        "    def call(self, x):\n",
        "        attention = self.multihead(\n",
        "            query=x,\n",
        "            value=x,\n",
        "            key=x,\n",
        "            use_causal_mask=True\n",
        "        )\n",
        "        out_put = self.add([attention, x])\n",
        "        return self.layernorm(out_put)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR4mjl3dseWG"
      },
      "source": [
        "#### Nháp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDs8rFzkseWG"
      },
      "outputs": [],
      "source": [
        "# def create_causal_mask(size):\n",
        "#   \"\"\"Tạo causal mask cho self-attention.\"\"\"\n",
        "#   mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "#   return mask  * -1e9\n",
        "\n",
        "\n",
        "# attention_scores = ...\n",
        "# mask = create_causal_mask(tf.shape(attention_scores)[1])\n",
        "# masked_attention_scores = attention_scores + mask\n",
        "# attention_probs = tf.nn.softmax(masked_attention_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PklIFKvkseWG",
        "outputId": "e6fb6087-9661-4a54-aa10-db7dc4fcad8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[-0.00839665  0.12513153 -1.0209956   0.28299028]\n",
            "  [-1.8376423   1.1970675  -0.4849051   0.39539403]\n",
            "  [-1.1354313   1.5976158  -1.320432    0.04959732]\n",
            "  [-1.5137734   0.03801779 -1.9150497  -1.8886613 ]\n",
            "  [ 1.7180611  -1.5693091   0.666355   -0.04582888]]], shape=(1, 5, 4), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "v = tf.convert_to_tensor(tf.random.normal((1, 5, 4)))\n",
        "print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLihWG4bseWH",
        "outputId": "93b564d1-01f6-471f-f3db-cd3db6381859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0.9753739  -0.08657703 -1.591531    0.7027341 ]\n",
            "  [-1.3977977   1.1972816  -0.44094604  0.641462  ]\n",
            "  [-0.03020522  1.332132   -1.4790007   0.1770738 ]\n",
            "  [ 1.1205184   0.86078894 -1.1203074  -0.8609998 ]\n",
            "  [ 1.4059865  -1.400532    0.17064978 -0.17610422]]], shape=(1, 5, 4), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "attention_layer = CausalSelfAttention(\n",
        "    num_heads=2,\n",
        "    key_dim=4 // 2,\n",
        "    value_dim=4 // 2,\n",
        ")\n",
        "l = attention_layer(v)\n",
        "print(l)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpLYNcScseWH"
      },
      "source": [
        "## Global Self-attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFjg6yy5seWH"
      },
      "outputs": [],
      "source": [
        "class GlobalSelfAttention(BaseAttention):\n",
        "    def call(self, context):\n",
        "        attention = self.multihead(\n",
        "            query=context,\n",
        "            value=context,\n",
        "            key=context\n",
        "        )\n",
        "        out_put = self.add([attention, context])\n",
        "        return self.layernorm(out_put)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFsC-GuKseWN"
      },
      "source": [
        "## Feed-forward Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHfBSirbseWN"
      },
      "outputs": [],
      "source": [
        "class Feedforward(Layer):\n",
        "    def __init__(self, ff_dim, d_model, drop_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.ffn = Sequential(\n",
        "            [Dense(ff_dim, activation=\"relu\"), Dense(d_model), Dropout(drop_rate)]\n",
        "        )\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "        self.add = tf.keras.layers.Add()\n",
        "\n",
        "    def call(self, input):\n",
        "        out_put = self.add([self.ffn(input), input])\n",
        "        return self.layernorm(out_put)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tWFSmyvseWN"
      },
      "source": [
        "## Encoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V0kdqWfseWN"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(Layer):\n",
        "    def __init__(self, *, num_heads, ff_dim, d_model, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attention = GlobalSelfAttention(\n",
        "            num_heads=num_heads,\n",
        "            key_dim=d_model,\n",
        "            dropout=dropout_rate\n",
        "        )\n",
        "        self.feedforward = Feedforward(ff_dim, d_model)\n",
        "\n",
        "    def call(self, context):\n",
        "        context = self.self_attention(context)\n",
        "        out_put = self.feedforward(context)\n",
        "        return out_put\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = tf.convert_to_tensor(tf.random.normal((1, 5, 4)))\n",
        "print(v)\n",
        "layr = EncoderLayer(num_heads=1, ff_dim=10, d_model=4)\n",
        "print(layr(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if1IfisXvlPf",
        "outputId": "19082440-7c1c-4bdb-b677-56ce0504f014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[-0.35975075  1.5145854   0.9998956  -0.83270323]\n",
            "  [ 0.10627941 -1.6242574   1.5322539  -0.63025033]\n",
            "  [ 0.17648193  0.19940554 -0.31985644  0.20605733]\n",
            "  [-0.38278538 -0.97199893 -0.33949786  1.0419519 ]\n",
            "  [-0.3706958  -0.9142048  -1.3064793   1.0371869 ]]], shape=(1, 5, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[-0.9575638   1.1686676   0.81380004 -1.0249038 ]\n",
            "  [ 0.87742674 -1.505466    0.9318919  -0.30385277]\n",
            "  [-0.7980474   0.9834731  -1.1825747   0.997149  ]\n",
            "  [-0.623034   -0.8598155  -0.19949678  1.682346  ]\n",
            "  [-0.65428317 -0.26770228 -0.77862376  1.7006092 ]]], shape=(1, 5, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxSl8eqEseWN"
      },
      "source": [
        "## Transformer Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYos9mBfseWN"
      },
      "outputs": [],
      "source": [
        "class Encoder(Layer):\n",
        "    \"\"\"Đây là một mô tả ngắn gọn về lớp Decoder.\n",
        "\n",
        "    Args:\n",
        "        num_heads (int): Số lớp self head attention.\n",
        "        vocab_size (int): Kích thước của vocabulary thường là rất lớn.\n",
        "        num_layers (int): Số lượng lớp block encoder recomment = 6.\n",
        "        ff_dim (int): Kích thước lớp dense của feed forward layer.\n",
        "        d_model (int): Chiều sâu mô hình recomment = 128/258/512/1024.\n",
        "        dropout_rate (float): Tỉ lệ drop out. Mặc định là '0.1'.\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, *, num_heads, vocab_size, num_layers, ff_dim, d_model, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.pos_embedding =  SinusoidalPositionalEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
        "        self.N_layers = [EncoderLayer(\n",
        "                        num_heads=num_heads,\n",
        "                        ff_dim=ff_dim,\n",
        "                        d_model=d_model,\n",
        "                        dropout_rate=dropout_rate,)\n",
        "                        for _ in range(num_layers)]\n",
        "        self.drop_out = Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, context):\n",
        "        context = self.pos_embedding(context)\n",
        "        context = self.drop_out(context)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            context = self.N_layers[i](context)\n",
        "        return context\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = tf.convert_to_tensor(tf.random.normal((1, 5)))\n",
        "print(v)\n",
        "layr = Encoder(num_heads=1, vocab_size=1000, num_layers=1, ff_dim=10, d_model=4)\n",
        "print(layr(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tELtkmqvv9U",
        "outputId": "4d686f88-198d-4bdc-f4b4-1330f8792d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[-0.8340743  -1.0207756  -0.6342568   0.51541275 -0.590669  ]], shape=(1, 5), dtype=float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_10' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_14' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feedforward_14' (of type Feedforward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[-1.0980461  -0.8851868   1.1305602   0.8526729 ]\n",
            "  [ 0.35225743 -1.5044429  -0.1108938   1.2630793 ]\n",
            "  [ 0.9008785  -0.8463565  -1.1379528   1.0834308 ]\n",
            "  [ 0.30503353 -0.6424315  -1.1410583   1.4784561 ]\n",
            "  [-1.3623192   0.12716724 -0.20563602  1.440788  ]]], shape=(1, 5, 4), dtype=float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_10' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TccndnlwseWO"
      },
      "source": [
        "#### Nháp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjVLrWgJseWO",
        "outputId": "9848186d-a120-46ab-b5dd-cd1786521b48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[-0.00355456  0.77798814 -0.20170389 -0.8216381  -0.30207   ]], shape=(1, 5), dtype=float32)\n",
            "tf.Tensor([[-0.00355456  0.77798814 -0.20170389 -0.8216381  -0.30207   ]], shape=(1, 5), dtype=float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_11' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_15' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feedforward_15' (of type Feedforward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_11' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 5, 4), dtype=float32, numpy=\n",
              "array([[[-0.7767646 , -1.1273553 ,  1.3452914 ,  0.5588286 ],\n",
              "        [ 0.3299836 , -1.4364252 ,  1.331079  , -0.22463721],\n",
              "        [ 1.4121897 , -1.3774781 , -0.2432982 ,  0.20858648],\n",
              "        [ 1.1737955 , -1.2382491 , -0.7037501 ,  0.7682036 ],\n",
              "        [ 0.52280104, -1.4083366 , -0.3780914 ,  1.2636268 ]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "v = tf.convert_to_tensor(tf.random.normal((1, 5)))\n",
        "print(v)\n",
        "layr = Encoder(num_heads=1, vocab_size=1000, num_layers=1, ff_dim=10, d_model=4)\n",
        "print(v)\n",
        "layr(v)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76sqwsQWseWO"
      },
      "source": [
        "<!-- ## Decoder Layer -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKazOrFIseWO"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(Layer):\n",
        "    def __init__(self, *,num_heads, d_model, ff_dim, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mask_self_attention = CausalSelfAttention(\n",
        "            num_heads=num_heads,\n",
        "            key_dim=d_model,\n",
        "            dropout=dropout_rate,)\n",
        "\n",
        "        self.cross_attention = CrossAttention(\n",
        "            num_heads=num_heads,\n",
        "            key_dim=d_model,\n",
        "            dropout=dropout_rate,)\n",
        "        self.feed_forward = Feedforward(ff_dim, d_model)\n",
        "\n",
        "    def call(self, x, context):\n",
        "        x = self.mask_self_attention(x=x)\n",
        "        out_put1 = self.cross_attention(x, context=context)\n",
        "\n",
        "        # Cache the last attention scores for plotting later\n",
        "        self.attention_scores = self.cross_attention.attention_scores\n",
        "        out_put2 = self.feed_forward(out_put1)\n",
        "\n",
        "        return out_put2 # Shape (batch_size, seq_len, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O5TBc9XseWO"
      },
      "source": [
        "## Transformer Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzbUnOB9seWO"
      },
      "outputs": [],
      "source": [
        "class Decoder(Layer):\n",
        "    \"\"\"Đây là một mô tả ngắn gọn về lớp Decoder.\n",
        "\n",
        "    Args:\n",
        "        num_heads (int): Số lớp self head attention.\n",
        "        vocab_size (int): Kích thước của vocabulary thường là rất lớn.\n",
        "        num_layers (int): Số lượng lớp block decoder recomment = 6.\n",
        "        ff_dim (int): Kích thước lớp dense của feed forward layer.\n",
        "        d_model (int): Chiều sâu mô hình recomment = 128/258/512/1024.\n",
        "        dropout_rate (float): Tỉ lệ drop out. Mặc định là '0.1'.\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *, num_heads, vocab_size, num_layers, ff_dim, d_model, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.pos_embedding =  SinusoidalPositionalEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
        "        self.N_layers = [\n",
        "            DecoderLayer(num_heads=num_heads,\n",
        "                        ff_dim=ff_dim,\n",
        "                        d_model=d_model,\n",
        "                        dropout_rate=dropout_rate,)\n",
        "            for _ in range(num_layers)]\n",
        "        self.drop_out = Dropout(dropout_rate)\n",
        "\n",
        "        self.attention_scores = None\n",
        "\n",
        "    def call(self, x, context):\n",
        "        x = self.pos_embedding(x)\n",
        "        x = self.drop_out(x)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            y = self.N_layers[i](x, context)\n",
        "\n",
        "        self.attention_scores = self.N_layers[-1].attention_scores\n",
        "\n",
        "        # The shape of x is (batch_size, target_seq_len, d_model).\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-81XsGwseWP"
      },
      "source": [
        "## Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcdaMKPsseWP"
      },
      "outputs": [],
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, *, num_layers, d_model, num_heads, ff_dim,\n",
        "                vocab_size, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_heads=num_heads,\n",
        "                               d_model=d_model,\n",
        "                               vocab_size=vocab_size,\n",
        "                               ff_dim=ff_dim,\n",
        "                               num_layers=num_layers,\n",
        "                               dropout_rate=dropout_rate,)\n",
        "\n",
        "        self.decoder = Decoder(num_heads=num_heads,\n",
        "                               d_model=d_model,\n",
        "                               vocab_size=vocab_size,\n",
        "                               ff_dim=ff_dim,\n",
        "                               num_layers=num_layers,\n",
        "                               dropout_rate=dropout_rate,)\n",
        "\n",
        "        self.final_layer = Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        context, x  = inputs\n",
        "\n",
        "        context = self.encoder(context)\n",
        "        x = self.decoder(x, context)\n",
        "\n",
        "        logits = self.final_layer(x)\n",
        "\n",
        "        try:\n",
        "            # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
        "            # b/250038731\n",
        "            del logits._keras_mask\n",
        "        except AttributeError:\n",
        "            pass\n",
        "\n",
        "        # Return the final output and the attention weights.\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQ6Py9NIseWP"
      },
      "outputs": [],
      "source": [
        "N_LAYERS = 4\n",
        "D_MODEL = 128\n",
        "D_FF = 512\n",
        "N_HEADS = 8\n",
        "DROPOUT_RATE = 0.2\n",
        "transformer = Transformer(\n",
        "    num_layers=N_LAYERS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=N_HEADS,\n",
        "    ff_dim=D_FF,\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    dropout_rate=DROPOUT_RATE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E75vaWZseWP"
      },
      "outputs": [],
      "source": [
        "batches = train_ds.take(2)\n",
        "for batch in batches:\n",
        "    X_try, y_try = batch[0], batch[1]\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJqVBILTseWQ",
        "outputId": "55dd426b-361f-4b10-eac4-47c1895f6b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_12' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_16' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feedforward_16' (of type Feedforward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_12' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_13' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_17' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feedforward_17' (of type Feedforward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_13' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_14' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_18' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feedforward_18' (of type Feedforward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_14' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_15' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_19' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feedforward_19' (of type Feedforward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_15' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_5' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_4' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_20' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feedforward_20' (of type Feedforward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_4' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_6' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_5' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_21' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feedforward_21' (of type Feedforward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_5' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_7' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_6' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_22' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feedforward_22' (of type Feedforward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_6' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_8' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_7' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_23' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feedforward_23' (of type Feedforward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_7' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([32, 7, 5000])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "output = transformer(X_try)\n",
        "output.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "XqKwkHtOseWQ",
        "outputId": "e664d7fd-49ce-45a6-f7ac-0c964ab8209d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"transformer_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_10 (\u001b[38;5;33mEncoder\u001b[0m)                 │ ?                           │       \u001b[38;5;34m3,278,848\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder_1 (\u001b[38;5;33mDecoder\u001b[0m)                  │ ?                           │       \u001b[38;5;34m5,389,824\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m5000\u001b[0m)               │         \u001b[38;5;34m645,000\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)                 │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,278,848</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)                  │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,389,824</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">645,000</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,313,672\u001b[0m (35.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,313,672</span> (35.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,313,672\u001b[0m (35.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,313,672</span> (35.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG34hwHhseWQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siWs_BEsseWR"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, dtype=tf.float32)\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-foNvyjseWR"
      },
      "outputs": [],
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.98,\n",
        "    epsilon=1e-9\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uc-UZnIbseWR"
      },
      "outputs": [],
      "source": [
        "def masked_loss(label, pred):\n",
        "    mask = label != 0\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_object(label, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "    pred = tf.argmax(pred, axis=2)\n",
        "    label = tf.cast(label, pred.dtype)\n",
        "    match = label == pred\n",
        "\n",
        "    mask = label != 0\n",
        "\n",
        "    match = match & mask\n",
        "\n",
        "    match = tf.cast(match, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "\n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)\n",
        "\n",
        "def compute_perplexity(logits, targets):\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "\n",
        "    loss = loss_fn(targets, logits)\n",
        "\n",
        "    perplexity = np.exp(np.mean(loss))\n",
        "\n",
        "    return perplexity\n",
        "\n",
        "\n",
        "def compute_bleu(predicted, targets):\n",
        "    predicted_strings = []\n",
        "    for seq in predicted:\n",
        "        seq = np.argmax(seq, axis=1)\n",
        "        string_seq = \" \".join([tokenizer.sequences_to_texts([[token]])[0] for token in seq if token != 0])\n",
        "        predicted_strings.append(string_seq)\n",
        "    target_strings = []\n",
        "    for seq in targets:\n",
        "        seq = seq.numpy().tolist()\n",
        "        string_seq = \" \".join([tokenizer.sequences_to_texts([[token]])[0] for token in seq if token != 0])\n",
        "        target_strings.append([string_seq])\n",
        "\n",
        "    bleu_score = corpus_bleu(target_strings, predicted_strings)\n",
        "\n",
        "    return bleu_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyAziz7rseWS"
      },
      "outputs": [],
      "source": [
        "# Khai báo một số giá trị siêu tham số\n",
        "EPOCHS = 10\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqPJCDxNseWS"
      },
      "outputs": [],
      "source": [
        "transformer.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[masked_accuracy]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNEbbVasseWS",
        "outputId": "48a48575-15e9-4691-b4de-0dde45286b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - loss: 1.1883 - masked_accuracy: 0.9231 - val_loss: 4.0887 - val_masked_accuracy: 0.5374\n",
            "Epoch 2/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - loss: 1.0649 - masked_accuracy: 0.9378 - val_loss: 3.9936 - val_masked_accuracy: 0.5559\n",
            "Epoch 3/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.9537 - masked_accuracy: 0.9436 - val_loss: 3.9621 - val_masked_accuracy: 0.5643\n",
            "Epoch 4/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8560 - masked_accuracy: 0.9570 - val_loss: 3.9218 - val_masked_accuracy: 0.5702\n",
            "Epoch 5/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.7478 - masked_accuracy: 0.9604 - val_loss: 3.8439 - val_masked_accuracy: 0.5812\n",
            "Epoch 6/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6590 - masked_accuracy: 0.9693 - val_loss: 3.8347 - val_masked_accuracy: 0.5911\n",
            "Epoch 7/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5835 - masked_accuracy: 0.9793 - val_loss: 3.8302 - val_masked_accuracy: 0.5972\n",
            "Epoch 8/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5184 - masked_accuracy: 0.9778 - val_loss: 3.8050 - val_masked_accuracy: 0.6003\n",
            "Epoch 9/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4659 - masked_accuracy: 0.9849 - val_loss: 3.7632 - val_masked_accuracy: 0.5984\n",
            "Epoch 10/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4116 - masked_accuracy: 0.9872 - val_loss: 3.7559 - val_masked_accuracy: 0.6005\n"
          ]
        }
      ],
      "source": [
        "history = transformer.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_ds\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abysm8EAseWT",
        "outputId": "f6ffd678-be6d-496c-bd2f-abd80ffcdcf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - loss: 3.4903 - masked_accuracy: 0.6230\n"
          ]
        }
      ],
      "source": [
        "# Đánh giá mô hình trên tập test\n",
        "test_evaluation = transformer.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "t41lHrx4seWT",
        "outputId": "3e3dbe23-63a8-49ac-d0d8-ae99a589994d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAANXCAYAAADZwqXwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd1xW5f/H8dfNxgEuBEVy5cgFTnKUC8WZmpWmhWGamlZG/fpKmpYNGmaZmpq5clKKNlRMcZLmxpEjzYEL1EpQFBDu+/cHdRcJTuDcwPv5eJxHh4vrnPt9TnofP/d17uuYLBaLBREREREREbkndkYHEBERERERKQhUXImIiIiIiOQAFVciIiIiIiI5QMWViIiIiIhIDlBxJSIiIiIikgNUXImIiIiIiOQAFVciIiIiIiI5QMWViIiIiIhIDlBxJSIiIiIikgNUXInksWeeeYZKlSrd1bZvvvkmJpMpZwPdpnvJLSIiOSO/XkNECgsVVyJ/MZlMt7WsX7/e6KgiImJjdA0REQCTxWKxGB1CxBbMmzcv089fffUVq1evZu7cuZna27Vrh6en512/zvXr1zGbzTg7O9/xtmlpaaSlpeHi4nLXr3+3nnnmGdavX8+JEyfy/LVFRGydriEiAiquRLI1bNgwJk+ezK3+ily9epUiRYrkUSrjqLgSEbl9uobkXxaLheTkZFxdXY2OIvmQbgsUuQOtWrWiTp067Ny5k4cffpgiRYrw+uuvA/Dtt9/SuXNnypcvj7OzM1WrVuXtt98mPT090z7+e7/8iRMnMJlMjBs3ji+++IKqVavi7OxM48aN2b59e6Zts7pf3mQyMWzYMJYtW0adOnVwdnamdu3aREZG3pB//fr1NGrUCBcXF6pWrcq0adPu6R78pKQkXnnlFXx8fHB2dqZGjRqMGzfuhn9MrF69mhYtWlCiRAmKFStGjRo1rOftbxMnTqR27doUKVKEkiVL0qhRIxYsWHBXuUREbFFhvoZs2rSJxx9/nPvuuw9nZ2d8fHx4+eWXuXbt2g19Dx06xBNPPIGHhweurq7UqFGDkSNHZupz5swZnn32Wev5qly5MkOGDCE1NTXbYwWYPXs2JpMp0weFlSpVokuXLqxatYpGjRrh6urKtGnTAJg1axZt2rShbNmyODs7U6tWLaZMmZLlMa5cuZKWLVtSvHhx3NzcaNy4sfU6NmbMGBwdHblw4cIN2z333HOUKFGC5OTkW55HsX0ORgcQyW9+//13OnbsSO/evXnqqaest3fMnj2bYsWKERISQrFixVi7di2jR48mMTGRjz766Jb7XbBgAZcvX2bQoEGYTCY+/PBDHn30UY4dO4ajo+NNt42OjiYiIoLnn3+e4sWL89lnn9GzZ09iY2MpXbo0ALt376ZDhw6UK1eOt956i/T0dMaOHYuHh8ddnQeLxcIjjzzCunXrePbZZ/Hz82PVqlX83//9H2fOnOGTTz4B4JdffqFLly7Uq1ePsWPH4uzszNGjR/npp5+s+5o+fTovvvgijz32GC+99BLJycns3buXrVu30qdPn7vKJyJiiwrrNeSbb77h6tWrDBkyhNKlS7Nt2zYmTpzI6dOn+eabb6z99u7dy0MPPYSjoyPPPfcclSpV4rfffuP777/n3XffBeDs2bM0adKES5cu8dxzz1GzZk3OnDnD4sWLuXr1Kk5OTreV6d8OHz7Mk08+yaBBgxg4cCA1atQAYMqUKdSuXZtHHnkEBwcHvv/+e55//nnMZjNDhw61bj979mz69+9P7dq1CQ0NpUSJEuzevZvIyEj69OnD008/zdixYwkPD2fYsGHW7VJTU1m8eDE9e/bU7ZoFhUVEsjR06FDLf/+KtGzZ0gJYpk6dekP/q1ev3tA2aNAgS5EiRSzJycnWtn79+lkqVqxo/fn48eMWwFK6dGnLH3/8YW3/9ttvLYDl+++/t7aNGTPmhkyAxcnJyXL06FFr2549eyyAZeLEida2rl27WooUKWI5c+aMte3IkSMWBweHG/aZlf/mXrZsmQWwvPPOO5n6PfbYYxaTyWTN88knn1gAy4ULF7Ldd7du3Sy1a9e+ZQYRkfxC15BbH19YWJjFZDJZTp48aW17+OGHLcWLF8/UZrFYLGaz2boeFBRksbOzs2zfvv2Gff7dL6tjtVgsllmzZlkAy/Hjx61tFStWtACWyMjI28odGBhoqVKlivXnS5cuWYoXL27x9/e3XLt2LdvcTZs2tfj7+2f6fUREhAWwrFu37obXkfxJtwWK3CFnZ2eCg4NvaP/3vdmXL1/m4sWLPPTQQ1y9epVDhw7dcr+9evWiZMmS1p8feughAI4dO3bLbQMCAqhatar153r16uHm5mbdNj09nTVr1tC9e3fKly9v7Xf//ffTsWPHW+4/KytWrMDe3p4XX3wxU/srr7yCxWJh5cqVAJQoUQLIuOXFbDZnua8SJUpw+vTpG25hEREpaArrNeTfx5eUlMTFixdp1qwZFouF3bt3A3DhwgU2btxI//79ue+++zJt//ctfmazmWXLltG1a1caNWp0w+vc7W3ulStXJjAw8Ka5ExISuHjxIi1btuTYsWMkJCQAGbe+X758mREjRtww+vTvPEFBQWzdupXffvvN2jZ//nx8fHxo2bLlXeUW26PiSuQOeXt7Z3nLwS+//EKPHj1wd3fHzc0NDw8PnnrqKQDrG/DN/PdC8vdF8s8//7zjbf/e/u9tz58/z7Vr17j//vtv6JdV2+04efIk5cuXp3jx4pnaH3jgAevvIeOC37x5cwYMGICnpye9e/fm66+/zlRo/e9//6NYsWI0adKEatWqMXTo0Ey3DYqIFBSF9RoSGxvLM888Q6lSpShWrBgeHh7WguLv4/u7mKtTp062+7lw4QKJiYk37XM3KleunGX7Tz/9REBAAEWLFqVEiRJ4eHhYvyf3d+6/i6VbZerVqxfOzs7Mnz/fuv0PP/xA37599fyxAkTFlcgdymr2oEuXLtGyZUv27NnD2LFj+f7771m9ejUffPABQLYjNv9mb2+fZbvlNib0vJdtc5urqysbN25kzZo1PP300+zdu5devXrRrl076xe1H3jgAQ4fPsyiRYto0aIFS5YsoUWLFowZM8bg9CIiOaswXkPS09Np164dy5cv53//+x/Lli1j9erVzJ49G7i947tT2RUr/50g5G9Z/X/57bffaNu2LRcvXmT8+PEsX76c1atX8/LLLwN3nrtkyZJ06dLFWlwtXryYlJQUaxEtBYMmtBDJAevXr+f3338nIiKChx9+2Np+/PhxA1P9o2zZsri4uHD06NEbfpdV2+2oWLEia9as4fLly5lGr/6+faVixYrWNjs7O9q2bUvbtm0ZP3487733HiNHjmTdunUEBAQAULRoUXr16kWvXr1ITU3l0Ucf5d133yU0NFRf8hWRAq2gX0P27dvHr7/+ypw5cwgKCrK2r169OlO/KlWqALB///5s9+Xh4YGbm9tN+8A/I3eXLl2y3p4O/9xVcTu+//57UlJS+O677zKN7q1bty5Tv79vqdy/f/8tR/KCgoLo1q0b27dvZ/78+dSvX5/atWvfdiaxfRq5EskBf3/q9+9P+VJTU/n888+NipSJvb09AQEBLFu2jLNnz1rbjx49av1u1J3q1KkT6enpTJo0KVP7J598gslkst6H/8cff9ywrZ+fHwApKSlAxuxZ/+bk5EStWrWwWCxcv379rvKJiOQXBf0aktXxWSwWJkyYkKmfh4cHDz/8MDNnziQ2NjbT7/7e1s7Oju7du/P999+zY8eOG17r735/FzwbN260/i4pKYk5c+bcMu/NcickJDBr1qxM/dq3b0/x4sUJCwu7YTr1/47+dezYkTJlyvDBBx+wYcMGjVoVQBq5EskBzZo1o2TJkvTr148XX3wRk8nE3LlzbeK2vL+9+eab/PjjjzRv3pwhQ4ZYC6M6deoQExNzx/vr2rUrrVu3ZuTIkZw4cQJfX19+/PFHvv32W4YPH269sI0dO5aNGzfSuXNnKlasyPnz5/n888+pUKECLVq0ADIuTF5eXjRv3hxPT08OHjzIpEmT6Ny58w3f6RIRKWgK+jWkZs2aVK1alVdffZUzZ87g5ubGkiVLsvw+2GeffUaLFi1o0KABzz33HJUrV+bEiRMsX77c+jrvvfceP/74Iy1btuS5557jgQce4Ny5c3zzzTdER0dTokQJ2rdvz3333cezzz7L//3f/2Fvb8/MmTPx8PC4oXDLTvv27XFycqJr164MGjSIK1euMH36dMqWLcu5c+es/dzc3Pjkk08YMGAAjRs3pk+fPpQsWZI9e/Zw9erVTAWdo6MjvXv3ZtKkSdjb2/Pkk0/eVhbJP1RcieSA0qVL88MPP/DKK68watQoSpYsyVNPPUXbtm2znH3ICA0bNmTlypW8+uqrvPHGG/j4+DB27FgOHjx4WzNR/ZednR3fffcdo0ePJjw8nFmzZlGpUiU++ugjXnnlFWu/Rx55hBMnTjBz5kwuXrxImTJlaNmyJW+99Rbu7u4ADBo0iPnz5zN+/HiuXLlChQoVePHFFxk1alSOHb+IiK0q6NcQR0dHvv/+e1588UXCwsJwcXGhR48eDBs2DF9f30x9fX19+fnnn3njjTeYMmUKycnJVKxYkSeeeMLax9vbm61bt/LGG28wf/58EhMT8fb2pmPHjhQpUsT6mkuXLuX555/njTfewMvLi+HDh1OyZMksZ2vMSo0aNVi8eDGjRo3i1VdfxcvLiyFDhuDh4UH//v0z9X322WcpW7Ys77//Pm+//TaOjo7UrFnT+v2sfwsKCmLSpEm0bduWcuXK3VYWyT9MFlv6WERE8lz37t355ZdfOHLkiNFRREQkn9E15M7t2bMHPz8/vvrqK55++mmj40gO03euRAqRa9euZfr5yJEjrFixglatWhkTSERE8g1dQ3LG9OnTKVasGI8++qjRUSQX6LZAkUKkSpUqPPPMM1SpUoWTJ08yZcoUnJyceO2114yOJiIiNk7XkHvz/fffc+DAAb744guGDRtG0aJFjY4kuUC3BYoUIsHBwaxbt464uDicnZ1p2rQp7733Hg0aNDA6moiI2DhdQ+5NpUqViI+PJzAwkLlz52rCpgJKxZWIiIiIiEgO0HeuREREREREcoCKKxERERERkRygCS2yYDabOXv2LMWLF8dkMhkdR0Sk0LBYLFy+fJny5ctjZ6fP//5N1yYREWPcybVJxVUWzp49i4+Pj9ExREQKrVOnTlGhQgWjY9gUXZtERIx1O9cmFVdZ+Hv2llOnTuHm5mZwGhGRwiMxMREfHx/NopUFXZtERIxxJ9cmFVdZ+Pt2Czc3N13AREQMoNvebqRrk4iIsW7n2qQb2kVERP5j8uTJVKpUCRcXF/z9/dm2bVu2fa9fv87YsWOpWrUqLi4u+Pr6EhkZmanP5cuXGT58OBUrVsTV1ZVmzZqxffv23D4MERHJYyquRERE/iU8PJyQkBDGjBnDrl278PX1JTAwkPPnz2fZf9SoUUybNo2JEydy4MABBg8eTI8ePdi9e7e1z4ABA1i9ejVz585l3759tG/fnoCAAM6cOZNXhyUiInlADxHOQmJiIu7u7iQkJOjWCxGRPGQL77/+/v40btyYSZMmARmz9Pn4+PDCCy8wYsSIG/qXL1+ekSNHMnToUGtbz549cXV1Zd68eVy7do3ixYvz7bff0rlzZ2ufhg0b0rFjR955553bymUL50ZEpDC6k/dfjVyJiIj8JTU1lZ07dxIQEGBts7OzIyAggC1btmS5TUpKCi4uLpnaXF1diY6OBiAtLY309PSb9sluv4mJiZkWERGxbSquRERE/nLx4kXS09Px9PTM1O7p6UlcXFyW2wQGBjJ+/HiOHDmC2Wxm9erVREREcO7cOSBjlr+mTZvy9ttvc/bsWdLT05k3bx5btmyx9slKWFgY7u7u1kXTsIuI2D4VVyIiIvdgwoQJVKtWjZo1a+Lk5MSwYcMIDg7O9KDJuXPnYrFY8Pb2xtnZmc8++4wnn3zypg+jDA0NJSEhwbqcOnUqLw5HRETugYorERGRv5QpUwZ7e3vi4+MztcfHx+Pl5ZXlNh4eHixbtoykpCROnjzJoUOHKFasGFWqVLH2qVq1Khs2bODKlSucOnWKbdu2cf369Ux9/svZ2dk67bqmXxcRyR9UXImIiPzFycmJhg0bEhUVZW0zm81ERUXRtGnTm27r4uKCt7c3aWlpLFmyhG7dut3Qp2jRopQrV44///yTVatWZdlHRETyL5svrjZu3EjXrl0pX748JpOJZcuW3bR/REQE7dq1w8PDAzc3N5o2bcqqVavyJqyIiOR7ISEhTJ8+nTlz5nDw4EGGDBlCUlISwcHBAAQFBREaGmrtv3XrViIiIjh27BibNm2iQ4cOmM1mXnvtNWufVatWERkZyfHjx1m9ejWtW7emZs2a1n2KiEjBYPPFVVJSEr6+vkyePPm2+m/cuJF27dqxYsUKdu7cSevWrenatWum542IiIhkp1evXowbN47Ro0fj5+dHTEwMkZGR1kkuYmNjM01EkZyczKhRo6hVqxY9evTA29ub6OhoSpQoYe2TkJDA0KFDqVmzJkFBQbRo0YJVq1bh6OiY14cnIiK5KF8958pkMrF06VK6d+9+R9vVrl2bXr16MXr06Nvqr2eJiIgYQ++/2dO5ERExhp5z9S9ms5nLly9TqlSpbPvk9LNEVv+2mvFbxt/TPkRERERE5B5dvwynv4Vf3s+Tl3PIk1cx0Lhx47hy5QpPPPFEtn3CwsJ46623cuT19sTtof289tiZ7GhcvjEPVXwoR/YrIiIiIiK3YDHDnzFwbhWci4QLm8GSBiY7uP85cM5+wCUnFOiRqwULFvDWW2/x9ddfU7Zs2Wz75eSzRHy9fOnn2w+zxcxTS5/iUvKlu96XiIiIiIjcQvJ5OD4fNj8NS8tBZEPY8zqc35hRWBW7H+4fAunJuR6lwI5cLVq0iAEDBvDNN98QEBBw077Ozs44Ozvn2GtP7DiR6NhofvvzNwb/MJiFPRdiMplybP8iIiIiIoWW+Tpc3JIxOnU2Ev7clfn3DkXBsy2UC8xYilfNs2gFsrhauHAh/fv3Z9GiRXTu3DnPX7+4c3EW9FxA85nNCf8lnI73d6SfX788zyEiIiIiUiBcOf7XrX6rIC4K0i5n/n1Jv7+KqQ5QphnYOxkS0+aLqytXrnD06FHrz8ePHycmJoZSpUpx3333ERoaypkzZ/jqq6+AjFsB+/Xrx4QJE/D39ycuLg4AV1dX3N3d8yx3E+8mvNXqLUauHcnQFUNpfl9z7i91f569voiIiIhIvpV2FeLX//Pdqcu/Zv69cxnwav9XQdUeXL0MiflfNj8V+/r162nduvUN7f369WP27Nk888wznDhxgvXr1wPQqlUrNmzYkG3/25FT092mm9Np+1VbNpzcQOPyjfmp/0842uuZJiIi2dF049nTuRGRAs1igYRfMgqpc6vg/CYwp/zze5M9lGmaMTJVLhBKNciYpCIP3Mn7r80XV0bIyQvYqYRT1Jtaj0vJl3i9xeu82/bdHEopIlLwqIDIns6NiBQ4KX9A3Jp/bve7dibz74vcB+X/KqY824JT3t2F9m938v5r87cF5nc+7j5M7zqdx795nLDoMNpXbU/LSi2NjiUiIiIikrfM6fDH9oxJKM6tgj+2ZUyd/jd7Fyjb6p/RKbcakM8mhVNxlQceq/UY/f36MzNmJk8tfYo9g/dQyjV359gXERERETHc1TP/fG8qbg2k/pn59+61/immPB4CB1djcuYQFVd5ZELHCWyK3cSRP44w6IdBfP3Y15qeXUREREQKnmvn4ND4jBGqhP2Zf+dYArwCMm7382oPRX0MiZhbVFzlkWJOxZj/6HyazWzG4gOLmRUzi/71+xsdS0REREQk51w7B6sfgiu//dVggtKN/xmdKt0E7ApuCZI3U2wIAI29G/NO63cAeHHlixz5/YjBiUREREREckjK77C2fUZhVbQSNF8EPS9A4Fao9xZ4NCvQhRWouMpz/9f8/2hdqTVJ15PoE9GH1PRUoyOJiIiIiNyb64mwrmPGbYCu5aDNGqjYC5xLG50sT6m4ymN2Jju+6vEVJV1KsuPsDkavG210JBERERGRu5d2FTZ0zZgJ0Ll0RmFVvKrRqQyh4soAFdwq8OUjXwLw4U8fsu74OoMTiYiIiIjchfRU2NQTzm8ERzdovSpjBsBCSsWVQR594FEG1B+ABQtPL32a36/+bnQkEREREZHbZ06DzX0yplm3d4WWy6FUQ6NTGUrFlYE+7fAp1UtX58zlMzz3w3NYLBajI4mIiIiI3JrFDNsGwqklYOcEDy+Dsi2MTmU4FVcGKupUlIU9F+Jo50jEwQi+3PWl0ZFERERERG7OYoGdw+HYbDDZZ8wKWK690alsgoorgzUo14B327wLwPBVwzl88bDBiUREREREbmLvG/DrxIz1B2eBTw9j89gQFVc24JVmr9C2cluuXr+q6dlFRERExHYd+AB+yRgYoNFkqPy0sXlsjIorG2BnsmNO9zmUdi3NrnO7GLV2lNGRREREREQy+/VziBmRse73PlR/3tg8NkjFlY3wdvNmxiMzAPho80esObbG4EQiIiIiIn85Phd2DM1Yr/061PqfsXlslIorG9KtZjcGNRwEQNDSIC5evWhwIhEREREp9E4thZ+DM9arD4N67xibx4apuLIx4wPHU7NMTc5dOceA7wZoenYRERERMc65H+Gn3mBJhyrPQMMJYDIZncpmqbiyMUUci7Dg0QU42jny7eFv+WLnF0ZHEhEREZHC6Hw0bOwO5lTweQyaTAeTyoeb0dmxQfXL1ef9gPcBeHnVyxy8cNDgRCIiIiJSqPyxCzZ0hvRrUK4DNJsPdg5Gp7J5Kq5s1PAHh9O+anuupV3jySVPkpKWYnQkERERESkMEg7AuvZwPRHKPgwPLQF7J6NT5QsqrmyUncmO2d1mU6ZIGfbE7+H1qNeNjiQiIiIiBd2VY7C2HaT8DqUaQcvvwaGI0anyDRVXNqxc8XLW6dnH/zyeH3/70eBEIiIiIlJgXT0DUQFw7Sy414bWkeDoZnSqfEXFlY17pMYjDGk0BIB+y/pxIemCwYlEREREpMBJvgBrAyDpOBSrCm1Wg3Npo1PlOyqu8oFx7cdRy6MWcVfi6P9df03PLiIiIiI5J/USrAuExENQpAK0WQOu5YxOlS+puMoHijgWYWHPhTjZO/HDrz8wZccUoyOJiIiISEGQlgTrO8Ofu8HZI6OwKlbJ6FT5loqrfKKeZz0+CPgAgFd+fIVfzv9icCIRERERydfSkzOeY3VxMziWyLgV0K2G0anyNRVX+ciL/i8SWDWQ5LRk+kT0ITkt2ehIIiIF0uTJk6lUqRIuLi74+/uzbdu2bPtev36dsWPHUrVqVVxcXPD19SUyMjJTn/T0dN544w0qV66Mq6srVatW5e2339Zt3iJiHPN1+Kk3xK0Bh6LQeiWU9DU6Vb6n4iofsTPZMbv7bDyKeLA3fi+ha0KNjiQiUuCEh4cTEhLCmDFj2LVrF76+vgQGBnL+/Pks+48aNYpp06YxceJEDhw4wODBg+nRowe7d++29vnggw+YMmUKkyZN4uDBg3zwwQd8+OGHTJw4Ma8OS0TkHxYz/BwMp78FO2d4+Dso86DRqQoEk0Ufm90gMTERd3d3EhIScHOzveknl/+6nC4LuwCwsu9KOtzfweBEIiI5wxbef/39/WncuDGTJk0CwGw24+PjwwsvvMCIESNu6F++fHlGjhzJ0KFDrW09e/bE1dWVefPmAdClSxc8PT2ZMWNGtn1uxRbOjYgUABYLbH8ejk4FkwM8FAEVuhqdyqbdyfuvRq7yoc7VOzOs8TAAnln2DOeTsv40VURE7kxqaio7d+4kICDA2mZnZ0dAQABbtmzJcpuUlBRcXFwytbm6uhIdHW39uVmzZkRFRfHrr78CsGfPHqKjo+nYsWO2WVJSUkhMTMy0iIjcE4sFYv6XUVhhgqZzVVjlMJsvrjZu3EjXrl0pX748JpOJZcuW3bT/uXPn6NOnD9WrV8fOzo7hw4fnSc689mG7D6lTtg7xSfEEfxus+/ZFRHLAxYsXSU9Px9PTM1O7p6cncXFxWW4TGBjI+PHjOXLkCGazmdWrVxMREcG5c+esfUaMGEHv3r2pWbMmjo6O1K9fn+HDh9O3b99ss4SFheHu7m5dfHx8cuYgRaTw+uU9OPhRxnqTL6BSb2PzFEA2X1wlJSXh6+vL5MmTb6t/SkoKHh4ejBo1Cl/fgvulPFdHVxY8ugBne2dWHFnB5O23d35ERCRnTZgwgWrVqlGzZk2cnJwYNmwYwcHB2Nn9c4n9+uuvmT9/PgsWLGDXrl3MmTOHcePGMWfOnGz3GxoaSkJCgnU5depUXhyOiBRUhz+DvaMy1huMh/sHGJungHIwOsCtdOzY8aa3TfxXpUqVmDBhAgAzZ87MrVg2oa5nXT5q9xEvRr7Iqz++SsuKLanrWdfoWCIi+VaZMmWwt7cnPj4+U3t8fDxeXl5ZbuPh4cGyZctITk7m999/p3z58owYMYIqVapY+/zf//2fdfQKoG7dupw8eZKwsDD69euX5X6dnZ1xdnbOoSMTkULtt1mw86WM9bpvQs2XDY1TkNn8yFVeyM/3tQ9rMoxO1TqRkp5Cn4g+XLt+zehIIiL5lpOTEw0bNiQqKsraZjabiYqKomnTpjfd1sXFBW9vb9LS0liyZAndunWz/u7q1auZRrIA7O3tMZvNOXsAIiL/FfsNbPtrlKpmCNQZbWyeAk7FFfn7vnaTycSsbrMoW7Qs+8/v539r/md0JBGRfC0kJITp06czZ84cDh48yJAhQ0hKSiI4OBiAoKAgQkP/eRTG1q1biYiI4NixY2zatIkOHTpgNpt57bXXrH26du3Ku+++y/Llyzlx4gRLly5l/Pjx9OjRI8+PT0QKkTMrYHPfjKnXqw6A+uPAZDI6VYGm4or8f1972aJlmd1tNgATt01kxZEVxgYSEcnHevXqxbhx4xg9ejR+fn7ExMQQGRlpneQiNjY202QVycnJjBo1ilq1atGjRw+8vb2Jjo6mRIkS1j4TJ07kscce4/nnn+eBBx7g1VdfZdCgQbz99tt5fXgiUljEb4DonhkPC674JDSeqsIqD+Sr51yZTCaWLl1K9+7db6t/q1at8PPz49NPP72j18mvzxIZHjmcCVsnULZoWfYO3otnMc9bbyQiYkPy6/tvXtC5EZHbdnEbrG0LaVfAuys8tATsHI1OlW/pOVeF1PsB71PPsx7nk87zzLfPYLboXn4RERGRQuXSPljfIaOw8mwDLb5WYZWHbL64unLlCjExMcTExABw/PhxYmJiiI2NBTJu6QsKCsq0zd/9r1y5woULF4iJieHAgQN5HT3PuTi4sODRBbg4uBB5NJKJWycaHUlERERE8kriEVjbDlL/hNIPwsPfgr3LrbeTHGPztwWuX7+e1q1b39Der18/Zs+ezTPPPMOJEydYv3699XemLO4nrVixIidOnLit18zvt15M3jaZYSuH4WTvxPaB26nnWc/oSCIityW/v//mJp0bEbmppFhY/RBcjYUSvhCwDpxKGp2qQLiT91+bL66MkN8vYBaLhUcWPcIPv/5ALY9a7Bi4A1dHV6NjiYjcUn5//81NOjciNuZUBPw2I2PCCCxgsWT893bWb6cv3Nk+ky/A9UvgVgMCNoJL2bw6EwXenbz/2vxDhOXOmUwmZj4yk3pT63HgwgFe/fFVJneebHQsERERkYLhxMKMKc7/LoJsRdHK0Hq1CisDqbgqoDyKejCn+xwC5wXy+Y7PCbw/kEdqPGJ0LBEREZH87fT3sCUIsEDlIPBqB5j+mubclHnd2kb2fW5n/bb62kGpBvqOlcFUXBVg7au25+UHX+aTnz8haGkQ2wZuo3rp6kbHEhEREcmf4tZC9ONgSYNKT8GDszKKGpG/6E9DAfd+wPs092lOQkoC3RZ1IzEl0ehIIiIiIvnPxZ9h4yNgToEK3VRYSZb0J6KAc7J3YvETi/Eu7s2hi4d4KuIpPf9KRERE5E78uRfWdYS0JPAKgOaLwE43gMmNVFwVAl7FvFjaaynO9s58/+v3vLn+TaMjiYiIiOQPib/CuvYZM/GVaQoPL9P3miRbKq4Kicbejfmi6xcAvL3xbSIORhicSERERMTGJcXC2gBIjoeSftBqBTgUNTqV2DAVV4VIkG8Qw/2HZ6wvDWJf/D5jA4mIiIjYqmvxGYXV1VMZz45qvQqcShidSmyciqtC5qP2H9G2cluSrifRPbw7f1z7w+hIIiIiIrYl9c+MWwEvH4GiFfXsKLltKq4KGQc7B8IfC6dSiUoc+/MYvRf3Js2cZnQsEREREdtw/XLG5BWX9oKLF7RZA0V9jE4l+YSKq0KodJHSfNv7W4o4FmH1sdWMWDPC6EgiIiIixktPho3d4fet4FQK2qyG4vcbnUryERVXhVQ9z3rM7jYbgI+3fMz8vfONDSQiIiJiJPN1iH4C4teCQzFoHQkl6hidSvIZFVeF2OO1H+f1Fq8DMOD7Aew8u9PgRCIiIiIGMKfDln5w5vuMadZbfg+lGxudSvIhFVeF3Ntt3qZztc4kpyXTPbw78VfijY4kIiIikncsFtjxPJxcCCYHaLEEPFsZnUryKRVXhZydyY75j86nRukanE48zWPfPEZqeqrRsURERERyn8UCMa/B0S/AZAfN5oN3J6NTST6m4kpwd3Hn297f4ubsRnRsNC+tfMnoSCIiIiK575d34eC4jPUmX0DFJ4zNI/meiisBoEaZGsx/dD4mTEzdOZUvdn5hdCQRERGR3HNoAux9I2O9wSdQ9Vlj80iBoOJKrLpU78Lbrd8GYNiKYfwU+5PBiURERERywW+zYNfwjPW6b0LN4QaGkYJExZVk8vpDr/NYrce4br5Oz697cjrxtNGRRERERHJO7DewbUDGes0QqDPa2DxSoKi4kkxMJhOzus2ibtm6xCfF82j4oySnJRsdS0REROTenV0Jm/uCxQxVB0D9cWAyGZ1KChAVV3KDYk7F+Lb3t5RyLcX2s9sZ9MMgLBaL0bFERERE7t75jbDp0YyHBd/XCxpPVWElOU7FlWSpcsnKfP3Y19iZ7Phqz1dM2DrB6EgiIiIid+f3HbC+C6QnQ/ku0Gwu2NkbnUoKIBVXkq22Vdoyrl3G9KSv/vgqUceiDE4kIiIicocu/QLrAiHtMni2hhZfg52j0amkgFJxJTc1/MHhPF3vadIt6Tyx+AmO/3nc6EgiIiIit+fyb7CuHaT+AaWbwMPfgoOr0amkAFNxJTdlMpmY1mUajco34o9rf9A9vDtJqUlGxxIRERG5uaunYW0AXDsHJepCq5XgWNzoVFLAqbiSW3J1dGVpr6V4FvVkb/xegr8N1gQXIiIiYruSL8DadpB0AordD61/BOdSRqeSQkDFldyWCm4VWPLEEhztHPnmwDeERYcZHUlERETkRqmXMr5jlXgIivhA2zXg6mV0KikkVFzJbWt+X3MmdZoEwKi1o1j+63KDE4mIiIj8S1oSbOgCf+4Gl7LQZg0UrWh0KilEVFzJHXmu4XMMajgICxb6RPTh8MXDRkcSERERgfQU2NgDLvwEjiUybgV0q250KilkVFzJHfus42e0uK8FiSmJdFvUjYTkBKMjiYiISGFmToOfnoS41eBQFFqtgJK+RqeSQsjmi6uNGzfStWtXypcvj8lkYtmyZbfcZv369TRo0ABnZ2fuv/9+Zs+enes5CxMneycWP76YCm4VOPz7YZ5a+hRmi9noWCIiIlIYWczwc384vRTsnDKmW/doanQqKaRsvrhKSkrC19eXyZMn31b/48eP07lzZ1q3bk1MTAzDhw9nwIABrFq1KpeTFi6exTxZ2mspLg4u/PDrD4xeN9roSCIiOWby5MlUqlQJFxcX/P392bZtW7Z9r1+/ztixY6latSouLi74+voSGRmZqU+lSpUwmUw3LEOHDs3tQxEp2CwW2PEinJgLJnto8Q14tTU6lRRiDkYHuJWOHTvSsWPH2+4/depUKleuzMcffwzAAw88QHR0NJ988gmBgYG5FbNQalS+EdO7TufppU/z7qZ38fPy47FajxkdS0TknoSHhxMSEsLUqVPx9/fn008/JTAwkMOHD1O2bNkb+o8aNYp58+Yxffp0atasyapVq+jRowebN2+mfv36AGzfvp309HTrNvv376ddu3Y8/vjjeXZcIgXSnpFwZDJggqZfQYVHjE4khZzNj1zdqS1bthAQEJCpLTAwkC1btmS7TUpKComJiZkWuT1P1XuKkAdDAOi3rB974/canEhE5N6MHz+egQMHEhwcTK1atZg6dSpFihRh5syZWfafO3cur7/+Op06daJKlSoMGTKETp06WT/kA/Dw8MDLy8u6/PDDD1StWpWWLVvm1WGJFDy/vA8H/no0TOMpUKmPsXlEKIDFVVxcHJ6enpnaPD09SUxM5Nq1a1luExYWhru7u3Xx8fHJi6gFxgftPiCgSgBXr1+l+6Lu/H71d6MjiYjcldTUVHbu3JnpQzo7OzsCAgKy/ZAuJSUFFxeXTG2urq5ER0dn+xrz5s2jf//+mEymbLPogz+Rm/j1c9gTmrHu9yFUG2RsHpG/FLji6m6EhoaSkJBgXU6dOmV0pHzFwc6BRT0XUblEZY5fOk6vxb1IM6cZHUtE5I5dvHiR9PT0LD+ki4uLy3KbwMBAxo8fz5EjRzCbzaxevZqIiAjOnTuXZf9ly5Zx6dIlnnnmmZtm0Qd/Itk4Phd2/PV9xdqjoNb/GZtH5F8KXHHl5eVFfHx8prb4+Hjc3NxwdXXNchtnZ2fc3NwyLXJnShcpzbe9v6WoY1Gijkfx2urXjI4kIpInJkyYQLVq1ahZsyZOTk4MGzaM4OBg7OyyvsTOmDGDjh07Ur58+ZvuVx/8iWTh1FL4OThjvfoLUG+ssXlE/qPAFVdNmzYlKioqU9vq1atp2lRTcua2up51mdN9DgCf/PwJX+35yuBEIiJ3pkyZMtjb22f5IZ2Xl1eW23h4eLBs2TKSkpI4efIkhw4dolixYlSpUuWGvidPnmTNmjUMGDDglln0wZ/If1zYDD/1Bks6VHkGGn4KN7m1VsQINl9cXblyhZiYGGJiYoCMqdZjYmKIjY0FMj7ZCwoKsvYfPHgwx44d47XXXuPQoUN8/vnnfP3117z88stGxC90etbqyaiHRgHw3PfPsf3MdoMTiYjcPicnJxo2bJjpQzqz2UxUVNQtP6RzcXHB29ubtLQ0lixZQrdu3W7oM2vWLMqWLUvnzp1zPLtIgZZ6KeMhweZUqNADmkwHk83/M1YKIZv/U7ljxw7q169vnc42JCSE+vXrM3p0xnOVzp07Zy20ACpXrszy5ctZvXo1vr6+fPzxx3z55Zeahj0PvdX6LbpW70pKego9wnsQdyXr7ymIiNiikJAQpk+fzpw5czh48CBDhgwhKSmJ4OCMW5GCgoIIDQ219t+6dSsREREcO3aMTZs20aFDB8xmM6+9lvn2aLPZzKxZs+jXrx8ODjb/JBQR22GxwLbn4GosFKsCTWeDnf4OiW2y+T+ZrVq1wmKxZPv72bNnZ7nN7t27czGV3IydyY55j87D/0t/Dl08xGNfP8bafmtxsncyOpqIyC316tWLCxcuMHr0aOLi4vDz8yMyMtI6yUVsbGym71MlJyczatQojh07RrFixejUqRNz586lRIkSmfa7Zs0aYmNj6d+/f14ejkj+d2wmxH4DJgdothAcdYus2C6T5WaVSyGVmJiIu7s7CQkJusf9Hhy+eJgmXzYhMSWRQQ0HMbXLVKMjiYiN0/tv9nRupFBKOAiRjSD9Kvh9ALU0YZbkvTt5/7X52wIl/6pRpgYLey7EhIlpO6cxbcc0oyOJiIhIfpGenPE9q/Sr4BUAD7xqdCKRW1JxJbmqU7VOvNvmXQCGrRxGdGzWD9UUERERySRmBFzaA85loOlXmsBC8gX9KZVcN6LFCJ6o/QRp5jR6ft2TUwl6VouIiIjcxJnlcHhCxvqDs8G1nKFxRG6XiivJdSaTiZmPzMTX05fzSefpEd6Dq9evGh1LREREbNG1c/DzMxnrNV4Cbz26QPIPFVeSJ4o6FWVZ72WUdi3NznM7CVoahNliNjqWiIiI2BKLGbYEQcpFKOmXMYmFSD6i4kryTKUSlYjoFYGjnSNLDi5hxJoRRkcSERERW3JwHMStAfsiGdOu2zsbnUjkjqi4kjz1cMWHmdltJgAfbf5IMwiKiIhIhovbYM/IjPVGn4F7TWPziNwFFVeS556q9xRvtXoLgKErhhJ5NNLgRCIiImKo64mwuQ9Y0uC+x6GKHrYt+ZOKKzHEGw+/QT/ffqRb0nn8m8fZE7fH6EgiIiJilO1D4cpvULQiNPkCTCajE4ncFRVXYgiTycQXXb+gdaXWXEm9QucFnTmTeMboWCIiIpLXjs+FE/MynmPVbD44lTA6kchdU3ElhnGyd2LJE0uoWaYmZy6focvCLlxOuWx0LBEREckrl4/C9ucz1uu8CR7NDY0jcq9UXImhSrqWZEWfFZQtWpaYuBh6L+lNmjnN6FgiIiKS29JT4acnIe0KlH0Yar9udCKRe6biSgxXuWRlvuv9HS4OLqw4soKXVr6ExWIxOpaIiIjkpr1vwB87wKkkNJ0HdvZGJxK5ZyquxCb4V/BnXo95mDDx+Y7P+fTnT42OJCIiIrnl3Go4+GHGuv8MKOpjbB6RHKLiSmxGz1o9+bBdxhvtKz++wtKDSw1OJCIiIjku+TxsCcpYv38w+PQwNo9IDlJxJTbllaavMLjhYCxY6BvRl21nthkdSURERHKKxQI/B0NyHLjXhgbjjU4kkqNUXIlNMZlMTOw0kY73d+Ra2jW6LuzKiUsnjI4lIiIiOeHwZ3B2Bdg5Q/OF4OBqdCKRHKXiSmyOg50D4Y+F4+vpy/mk83Sa34lLyZeMjiUiIiL34o/dEPNaxnqD8VCirrF5RHKBiiuxScWdi/NDnx8oX7w8By8epOfXPUlNTzU6loiIiNyNtCTY/CSYU6FCN6g2xOhEIrlCxZXYrApuFVjeZznFnIqx9vhaBv8wWFO0i4iI5Ec7X4LEw+DqnTE7oMlkdCKRXKHiSmyan5cf4Y+FY2eyY1bMLN7b9J7RkUREROROnPwafpsBmKDZPHAubXQikVyj4kpsXqdqnZjYcSIAo9aNYuG+hQYnEhERkdty5QRsey5jvfbr4NnKyDQiuU7FleQLzzd+npAHQwB45ttn2HRyk8GJRERE5KbMabC5D1xPgDJNoe4YoxOJ5DoVV5JvfNT+I3rU7EFqeirdw7vz6++/Gh1JREREsrN/LFzcAo5u0GwB2DkanUgk16m4knzDzmTHvEfn0cS7CX9c+4POCzpz8epFo2OJiIjIf8VvgP3vZKw3+QKKVTI0jkheUXEl+UoRxyJ81/s7KpWoxNE/jtJ9UXeS05KNjiUiIiJ/S/kdtjwFWKBKf6jYy+hEInlGxZXkO57FPFneZznuzu78dOongr8NxmwxGx1LRERELBbYOgCunobi1aHRZ0YnEslTKq4kX6rlUYuIXhE42DmwaP8i3lj7htGRRERE5OhUOL0M7Jyg+SJwKGp0IpE8peJK8q02ldswvet0AN6Lfo+Zu2canEhERKQQu7QfdmXM7Ivf+1CqvrF5RAyQL4qryZMnU6lSJVxcXPD392fbtm3Z9r1+/Tpjx46latWquLi44OvrS2RkZB6mlbz0jN8zjHpoFACDfhjEmmNrDE4kIiJSCKVdg596Q3oylOsINV4yOpGIIWy+uAoPDyckJIQxY8awa9cufH19CQwM5Pz581n2HzVqFNOmTWPixIkcOHCAwYMH06NHD3bv3p3HySWvjG09lj51+5BmTqPn1z3Zf36/0ZFEREQKl92vQsIv4OIJTWeDyeb/iSmSK0wWi8VidIib8ff3p3HjxkyaNAkAs9mMj48PL7zwAiNGjLihf/ny5Rk5ciRDhw61tvXs2RNXV1fmzZt3W6+ZmJiIu7s7CQkJuLm55cyBSK5KSUuh3dx2bIrdxH3u97F1wFa8inkZHUtE7pDef7OncyM269Qy2NQjY731KijX3tA4IjntTt5/bfpjhdTUVHbu3ElAQIC1zc7OjoCAALZs2ZLlNikpKbi4uGRqc3V1JTo6OtvXSUlJITExMdMi+YuzgzNLey2lWqlqxCbE0nVhV5JSk4yOJSIiUrBdPQ1bn81Yf+D/VFhJoWfTxdXFixdJT0/H09MzU7unpydxcXFZbhMYGMj48eM5cuQIZrOZ1atXExERwblz57J9nbCwMNzd3a2Lj49Pjh6H5I3SRUqzou8KyhQpw46zO+gb0Zd0c7rRsURERAomczpsfgpS/4BSjaDeO0YnEjGcTRdXd2PChAlUq1aNmjVr4uTkxLBhwwgODsbOLvtDDQ0NJSEhwbqcOnUqDxNLTrq/1P182/tbnO2d+fbwt7z646tGRxIRESmYDrwP5zeAQzFotgDsnYxOJGI4my6uypQpg729PfHx8Zna4+Pj8fLK+vs0Hh4eLFu2jKSkJE6ePMmhQ4coVqwYVapUyfZ1nJ2dcXNzy7RI/tXMpxlf9fgKgE+3fsqkbZMMTiQi+U1uzFJ75swZnnrqKUqXLo2rqyt169Zlx44duXkYIrnnwmbYNyZjvfHn4FbN2DwiNsKmiysnJycaNmxIVFSUtc1sNhMVFUXTpk1vuq2Liwve3t6kpaWxZMkSunXrlttxxYY8UfsJwtqGAfBS5Ev88OsPBicSkfwiN2ap/fPPP2nevDmOjo6sXLmSAwcO8PHHH1OyZMm8OiyRnJN6CTb3AUs6VOoLlZ82OpGIzbD52QLDw8Pp168f06ZNo0mTJnz66ad8/fXXHDp0CE9PT4KCgvD29iYsLOMf0lu3buXMmTP4+flx5swZ3nzzTY4fP86uXbsoUaLEbb2mZmQqGCwWCwO/H8iM3TMo4liETcGbaFCugdGxROQmbOH9NzdmqR0xYgQ//fQTmzZtuutctnBuRLBY4KcnITYcilWBjrvBUX8epWArMLMFAvTq1Ytx48YxevRo/Pz8iImJITIy0jrJRWxsbKbJKpKTkxk1ahS1atWiR48eeHt7Ex0dfduFlRQcJpOJKZ2n0K5KO65ev0qXBV04laDv04lI9nJrltrvvvuORo0a8fjjj1O2bFnq16/P9OnTb5pFM9mKTTo2K6OwMjlAs4UqrET+w+ZHroygTwcLloTkBFrMasH+8/upW7Yu0f2jcXPW/1cRW2T0++/Zs2fx9vZm8+bNmW4/f+2119iwYQNbt269YZs+ffqwZ88eli1bRtWqVYmKiqJbt26kp6eTkpICYC2+QkJCePzxx9m+fTsvvfQSU6dOpV+/fllmefPNN3nrrbduaNe1SQyTeBhWNoD0q+D3PtT6n9GJRPJEgRq5ErlX7i7uLO+zHK9iXuw7v48nvnmC6+nXjY4lIgXE7cxSazabadCgAe+99x7169fnueeeY+DAgUydOjXb/WomW7Ep6SnwU++MwsqzbcYzrUTkBiqupFC4z/0+fnjyB4o4FmHVb6sYtmIYGrQVKTgqVarE2LFjiY2Nvaf95NYsteXKlaNWrVqZtnvggQdumlcz2YpNiQmFP2PAuQw0/QpM+iekSFb0N0MKjYblG7Kw50JMmPhi1xd8tPkjoyOJSA4ZPnw4ERERVKlShXbt2rFo0SLrLXl3IrdmqW3evDmHDx/O1P/XX3+lYsWKd5xRJM+dXQmHP8lYf3A2FClvaBwRW6biSgqVR2o8wqcdPgXgf2v+xze/fGNsIBHJEcOHDycmJoZt27bxwAMP8MILL1CuXDmGDRvGrl277mhfISEhTJ8+nTlz5nDw4EGGDBlCUlISwcHBAAQFBREaGmrtv3XrViIiIjh27BibNm2iQ4cOmM1mXnvtNWufl19+mZ9//pn33nuPo0ePsmDBAr744otMMwyK2KRrcbDlr+8FVn8RvDsbm0fExqm4kkLnRf8XeaHJCwA8vfRptpzKegYwEcl/GjRowGeffcbZs2cZM2YMX375JY0bN8bPz4+ZM2fe1u3AuTFLbePGjVm6dCkLFy6kTp06vP3223z66af07ds3x8+BSI65fiXje1YpF6CEL9T/wOhEIjZPswVmwejZqiT3pZvT6RHeg+9//Z6yRcuyY+AOfNx9jI4lUujd6/vv9evXWbp0KbNmzWL16tU8+OCDPPvss5w+fZrJkyfTpk0bFixYkAvJc5+uTZKnki/Chs7w+zZwKAqB28H9AaNTiRjiTt5/HfIok4hNsbezZ2HPhTSf2Zw98XvoHt6dTcGbKOJYxOhoInIXdu3axaxZs1i4cCF2dnYEBQXxySefULNmTWufHj160LhxYwNTiuQTSSdhXWDG1OtOpaDVchVWIrdJtwVKoVXUqSjLei+jTJEy7Dq3i4HfD9QMgiL5VOPGjTly5AhTpkzhzJkzjBs3LlNhBVC5cmV69+5tUEKRfOLSPvixWUZhVeQ+aPcTlHnQ6FQi+YZGrqRQq1SiEosfX0zA3AAW7FuAn6cf/9dcz+4QyW+OHTt2y5n3ihYtyqxZs/IokUg+dH4jbHgErieAex1oHQlFvI1OJZKvaORKCr2WlVoyocMEIGMGwZVHVhqcSETu1Pnz59m6desN7Vu3bmXHjh0GJBLJZ04thbXtMworjxbQbqMKK5G7oOJKBBjSaAgDGwzEgoUnlzzJ4YuHb72RiNiMoUOHcurUqRvaz5w5o+nORW7l6BcQ/RiYU6BCN2j9IziVNDqVSL6k4koEMJlMTOo0ieY+zUlISaDbom4kJCcYHUtEbtOBAwdo0KDBDe3169fnwIEDBiQSyQcsFtg3FrYNAosZqg6EFovBwdXoZCL5loorkb842Tux5IklVHCrwOHfD9M3oi/p5nSjY4nIbXB2diY+Pv6G9nPnzuHgoK8Xi9zAnA47hsK+MRk/13kDmkwDO/19EbkXKq5E/sWzmCfLei3DxcGF5UeW88a6N4yOJCK3oX379oSGhpKQ8M+I86VLl3j99ddp166dgclEbFB6MvzUC45MAUzQaBLUGwsmk9HJRPI9FVci/9GwfENmPDIDgLDoMML3hxucSERuZdy4cZw6dYqKFSvSunVrWrduTeXKlYmLi+Pjjz82Op6I7UhNgHUd4NQSsHOCFuFQXd9LFMkpKq5EstCnbh9ea/YaAMHfBrP73G6DE4nIzXh7e7N3714+/PBDatWqRcOGDZkwYQL79u3Dx8fH6HgituHaOVjTEs5vAIfiGVOt3/e40alEChTdWCuSjffavsfe83uJPBpJ9/DubB+4nbJFyxodS0SyUbRoUZ577jmjY4jYpsQjsK49JJ0AF09otRJK1Tc6lUiBo+JKJBv2dvYs7LmQJtObcOSPIzz29WOsCVqDk72T0dFEJBsHDhwgNjaW1NTUTO2PPPKIQYlEbMDvO2B9J0i5AMWqQpsfoVgVo1OJFEi5VlydOnUKk8lEhQoVANi2bRsLFiygVq1a+mRR8o0SLiX47snv8P/Sn02xmxgeOZzPO39udCwR+Y9jx47Ro0cP9u3bh8lkwmKxABmPWQBIT9fMn1JInfsRNj0KaUlQsgG0WgGunkanEimwcu07V3369GHdunUAxMXF0a5dO7Zt28bIkSMZO3Zsbr2sSI6rWaYm8x+djwkTU3ZMYdqOaUZHEpH/eOmll6hcuTLnz5+nSJEi/PLLL2zcuJFGjRqxfv16o+OJGOPEAljfOaOw8gqAgPUqrERyWa4VV/v376dJkyYAfP3119SpU4fNmzczf/58Zs+enVsvK5IrulTvwrtt3gVg2MphbDq5yeBEIvJvW7ZsYezYsZQpUwY7Ozvs7Oxo0aIFYWFhvPjii0bHE8l7hz6FzX3BkgYVe0PL5eBY3OhUIgVerhVX169fx9nZGYA1a9ZY73evWbMm586dy62XFck1I1qMoFftXqSZ0+j5dU9iE2KNjiQif0lPT6d48Yx/OJYpU4azZ88CULFiRQ4fPmxkNJG8ZbFAzAjY9XLGz9VfhGbzQd8XFskTuVZc1a5dm6lTp7Jp0yZWr15Nhw4dADh79iylS5fOrZcVyTUmk4kZj8zAz8uPC1cv0H1Rd65ev2p0LBEB6tSpw549ewDw9/fnww8/5KeffmLs2LFUqaIv7kshYb4OPwfDgQ8yfvYNg4afgklP3hHJK7n2t+2DDz5g2rRptGrViieffBJfX18AvvvuO+vtgiL5TVGnoizrtQyPIh7sjtvNs989a/3ivIgYZ9SoUZjNZgDGjh3L8ePHeeihh1ixYgWfffaZwelE8kBaEmzsDsfngMke/GdC7RHw16QuIpI3TJZc/Jdheno6iYmJlCxZ0tp24sQJihQpQtmytvu8oMTERNzd3UlISMDNzc3oOGKDNp7cSNuv2pJmTuP9tu/zvxb/MzqSSIGQk++/f/zxByVLlrTOGJjf6dok2Ur5HdZ3gd9/BntXaPE1eHcxOpVIgXEn77+5NnJ17do1UlJSrIXVyZMn+fTTTzl8+LBNF1Yit+Phig8zseNEAEKjQllxZIXBiUQKr+vXr+Pg4MD+/fsztZcqVarAFFYi2UqKhdUtMgorp5LQJkqFlYiBcq246tatG1999RUAly5dwt/fn48//pju3bszZcqU3HpZkTwzuNFgBjUchAULTy55ksMX9aV5ESM4Ojpy33336VlWUvhc2g8/NoPEQ1CkArSLBo+mRqcSKdRyrbjatWsXDz30EACLFy/G09OTkydP8tVXX+n+dykwPuv4GS3ua0FiSiKPLHqES8mXjI4kUiiNHDmS119/nT/++MPoKCJ543w0rH4Irp0B91rQbnPGf0XEUA65teOrV69ap8X98ccfefTRR7Gzs+PBBx/k5MmTufWyInnKyd6JxY8vpvH0xvz6+6/0WdKH75/8Hns7e6OjiRQqkyZN4ujRo5QvX56KFStStGjRTL/ftWuXQclEcsHp7+CnXpCeDGWaQcvvwbmU0alEhFwsru6//36WLVtGjx49WLVqFS+/nPG8hfPnz+uLuFKgeBbzZFnvZTSf2ZyVR1cycu1I3g943+hYIoVK9+7djY4gkjeOfgnbB4HFDOW7QItwcChidCoR+UuuzRa4ePFi+vTpQ3p6Om3atGH16tUAhIWFsXHjRlauXHnb+5o8eTIfffQRcXFx+Pr6MnHixJtO5/7pp58yZcoUYmNjKVOmDI899hhhYWG4uLjc1utpRia5Gwv3LaRPRB8AFjy6gCfrPmlwIpH8R++/2dO5KeQsFvjlPdg7KuPnKv2hyTSwy7XPyUXkLzYxW+Bjjz1GbGwsO3bsYNWqVdb2tm3b8sknn9z2fsLDwwkJCWHMmDHs2rULX19fAgMDOX/+fJb9FyxYwIgRIxgzZgwHDx5kxowZhIeH8/rrr9/zMYnczJN1n+R/zTOmZO//XX92nt1pcCIRESkQzOmw88V/CqtaoeD/pQorERuUq8+5+tvp06cBqFChwh1v6+/vT+PGjZk0aRIAZrMZHx8fXnjhBUaMGHFD/2HDhnHw4EGioqKsba+88gpbt24lOjr6tl5Tnw7K3Uo3p9N1YVdWHl1JBbcK7Bi4A89inkbHEsk37vb9187O7qbTrheEmQR1bSqk0lNgy9MQ+w1ggoafQo0XjU4lUqjYxMiV2Wxm7NixuLu7U7FiRSpWrEiJEiV4++23MZvNt7WP1NRUdu7cSUBAwD+B7ewICAhgy5YtWW7TrFkzdu7cybZt2wA4duwYK1asoFOnTtm+TkpKComJiZkWkbthb2fPgp4LqF66OqcTT/PYN4+Rmp5qdCyRAm/p0qVERERYl/DwcEaMGEG5cuX44osvjI4ncneuJ8L6ThmFlZ0jNF+owkrExuXaePLIkSOZMWMG77//Ps2bNwcgOjqaN998k+TkZN59991b7uPixYukp6fj6Zn5k39PT08OHTqU5TZ9+vTh4sWLtGjRAovFQlpaGoMHD77pbYFhYWG89dZbd3B0Itkr4VKCb3t/i/+X/kTHRvPiyheZ2mWq0bFECrRu3brd0PbYY49Ru3ZtwsPDefbZZw1IJXIPrsXB+o7wZww4FIOHl4JXwC03ExFj5drI1Zw5c/jyyy8ZMmQI9erVo169ejz//PNMnz6d2bNn59bLsn79et577z0+//xzdu3aRUREBMuXL+ftt9/OdpvQ0FASEhKsy6lTp3ItnxQONcvUZGHPhZgwMW3nNKbuUHElYoQHH3ww023iIvnC5aOwunlGYeVSFgLWq7ASySdybeTqjz/+oGbNmje016xZ87Yf8limTBns7e2Jj4/P1B4fH4+Xl1eW27zxxhs8/fTTDBgwAIC6deuSlJTEc889x8iRI7Gzu7GedHZ2xtnZ+bYyidyuTtU6EdY2jBFRI3hh5QvU8qjFwxUfNjqWSKFx7do1PvvsM7y9vY2OInL7Lv0Ca9tA8nkoVgVar4Li9xudSkRuU66NXPn6+lonofi3SZMmUa9evdvah5OTEw0bNsz0qaPZbCYqKoqmTZtmuc3Vq1dvKKDs7TMe6JoHc3eIZPJa89foXac3aeY0Hvv6MU5e0gO0RXJDyZIlKVWqlHUpWbIkxYsXZ+bMmXz00UdGxxO5PebrsLlvRmFV0g/a/aTCSiSfybWRqw8//JDOnTuzZs0aayG0ZcsWTp06xYoVK257PyEhIfTr149GjRrRpEkTPv30U5KSkggODgYgKCgIb29vwsLCAOjatSvjx4+nfv36+Pv7c/ToUd544w26du1qLbJE8orJZGLGIzM4fPEwu+N20z28O9HB0RR1Kmp0NJEC5ZNPPsk0W6CdnR0eHh74+/tTsmRJA5OJ3IEDH8KlPeBcOmPEyqWs0YlE5A7lWnHVsmVLfv31VyZPnmydfOLRRx/lueee45133uGhhx66rf306tWLCxcuMHr0aOLi4vDz8yMyMtI6yUVsbGymkapRo0ZhMpkYNWoUZ86cwcPDg65du97WBBoiuaGIYxGW9V5Goy8aERMXQ//v+rOo56KbThstInfmmWeeMTqCyL1JOAD7x2asN5igwkokn8qT51z92549e2jQoIFNP3NEzxKR3LDp5CbafNWGNHMa77V5j9CHQo2OJGJz7vb9d9asWRQrVozHH388U/s333zD1atX6dev3x3lmDx5Mh999BFxcXH4+voyceJEmjRpkmXf69evExYWxpw5czhz5gw1atTggw8+oEOHDtY+b7755g2z0taoUSPbmW+zomtTAWZOh9Ut4PefoXwnaPkD6AM4EZthE8+5EpHMHqr4EJM6ZnwPceTakfzw6w8GJxIpOMLCwihTpswN7WXLluW99967o32Fh4cTEhLCmDFj2LVrF76+vgQGBnL+/Pks+48aNYpp06YxceJEDhw4wODBg+nRowe7d+/O1K927dqcO3fOutzug+2lEPh1UkZh5VAcGk9VYSWSj6m4EslDgxoNYnDDwViw0GdJHw5eOGh0JJECITY2lsqVK9/QXrFiRWJjY+9oX+PHj2fgwIEEBwdTq1Ytpk6dSpEiRZg5c2aW/efOncvrr79Op06dqFKlCkOGDKFTp058/PHHmfo5ODjg5eVlXbIqBqUQunIM9vz1LM76H0FRH2PziMg9UXElkscmdJzAQ/c9xOXUy3Rb1I1LyZeMjiSS75UtW5a9e/fe0L5nzx5Kly592/tJTU1l586dBAT880whOzs7AgIC2LJlS5bbpKSk4OLikqnN1dX1hpGpI0eOUL58eapUqULfvn1vWfSlpKSQmJiYaZECxmKBrc9B+lUo2wruH2h0IhG5Rzk+ocWjjz56099funQpp19SJF9xsndi8ROLafRFI478cYQnlzzJD0/+gL2dZrMUuVtPPvkkL774IsWLF+fhhzOeJ7dhwwZeeuklevfufdv7uXjxIunp6dZJk/7m6emZ7fejAgMDGT9+PA8//DBVq1YlKiqKiIiITN8t9vf3Z/bs2dSoUYNz587x1ltv8dBDD7F//36KFy+e5X7DwsJu+J6WFDDHZkJ8FNi7gv90MOkzb5H8Lsf/Fru7u990qVixIkFBQTn9siL5StmiZVnWexmuDq5EHo3k9ajXjY4kkq+9/fbb+Pv707ZtW1xdXXF1daV9+/a0adPmjr9zdacmTJhAtWrVqFmzJk5OTgwbNozg4OBMM9l27NiRxx9/nHr16hEYGMiKFSu4dOkSX3/9dbb7DQ0NJSEhwbqcOnUqV49D8tjVs7DrlYz1em/reVYiBUSOj1zNmjUrp3cpUiA1KNeAmd1m8uSSJ/lw84f4evnSp24fo2OJ5EtOTk6Eh4fzzjvvEBMTg6urK3Xr1qVixYp3tJ8yZcpgb29PfHx8pvb4+Hi8vLyy3MbDw4Nly5aRnJzM77//Tvny5RkxYgRVqlTJ9nVKlChB9erVOXr0aLZ9nJ2dcXZ2vqP8kk9YLLB9CFxPgNJNoMZwoxOJSA7R+LOIgXrX6c2I5iMAePa7Z9lxdofBiUTyt2rVqvH444/TpUuXOy6sIKNIa9iwIVFRUdY2s9lMVFQUTZs2vem2Li4ueHt7k5aWxpIlS+jWrVu2fa9cucJvv/1GuXLl7jijFAAnw+HMd2DnCP4zQLeFixQYKq5EDPZOm3foXK0zyWnJ9AjvwdnLZ42OJJLv9OzZkw8++OCG9g8//PCGZ1/dSkhICNOnT2fOnDkcPHiQIUOGkJSURHBwMABBQUGEhv7znLqtW7cSERHBsWPH2LRpEx06dMBsNvPaa69Z+7z66qts2LCBEydOsHnzZnr06IG9vT1PPvnkXR6x5FvJF2HnCxnrtUdCiTrG5hGRHKXiSsRg9nb2zH90PjVK1+B04mnaftWWuCtxRscSyVc2btxIp06dbmjv2LEjGzduvKN99erVi3HjxjF69Gj8/PyIiYkhMjLSOslFbGws586ds/ZPTk5m1KhR1KpVix49euDt7U10dDQlSpSw9jl9+jRPPvkkNWrU4IknnqB06dL8/PPPeHh43N0BS/618yVIuQgl6kItPUxepKAxWSwWi9EhbM2dPIVZJKcc+/MYrWa34lTiKWqWqcm6fuvwKpb1dzxECqq7ff91dXUlJiaGGjVqZGo/dOgQ9evX59q1azkdNc/p2lQAnPkBNnTNmBWw/c9QurHRiUTkNtzJ+69GrkRsRJWSVVjXbx0V3Cpw6OIh2sxpQ/yV+FtvKCLUrVuX8PDwG9oXLVpErVq1DEgk8h+pCbBtcMZ6zRAVViIFVI7PFigid69qqaqs77eeVnNacfDiQVrPac26fuvwLOZ5y21FCrM33niDRx99lN9++402bdoAEBUVxYIFC1i8eLHB6USAmNfg2hkodj/U1fPLRAoqjVyJ2Jiqpaqyrt86vIt7WwssjWCJ3FzXrl1ZtmwZR48e5fnnn+eVV17hzJkzrF27lvvv1/ODxGDx6+DoFxnrD84AhyLG5hGRXKPiSsQG3V/qftY/s95aYLX5SrcIitxK586d+emnn0hKSuLYsWM88cQTvPrqq/j6+hodTQqztCTYOiBjvdoQKPuwsXlEJFepuBKxUfeXup91/dZRvnh5Dlw4QJuv2nA+6bzRsURs2saNG+nXrx/ly5fn448/pk2bNvz8889Gx5LCbO9ouHIMiviA3/tGpxGRXKbiSsSGVStdjfX91v9TYM1RgSXyX3Fxcbz//vvWBwi7ubmRkpLCsmXLeP/992ncWBMHiEEuboXDn2asN5kGjprlUaSgU3ElYuOqla7Gun7rKFesHL9c+IW2X7XlQtIFo2OJ2ISuXbtSo0YN9u7dy6effsrZs2eZOHGi0bFEID0FtvYHixkqPQ3lOxqdSETygIorkXygeunqrH9mPeWKlWP/+f20+aqNCiwRYOXKlTz77LO89dZbdO7cGXt7e6MjiWT45V1IOAAuZaHhJ0anEZE8ouJKJJ/4b4GlESwRiI6O5vLlyzRs2BB/f38mTZrExYsXjY4lhd2fe+GXsIz1RpPAubSxeUQkz6i4EslHqpeubr1FcN/5fbT9qi0Xr+ofklJ4Pfjgg0yfPp1z584xaNAgFi1aRPny5TGbzaxevZrLly8bHVEKG3PaX7cDpkGFHuDzmNGJRCQPqbgSyWdqlKnBun7r8CrmpQJL5C9Fixalf//+REdHs2/fPl555RXef/99ypYtyyOPPGJ0PClMDo2HP3aCYwloPBlMJqMTiUgeUnElkg/9u8DaG7+XgK8C+P3q70bHErEJNWrU4MMPP+T06dMsXLjQ6DhSmCT+CvvGZKw3GA+u5YzNIyJ5TsWVSD5Vs0xN1vVbh2dRT/bE76HtV21VYIn8i729Pd27d+e7774zOooUBhZzxsOC05PBqz1UecboRCJiABVXIvnYfwusgLkawRIRMcSRqXBhEzgUzXimlW4HFCmUVFyJ5HMPeDzA2n5rKVu0LDFxMbSb244/rv1hdCwRkcIj6STE/C9j3TcMilUyNI6IGEfFlUgBUMujFuv6raNs0bLsjttNwFcBKrBERPKCxQLbBkPaFfBoDtWHGp1IRAyk4kqkgKjlUYu1QWtVYImI5KXjc+FcJNg5g/8MMOmfViKFmd4BRAqQ2mVrszZoLR5FPNgdt1u3CIqI5KZrcbBreMZ63TfBrYaRaUTEBqi4Eilgapetzbp+6/Ao4sGuc7toN7cdf1770+hYIiIFz45hkPonlKwPD7xidBoRsQEqrkQKoNpla7O231oVWCIiuSV2CZxaAiYHeHAm2DkanUhEbEC+KK4mT55MpUqVcHFxwd/fn23btmXbt1WrVphMphuWzp0752FiEePVKVuHtf3WUqZIGXae20n7ee25lHzJ6FgiIvlfyh+w46+JK2r9D0r6GRpHRGyHzRdX4eHhhISEMGbMGHbt2oWvry+BgYGcP38+y/4RERGcO3fOuuzfvx97e3sef/zxPE4uYrw6ZeuwNiijwNpxdgft5rZTgSUicq92hUByPLjVhDpvGJ1GRGyIzRdX48ePZ+DAgQQHB1OrVi2mTp1KkSJFmDlzZpb9S5UqhZeXl3VZvXo1RYoUUXElhVZdz7pEBUVR2rU0O87uoP1cjWCJiNy1s5FwfA5gAv+ZYO9sdCIRsSE2XVylpqayc+dOAgICrG12dnYEBASwZcuW29rHjBkz6N27N0WLFs22T0pKComJiZkWkYKknmc91vZbS2nX0mw/u53AeYEkJCcYHUtEJH+5fhm2DcpYr/EieDQ1No+I2BybLq4uXrxIeno6np6emdo9PT2Ji4u75fbbtm1j//79DBgw4Kb9wsLCcHd3ty4+Pj73lFvEFtXzrGcdwdp2Zhvt57VXgSUicidiQuFqLBStBL7vGp1GRGyQTRdX92rGjBnUrVuXJk2a3LRfaGgoCQkJ1uXUqVN5lFAkb/l6+RIVFEUp11JsO7NNI1giIrfr/CY4Mjlj3X86OGR/R4yIFF42XVyVKVMGe3t74uPjM7XHx8fj5eV1022TkpJYtGgRzz777C1fx9nZGTc3t0yLSEH17wJr65mtdJjfgcQU3QorIpKttGuw9a9/T1R9FrwCbt5fRAotmy6unJycaNiwIVFRUdY2s9lMVFQUTZve/D7nb775hpSUFJ566qncjimS7/h5+VkLrJ9P/0zgvEAVWCIi2dn/Flw+Aq7lof44o9OIiA2z6eIKICQkhOnTpzNnzhwOHjzIkCFDSEpKIjg4GICgoCBCQ0Nv2G7GjBl0796d0qVL53VkkXzBz8uPNU+voaRLSX4+/TMd5mkES0TkBn/shIN/FVSNp4BTCUPjiIhtczA6wK306tWLCxcuMHr0aOLi4vDz8yMyMtI6yUVsbCx2dplrxMOHDxMdHc2PP/5oRGSRfKN+ufpEBUXR9qu2bDm9hQ7zOhD5VCRuzro1VkSE9FT4uT9Y0uG+XlDhEaMTiYiNM1ksFovRIWxNYmIi7u7uJCQk6PtXUijsOreLgK8C+DP5T5r5NCOybyTFnYsbHUsKIb3/Zk/nxgD734G9b4Bzaeh8EFw8jE4kIga4k/dfm78tUERyX4NyDVgTtIYSLiXYfGozHeZ34HLKZaNjiYgYJ+EA7H87Y73hZyqsROS2qLgSEeCvAuvpfwqsjvM7qsASkcLJnJ5xO6A5Fcp3gYpPGp1IRPIJFVciYtWwfENWP72aEi4l+OnUT3SY34E/rv1hdCwRkbz162fw+1ZwdIMmU8BkMjqRiOQTKq5EJJNG5RtZC6zNpzbTbEYzjv953OhYIiJ548ox2DMyY73+R1CkgrF5RCRfUXElIjdoVL4Rm4I34ePmw+HfD/PgjAfZcXaH0bFE8szkyZOpVKkSLi4u+Pv7s23btmz7Xr9+nbFjx1K1alVcXFzw9fUlMjIy2/7vv/8+JpOJ4cOH50JyuScWC2wdCOnXwLM1VB1odCIRyWdUXIlIluqUrcPPA37Gz8uP80nnaTm7Jd8f/t7oWCK5Ljw8nJCQEMaMGcOuXbvw9fUlMDCQ8+fPZ9l/1KhRTJs2jYkTJ3LgwAEGDx5Mjx492L179w19t2/fzrRp06hXr15uH4bcjd++hPi1YO8KTabrdkARuWMqrkQkW+WLl2fjMxsJrBrI1etX6R7enSnbpxgdSyRXjR8/noEDBxIcHEytWrWYOnUqRYoUYebMmVn2nzt3Lq+//jqdOnWiSpUqDBkyhE6dOvHxxx9n6nflyhX69u3L9OnTKVmyZF4cityJq2dg96sZ6/XegeJVjc0jIvmSiisRuanizsX5/snvebb+s5gtZp5f8Tz/W/0/zBaz0dFEclxqaio7d+4kICDA2mZnZ0dAQABbtmzJcpuUlBRcXFwytbm6uhIdHZ2pbejQoXTu3DnTvm8mJSWFxMTETIvkEosFtg+B64lQ2h9qvGR0IhHJp1RcicgtOdo7Mr3rdN5unfHMlw83f0jfiL6kpKUYnEwkZ128eJH09HQ8PT0ztXt6ehIXF5flNoGBgYwfP54jR45gNptZvXo1ERERnDt3ztpn0aJF7Nq1i7CwsNvOEhYWhru7u3Xx8fG5u4OSWzu5CM58D3aO4D8D7OyNTiQi+ZSKKxG5LSaTiVEPj+Kr7l/hYOfAov2LaD+vvaZql0JvwoQJVKtWjZo1a+Lk5MSwYcMIDg7Gzi7jEnvq1Cleeukl5s+ff8MI182EhoaSkJBgXU6dOpVbh1C4xUXBjqEZ67VHQYnaxuYRkXxNxZWI3JGnfZ8msm8kbs5ubDy5keYzm3Pi0gmjY4nkiDJlymBvb098fHym9vj4eLy8vLLcxsPDg2XLlpGUlMTJkyc5dOgQxYoVo0qVKgDs3LmT8+fP06BBAxwcHHBwcGDDhg189tlnODg4kJ6enuV+nZ2dcXNzy7RIDjKnw94xsLYdpP4JpZtArRFGpxKRfE7FlYjcsbZV2hIdHE0FtwocuniIB7/UVO1SMDg5OdGwYUOioqKsbWazmaioKJo2bXrTbV1cXPD29iYtLY0lS5bQrVs3ANq2bcu+ffuIiYmxLo0aNaJv377ExMRgb69b0PLctXOwNgD2jwUsUPVZaLsO7J2MTiYi+ZyD0QFEJH+q61mXn5/9mc4LOrMnfg8tZ7ck/LFwulTvYnQ0kXsSEhJCv379aNSoEU2aNOHTTz8lKSmJ4OBgAIKCgvD29rZ+f2rr1q2cOXMGPz8/zpw5w5tvvonZbOa1114DoHjx4tSpUyfTaxQtWpTSpUvf0C554Nxq2PIUJJ8Hh6LQeBpU7mt0KhEpIDRyJSJ3zdvNm43BG2lftT1Xr1+l26JuTNsxzehYIvekV69ejBs3jtGjR+Pn50dMTAyRkZHWSS5iY2MzTVaRnJzMqFGjqFWrFj169MDb25vo6GhKlChh0BFIlsxpsGcUrAvMKKxK1IUOO1VYiUiOMlksFovRIWxNYmIi7u7uJCQk6B53kdtwPf06g38YzMyYjOcAjWg+gnfbvoudSZ/fyJ3R+2/2dG7uwdUz8NOTcGFTxs/3PwcNPgUHV0NjiUj+cCfvv/qXj4jcM0d7R7585EvGthoLwPs/vc9TEU9pqnYRMd7ZSFjpl1FYORSDZguhyTQVViKSK1RciUiOMJlMvNHyDWZ3m42DnQML9y8kcF4gf1770+hoIlIYmdMgJhTWd4SUi1DSDzrsgkq9jU4mIgWYiisRyVH9/Pqxsu9K3Jzd2HByg6ZqF5G8l3QKolrBgfczfq72PLTfAm7VDI0lIgWfiisRyXEBVQKIDo7Gu7g3By8epOmMpuw8u9PoWCJSGJxZ/tdtgD+BQ3Fo8TU0ngz2t/8AZxGRu6XiSkRyRV3Puvw84GfqedYj7kocLWe3ZMWRFUbHEpGCynwddr8GG7pA6h9QsgF03A33PW50MhEpRFRciUiuqeBWgU3Bm2hXpR1J15N4ZOEjfLHzC6NjiUhBkxQLa1rCwY8yfq7+ArTfDMWrGptLRAodFVcikqvcnN1Y3mc5wX7BpFvSGfTDIF6Peh2zxWx0NBEpCE5/l3Eb4MUt4OgODy2BRp+BvbPRyUSkEFJxJSK5ztHekRmPzODNlm8CEBYdxtNLn9ZU7SJy99JTYdcrsLEbpP4JpRpn3Abo86jRyUSkEFNxJSJ5wmQyMabVGGZ1m4WDnQML9i2gw/wOXEq+ZHQ0EclvrpyANQ/BofEZP9cYDu2ioVhlI1OJiKi4EpG89YzfM6zos4LiTsVZf2I9zWc25+Slk0bHEpH84tQyWFkfft8GjiXg4WXQ8BOwdzI4mIiIiisRMUC7qu2I7p8xVfuBCwd4cMaD7Dq3y+hYImLL0lNgx0uwqQdcvwSl/aFTDFToZnQyERErFVciYoh6nvX4ecDP1C1bl7grcTw862FWHllpdCwRsUVXjsHq5vDrZxk/13wFAjZC0YrG5hIR+Q8VVyJimL+nag+oEkDS9SS6LuzK9J3TjY4lIrYkdknGbYB/7ASnUtDye2gwTrcBiohNUnElIoZyd3FneZ/l9PPtR7olned+eI5Ra0dhsViMjiYiRkpPhu3DIPoxuJ4IZZpBxxjw7mJ0MhGRbKm4EhHDOdk7MavbLMa0HAPAu5veJWhZEKnpqQYnExFDXD4KPzaDI5Mzfn7gNQhYD0V9DI0lInIr+aK4mjx5MpUqVcLFxQV/f3+2bdt20/6XLl1i6NChlCtXDmdnZ6pXr86KFSvyKK2I3A2TycSbrd5k5iMzcbBzYN7eeXSYp6naRQqdk+GwsgH8uRucS0PL5VD/A7BzNDqZiMgt2XxxFR4eTkhICGPGjGHXrl34+voSGBjI+fPns+yfmppKu3btOHHiBIsXL+bw4cNMnz4db2/vPE4uIncjuH4wy/ssp5hTMdadWEeLmS2ITYg1OpaI5Lb0ZNg2BH7qDWmXwaPFX7cBdjI6mYjIbTNZbPyLDf7+/jRu3JhJkyYBYDab8fHx4YUXXmDEiBE39J86dSofffQRhw4dwtHx7j7lSkxMxN3dnYSEBNzc3O4pv4jcnZi4GDov6MzZy2cpV6wcK/quwM/Lz+hYksv0/pu9An1uEn+F6Cfg0h7ABLVDoe5bYOdgdDIRkTt6/7XpkavU1FR27txJQECAtc3Ozo6AgAC2bNmS5TbfffcdTZs2ZejQoXh6elKnTh3ee+890tPTs32dlJQUEhMTMy0iYiw/Lz9+fvZn6pStw7kr53ho1kN8d/g7o2OJSE47sQAiG2YUVs4e0DoSfN9VYSUi+ZJNF1cXL14kPT0dT0/PTO2enp7ExcVluc2xY8dYvHgx6enprFixgjfeeIOPP/6Yd955J9vXCQsLw93d3br4+OgLsyK2wMfdh+jgaNpWbsuV1Ct0W9SN//vx/7ieft3oaCJyr9KuwdbnYHNfSLsCZVtm3AZYrr3RyURE7ppNF1d3w2w2U7ZsWb744gsaNmxIr169GDlyJFOnTs12m9DQUBISEqzLqVOn8jCxiNyMu4s7K/qu4OUHXwZg3JZxtJrTilMJ+nsqkm9d/g1+9IffpgMmqPMGtFkDRcobnUxE5J7YdHFVpkwZ7O3tiY+Pz9QeHx+Pl5dXltuUK1eO6tWrY29vb2174IEHiIuLIzU162mdnZ2dcXNzy7SIiO1wsndifOB4Ip6IwN3Znc2nNlN/Wn0ij0YaHU1E7pTFApv7wKV94OIJbX6EemN1G6CIFAg2XVw5OTnRsGFDoqKirG1ms5moqCiaNm2a5TbNmzfn6NGjmM1ma9uvv/5KuXLlcHLS09xF8rMeD/Rg16BdNCjXgN+v/U7H+R0ZGTWSNHOa0dFE5HadXQ6/bwP7IhC4HbwCbr2NiEg+YdPFFUBISAjTp09nzpw5HDx4kCFDhpCUlERwcDAAQUFBhIaGWvsPGTKEP/74g5deeolff/2V5cuX89577zF06FCjDkFEclCVklX4qf9PPN/oeQDei36PgK8COHv5rMHJROSWLBbYm/GwcKoP00OBRaTAsfkx+F69enHhwgVGjx5NXFwcfn5+REZGWie5iI2Nxc7unxrRx8eHVatW8fLLL1OvXj28vb156aWX+N///mfUIYhIDnNxcGFy58k8XPFhBn4/kA0nN1B/Wn0WPLqAtlXaGh1PRLJz5jv4cxc4FIMH/s/oNCIiOc7mn3NlhAL9LBGRAubX33/l8W8eZ2/8XkyYGNNyDKMeHoW9nf2tNxabo/ff7OX7c2Mxw8oGGVOu1349Y7p1EZF8oMA850pE5Faql67Oz8/+zID6A7Bg4c0Nb9Jhfgfir8TfemMRyTunl2UUVg7FoeYrRqcREckVKq5EJN9zdXRl+iPTmdtjLkUci7Dm2BrqT6vPxpMbjY4mIpAxavX3d61qDgfnUobGERHJLSquRKTAeKreU2wfuJ1aHrU4d+Ucree0JmxTGGaL+dYbi0juiV0MCfvB0R1qvmx0GhGRXKPiSkQKlFoetdg2YBtBvkGYLWZeX/s6XRZ04eLVi0ZHEymczOmw/62M9Zovg1NJY/OIiOQiFVciUuAUdSrK7G6zmfHIDFwcXFh5dCX1p9Vn86nNRkcTKXxiv4aEA+BYAmoMNzqNiEiuUnElIgWSyWSif/3+bB2wleqlq3M68TQtZ7fk480fo0lSRfLIv0etHngVnNyNzSMikstUXIlIgVbPsx47Bu6gd53epJnTeHX1q3QP786f1/40OppIwXdyISQeBqdSUOMFo9OIiOQ6FVciUuAVdy7OgkcXMKXzFJzsnfju8Hc0+KIB289sNzqaSMFlToN9f49a/R845sNnc4mI3CEVVyJSKJhMJgY3GsyWZ7dQpWQVTlw6QfOZzZm4daJuExTJDSfmw5Wj4FwGqg8zOo2ISJ5QcSUihUqDcg3Y9dwuHn3gUa6br/Ni5Is8sfgJEpITjI4mNmTy5MlUqlQJFxcX/P392bZtW7Z9r1+/ztixY6latSouLi74+voSGRmZqc+UKVOoV68ebm5uuLm50bRpU1auXJnbh2Ec83XYPzZj/YHXwLGYsXlERPKIiisRKXTcXdxZ/PhiJnSYgKOdI4sPLKbhFw3ZfW630dHEBoSHhxMSEsKYMWPYtWsXvr6+BAYGcv78+Sz7jxo1imnTpjFx4kQOHDjA4MGD6dGjB7t3//PnqUKFCrz//vvs3LmTHTt20KZNG7p168Yvv/ySV4eVt45/BVeOgUtZqP680WlERPKMyaL7YW6QmJiIu7s7CQkJuLnpHnGRgmzbmW088c0TnEw4ibO9MxM6TOC5hs9hMpmMjlYo2cL7r7+/P40bN2bSpEkAmM1mfHx8eOGFFxgxYsQN/cuXL8/IkSMZOnSota1nz564uroyb968bF+nVKlSfPTRRzz77LO3lcsWzs1tSU+FH2pA0gloMF4PDRaRfO9O3n81ciUihVoT7ybsGrSLrtW7kpKewuDlg3lq6VNcSb1idDQxQGpqKjt37iQgIMDaZmdnR0BAAFu2bMlym5SUFFxcXDK1ubq6Eh0dnWX/9PR0Fi1aRFJSEk2bNs02S0pKComJiZmWfOH47IzCysUL7h9sdBoRkTyl4kpECr1SrqX4tve3fNTuI+xN9izYt4BGXzRiX/w+o6NJHrt48SLp6el4enpmavf09CQuLi7LbQIDAxk/fjxHjhzBbDazevVqIiIiOHfuXKZ++/bto1ixYjg7OzN48GCWLl1KrVq1ss0SFhaGu7u7dfHx8bn3A8xt6Smw/52M9dqh4OBqbB4RkTym4kpEhIzZBF9t9iobntmAd3FvDv9+GP8v/Zm1e5bR0cTGTZgwgWrVqlGzZk2cnJwYNmwYwcHB2NllvsTWqFGDmJgYtm7dypAhQ+jXrx8HDhzIdr+hoaEkJCRYl1OnTuX2ody7YzPh6ilwLQ/3P2d0GhGRPKfiSkTkX5rf15zdg3YTWDWQa2nX6P9df55Z9gxJqUlGR5M8UKZMGezt7YmPj8/UHh8fj5eXV5bbeHh4sGzZMpKSkjh58iSHDh2iWLFiVKlSJVM/Jycn7r//fho2bEhYWBi+vr5MmDAh2yzOzs7W2QX/XmxaejLsfzdjvfbrYO9y8/4iIgWQiisRkf/wKOrBir4reLfNu9iZ7JizZw7+X/pz8MJBo6NJLnNycqJhw4ZERUVZ28xmM1FRUTf9fhSAi4sL3t7epKWlsWTJErp163bT/mazmZSUlBzJbROOTodrZ6BIBag6wOg0IiKGUHElIpIFO5Mdrz/0OlFBUXgV8+KXC7/QeHpj5u3NfvY3KRhCQkKYPn06c+bM4eDBgwwZMoSkpCSCg4MBCAoKIjQ01Np/69atREREcOzYMTZt2kSHDh0wm8289tpr1j6hoaFs3LiREydOsG/fPkJDQ1m/fj19+/bN8+PLFWnX4EBYxnrtUWDvbGweERGDOBgdQETElrWq1IqYQTH0iejD2uNreXrp02w8uZEJHSbg6qgv6xdEvXr14sKFC4wePZq4uDj8/PyIjIy0TnIRGxub6ftUycnJjBo1imPHjlGsWDE6derE3LlzKVGihLXP+fPnCQoK4ty5c7i7u1OvXj1WrVpFu3bt8vrwcsfRaXDtHBStCFWCjU4jImIYPecqC/nmWSIikmfSzem8vfFtxm4YiwUL9TzrMb3rdJp4NzE6WoGi99/s2ey5SbsK31WB5HhoMh3u1y2BIlKw6DlXIiI5zN7Onjdbvcmqp1bhUcSDvfF7efDLBxm6fCiXki8ZHU/EOEemZBRWRStDlX5GpxERMZSKKxGRO9Cuajv2P7+fp+s9jQULn+/4nJqTarJw30J0I4AUOtevwIEPMtbrvAF2jsbmERExmIorEZE7VLZoWb7q8RVRQVHUKF2D+KR4+kT0IXBeIEd+P2J0PJG8c2QypFyAYlWh8tNGpxERMZyKKxGRu9Smchv2DN7D263fxtnemdXHVlN3Sl3GbhhLSloBmmJbJCvXL8PBjzLW64wGO82RJSKi4kpE5B44Ozgz6uFR7H9+P+2rticlPYUx68dQb2o9oo5F3XoHIvnVrxMh5XcoXh0q9TE6jYiITVBxJSKSA+4vdT+RfSMJfyyccsXK8evvvxIwN4C+EX2JuxJndDyRnJWaAAfHZazXHaNRKxGRv6i4EhHJISaTiSdqP8HBoQd5ockLmDCxYN8Cak6qyZTtUzBbzEZHFMkZhz+D1D/B7QG4r5fRaUREbIaKKxGRHObu4s5nHT9j28BtNCzXkISUBJ5f8TzNZjQjJi7G6Hgi9yb1Ehz6OGO97hiwszc0joiILVFxJSKSSxqVb8TWAVuZ2HEixZ2Ks/XMVhp+0ZCQVSFcTrlsdDyRu3PoE7ieAO614b7HjU4jImJTVFyJiOQiezt7hjUZxqFhh+hVuxdmi5lPfv6EByY/wJIDS/RsLMlfUv6Aw59mrNd9E0z6Z4SIyL/li3fFyZMnU6lSJVxcXPD392fbtm3Z9p09ezYmkynT4uLikodpRURuVL54eRY9tojIvpFULVmVM5fP8Ng3j9FlYReO/3nc6Hgit+fQeLieCCXqgc+jRqcREbE5Nl9chYeHExISwpgxY9i1axe+vr4EBgZy/vz5bLdxc3Pj3Llz1uXkyZN5mFhEJHuB9weyb8g+3nj4DRztHFlxZAW1P6/N+9Hvk5qeanQ8kewlX4TDEzLW676lUSsRkSzY/Dvj+PHjGThwIMHBwdSqVYupU6dSpEgRZs6cme02JpMJLy8v6+Lp6ZmHiUVEbs7V0ZWxrceyd8heWldqzbW0a4RGhVJ/Wn02ntxodDyRrB36GNKuQMn6UKGb0WlERGySTRdXqamp7Ny5k4CAAGubnZ0dAQEBbNmyJdvtrly5QsWKFfHx8aFbt2788ssvN32dlJQUEhMTMy0iIrmtZpmaRAVFMbfHXDyKeHDgwgFazm5J/2/7c/HqRaPjifwj+XzGQ4Phr1Erk7F5RERslE0XVxcvXiQ9Pf2GkSdPT0/i4rJ+KGeNGjWYOXMm3377LfPmzcNsNtOsWTNOnz6d7euEhYXh7u5uXXx8fHL0OEREsmMymXiq3lMcHnaYQQ0HATArZhY1JtVg5u6ZejaW2IaDH0FaEpRqBN5djE4jImKzbLq4uhtNmzYlKCgIPz8/WrZsSUREBB4eHkybNi3bbUJDQ0lISLAup06dysPEIiJQ0rUkU7tMZXP/zdTzrMcf1/7g2e+epeXsluw/v9/oeFKYXYuHXydnrGvUSkTkpmy6uCpTpgz29vbEx8dnao+Pj8fLy+u29uHo6Ej9+vU5evRotn2cnZ1xc3PLtIiIGKGpT1N2PreTj9t/TFHHokTHRlN/Wn1GrBlBUmqS0fGkMDrwAaRfg9L+UL6j0WlERGyaTRdXTk5ONGzYkKioKGub2WwmKiqKpk2b3tY+0tPT2bdvH+XKlcutmCIiOcrBzoGQpiEcHHqQHjV7kGZO44OfPqD257X54dcfjI4nhcm1c3B0SsZ6vbEatRIRuQWbLq4AQkJCmD59OnPmzOHgwYMMGTKEpKQkgoODAQgKCiI0NNTaf+zYsfz4448cO3aMXbt28dRTT3Hy5EkGDBhg1CGIiNwVH3cfInpF8F3v76joXpGTCSfpurArj4Y/yqkE3b4seeCX9yE9Gco0A692RqcREbF5Nl9c9erVi3HjxjF69Gj8/PyIiYkhMjLSOslFbGws586ds/b/888/GThwIA888ACdOnUiMTGRzZs3U6tWLaMOQUTknnSt0ZVfnv+F/zX/Hw52Diw9tJQHJj/A+C3jSTOnGR1PCqqrp+HoX99X1qiViMhtMVksFovRIWxNYmIi7u7uJCQk6PtXImJT9p/fz+AfBvPTqZ8A8PX0ZWqXqTxY4UGDk+UMvf9mL8/PzfahcORzKPswtF2v4kpECq07ef+1+ZErERH5R52yddgYvJEZj8yglGsp9sTvodmMZgxdPpQrqVeMjicFRVIs/PZlxrpmCBQRuW0qrkRE8hk7kx396/fn8LDDBPsFY8HC5zs+p+6Uuqw9vtboeFIQ/PIemFPBszV4tjI6jYhIvqHiSkQknypTpAwzu80kKiiKiu4VOXHpBG2/asvzy5/ncsplo+NJfnXlBPw2I2O97luGRhERyW9UXImI5HNtKrdh35B9PN/oeQCm7JhC3Sl1iToWdYstRbLwy7tgSQOvACj7kNFpRETyFRVXIiIFQHHn4kzuPJm1QWupVKISJxNOEjA3gME/DNYolty+y7/BsVkZ6xq1EhG5YyquREQKkNaVW2caxZq2cxp1ptRhzbE1BieTfOGXd8CSDuU6gEczo9OIiOQ7Kq5ERAqYYk7FrKNYlUtUJjYhlnZz2zH4h8EkpiQaHU9sVeIROD43Y12jViIid0XFlYhIAdW6cmv2DtnLsMbDgIxRrLpT6rL6t9UGJxObtP/tjFGr8p2hTBOj04iI5EsqrkRECrBiTsWY2Gki6/qto0rJKsQmxNJ+Xnue+/45jWLJPxIPw8n5Get13zQ0iohIfqbiSkSkEGhVqRV7B/8zijV913TqfF6HH3/70eBkYhP2jQWLGbwfgdKNjE4jIpJvqbgSESkkijoVZWKniazvt54qJatwKvEUgfMCNYpV2CUcgJMLM9Y1aiUick9UXImIFDItK7Vk7+C9vNjkReCfUaxVR1cZnEwMse8twAIVekCp+kanERHJ11RciYgUQkWdijKh4wQ2PLOBqiWrcirxFB3md2DAdwNISE4wOp7klUv7IPabjHWNWomI3DMVVyIihdjDFR9mz+A91lGsGbtnUGeKRrEmT55MpUqVcHFxwd/fn23btmXb9/r164wdO5aqVavi4uKCr68vkZGRmfqEhYXRuHFjihcvTtmyZenevTuHDx/O7cO4tb9Hre57HErWMzqNiEi+p+JKRKSQ++8o1unE04V6FCs8PJyQkBDGjBnDrl278PX1JTAwkPPnz2fZf9SoUUybNo2JEydy4MABBg8eTI8ePdi9e7e1z4YNGxg6dCg///wzq1ev5vr167Rv356kpKS8Oqwb/RkDp5YAJqgzxrgcIiIFiMlisViMDmFrEhMTcXd3JyEhATc3N6PjiIjkmavXrzIyaiQTtk7AgoUKbhX4ossXdKzWMU9e3xbef/39/WncuDGTJk0CwGw24+PjwwsvvMCIESNu6F++fHlGjhzJ0KFDrW09e/bE1dWVefPmZfkaFy5coGzZsmzYsIGHH374tnLl+LnZ2ANOL4OKvaH5wnvfn4hIAXUn778auRIREasijkX4pMMnbAzeyP2l7ud04mk6LehE/2/7cyn5ktHxcl1qaio7d+4kICDA2mZnZ0dAQABbtmzJcpuUlBRcXFwytbm6uhIdHZ3t6yQkZIwIlipVKts+KSkpJCYmZlpyzB87Mwork51GrUREcpCKKxERuUGL+1qwZ/AehvsPx4SJWTGzqPN5HVYcWWF0tFx18eJF0tPT8fT0zNTu6elJXFxcltsEBgYyfvx4jhw5gtlsZvXq1URERHDu3Lks+5vNZoYPH07z5s2pU6dOtlnCwsJwd3e3Lj4+Pnd/YP+1982M/1Z8Etxr5tx+RUQKORVXIiKSpX+PYlUrVY0zl8/QeUFngr8NLhSjWLdrwoQJVKtWjZo1a+Lk5MSwYcMIDg7Gzi7rS+zQoUPZv38/ixYtuul+Q0NDSUhIsC6nTp3KmcC/b4ezP/w1ajU6Z/YpIiKAiisREbmFFve1IGZwDCEPhmDCxOyY2dT+vHaBHMUqU6YM9vb2xMfHZ2qPj4/Hy8sry208PDxYtmwZSUlJnDx5kkOHDlGsWDGqVKlyQ99hw4bxww8/sG7dOipUqHDTLM7Ozri5uWVacsTev24DrPQ0uFXPmX2KiAig4kpERG5DEccifBz4MdH9o6leujpnL5+l84LOPLPsGf689qfR8XKMk5MTDRs2JCoqytpmNpuJioqiadOmN93WxcUFb29v0tLSWLJkCd26dbP+zmKxMGzYMJYuXcratWupXLlyrh3DTV3YAudWgske6rxhTAYRkQJMxZWIiNy2Zj7NiBn0zyjWnD1zqDOlDst/XW50tBwTEhLC9OnTmTNnDgcPHmTIkCEkJSURHBwMQFBQEKGhodb+W7duJSIigmPHjrFp0yY6dOiA2Wzmtddes/YZOnQo8+bNY8GCBRQvXpy4uDji4uK4du1a3h7cvjcz/lu5HxSvmrevLSJSCKi4EhGRO+Lq6HrDKFaXhV3ot6xfgRjF6tWrF+PGjWP06NH4+fkRExNDZGSkdZKL2NjYTJNVJCcnM2rUKGrVqkWPHj3w9vYmOjqaEiVKWPtMmTKFhIQEWrVqRbly5axLeHh43h3Y+WiI+xFMDlBnVN69rohIIaLnXGXBFp6zIiKSH1y7fo3R60bz8ZaPsWChXLFyfNH1C7pU73JX+9P7b/bu+dxEtYX4tVB1IPh/kfMBRUQKKD3nSkRE8oSroysftf+In/r/RI3SNTh35RxdF3Zl3OZxRkeTf4vfkFFY2TlCnZFGpxERKbBUXImIyD1r6tOU3YN282rTV3FzdqPnAz2NjiT/ZkkHt5pQdQAUrWh0GhGRAku3BWZBt6WIiNy936/+Tukipe9qW73/Zu+ez405HdKvgWOxnA8nIlKA3cn7r0MeZRIRkULibgsryWV29mCnwkpEJDfptkAREREREZEcoOJKREREREQkB+SL4mry5MlUqlQJFxcX/P392bZt221tt2jRIkwmE927d8/dgCIiIiIiUujZfHEVHh5OSEgIY8aMYdeuXfj6+hIYGMj58+dvut2JEyd49dVXeeihh/IoqYiIiIiIFGY2X1yNHz+egQMHEhwcTK1atZg6dSpFihRh5syZ2W6Tnp5O3759eeutt6hSpcotXyMlJYXExMRMi4iIiIiIyJ2w6eIqNTWVnTt3EhAQYG2zs7MjICCALVu2ZLvd2LFjKVu2LM8+++xtvU5YWBju7u7WxcfH556zi4iIiIhI4WLTxdXFixdJT0/H09MzU7unpydxcXFZbhMdHc2MGTOYPn36bb9OaGgoCQkJ1uXUqVP3lFtERERERAqfAvWcq8uXL/P0008zffp0ypQpc9vbOTs74+zsnIvJRERERESkoLPp4qpMmTLY29sTHx+fqT0+Ph4vL68b+v/222+cOHGCrl27WtvMZjMADg4OHD58mKpVq+ZuaBERERERKZRs+rZAJycnGjZsSFRUlLXNbDYTFRVF06ZNb+hfs2ZN9u3bR0xMjHV55JFHaN26NTExMfoulYiIiIiI5BqbHrkCCAkJoV+/fjRq1IgmTZrw6aefkpSURHBwMABBQUF4e3sTFhaGi4sLderUybR9iRIlAG5oFxERERERyUk2X1z16tWLCxcuMHr0aOLi4vDz8yMyMtI6yUVsbCx2djY9ACciIiIiIoWAyWKxWIwOYWsSEhIoUaIEp06dws3Nzeg4IiKFRmJiIj4+Ply6dAl3d3ej49gUXZtERIxxJ9cmmx+5MsLly5cB9B0tERGDXL58WcXVf+jaJCJirNu5NmnkKgtms5mzZ89SvHhxTCbTHW//d3WrTxdvpHOTPZ2bm9P5yV5BOjcWi4XLly9Tvnx53fL9H7o25R6dm+zp3GRP5yZ7Be3c3Mm1SSNXWbCzs6NChQr3vB83N7cC8QcqN+jcZE/n5uZ0frJXUM6NRqyypmtT7tO5yZ7OTfZ0brJXkM7N7V6b9LGgiIiIiIhIDlBxJSIiIiIikgNUXOUCZ2dnxowZg7Ozs9FRbI7OTfZ0bm5O5yd7OjdyO/TnJHs6N9nTucmezk32CvO50YQWIiIiIiIiOUAjVyIiIiIiIjlAxZWIiIiIiEgOUHElIiIiIiKSA1RciYiIiIiI5AAVV7lg8uTJVKpUCRcXF/z9/dm2bZvRkQwXFhZG48aNKV68OGXLlqV79+4cPnzY6Fg26f3338dkMjF8+HCjo9iEM2fO8NRTT1G6dGlcXV2pW7cuO3bsMDqW4dLT03njjTeoXLkyrq6uVK1albfffhvNUSRZ0XUpa7o23R5dl26ka1PWdG1ScZXjwsPDCQkJYcyYMfw/e3ceV0W9/3H8ddhRARcQXHA3931BXLLMXDO3X6lRGC7dzMyy5UaLlvealllmmppmWmqaZmqLW5T7GriQ+wouLK4gqICc8/vj5CkuYKLAHOD9fDzm4TDznTnvOeV8/TAz34mIiKBRo0Z07tyZ+Ph4o6MZasOGDQwfPpzt27ezbt060tLS6NSpE8nJyUZHsyu7du1i5syZNGzY0OgoduHy5cu0adMGZ2dnVq1axYEDB5g0aRKlSpUyOprh3n//faZPn87UqVM5ePAg77//Ph988AGffvqp0dHEzqhfyp76pn+mfikz9U3ZU9+kodhzXUBAAC1atGDq1KkAmM1m/P39GTFiBK+//rrB6ezH+fPnKVu2LBs2bOD+++83Oo5dSEpKomnTpnz22Wf897//pXHjxkyePNnoWIZ6/fXX2bJlC5s2bTI6it155JFH8PX15YsvvrAt69u3L+7u7syfP9/AZGJv1C/dOfVNGalfypr6puypb9KVq1yVmppKeHg4HTt2tC1zcHCgY8eObNu2zcBk9ichIQGA0qVLG5zEfgwfPpzu3btn+P+nqFu5ciXNmzfnscceo2zZsjRp0oRZs2YZHcsutG7dmrCwMI4cOQLA3r172bx5M127djU4mdgT9Us5o74pI/VLWVPflD31TeBkdIDC5MKFC6Snp+Pr65thua+vL4cOHTIolf0xm828+OKLtGnThvr16xsdxy4sWrSIiIgIdu3aZXQUu3LixAmmT5/OqFGjeOONN9i1axcvvPACLi4uDBw40Oh4hnr99ddJTEykdu3aODo6kp6ezrhx4wgKCjI6mtgR9Ut3Tn1TRuqXsqe+KXvqm1RciQGGDx/OH3/8webNm42OYhdOnz7NyJEjWbduHW5ubkbHsStms5nmzZvz3nvvAdCkSRP++OMPZsyYUeQ7sG+//ZYFCxawcOFC6tWrx549e3jxxRcpX758kf9uRO6G+qa/qF+6PfVN2VPfpOIqV3l7e+Po6EhcXFyG5XFxcfj5+RmUyr48//zz/Pjjj2zcuJGKFSsaHccuhIeHEx8fT9OmTW3L0tPT2bhxI1OnTiUlJQVHR0cDExqnXLly1K1bN8OyOnXq8N133xmUyH68+uqrvP766/Tv3x+ABg0aEBUVxfjx44tMByb/TP3SnVHflJH6pdtT35Q99U165ipXubi40KxZM8LCwmzLzGYzYWFhBAYGGpjMeBaLheeff57vv/+eX3/9lapVqxodyW489NBDREZGsmfPHtvUvHlzgoKC2LNnT5HuwNq0aZNpWOQjR45QuXJlgxLZj2vXruHgkPEU7ujoiNlsNiiR2CP1S7envilr6pduT31T9tQ36cpVrhs1ahQDBw6kefPmtGzZksmTJ5OcnExISIjR0Qw1fPhwFi5cyIoVK/Dw8CA2NhYALy8v3N3dDU5nLA8Pj0z39xcvXpwyZcoU+fv+X3rpJVq3bs17773H448/zs6dO/n888/5/PPPjY5muB49ejBu3DgqVapEvXr12L17Nx999BGDBg0yOprYGfVL2VPflDX1S7envil76psAi+S6Tz/91FKpUiWLi4uLpWXLlpbt27cbHclwQJbTl19+aXQ0u9S+fXvLyJEjjY5hF3744QdL/fr1La6urpbatWtbPv/8c6Mj2YXExETLyJEjLZUqVbK4ublZqlWrZnnzzTctKSkpRkcTO6R+KWvqm+6c+qWM1DdlTX2TxaL3XImIiIiIiOQCPXMlIiIiIiKSC1RciYiIiIiI5AIVVyIiIiIiIrlAxZWIiIiIiEguUHElIiIiIiKSC1RciYiIiIiI5AIVVyIiIiIiIrlAxZWIiIiIiEguUHElUoSZTCaWL19udAwRERFA/ZIUfCquRAzy9NNPYzKZMk1dunQxOpqIiBRB6pdE7p2T0QFEirIuXbrw5ZdfZljm6upqUBoRESnq1C+J3BtduRIxkKurK35+fhmmUqVKAdZbI6ZPn07Xrl1xd3enWrVqLF26NMP2kZGRdOjQAXd3d8qUKcMzzzxDUlJShjZz5syhXr16uLq6Uq5cOZ5//vkM6y9cuEDv3r0pVqwYNWvWZOXKlbZ1ly9fJigoCB8fH9zd3alZs2amTldERAoP9Usi90bFlYgde/vtt+nbty979+4lKCiI/v37c/DgQQCSk5Pp3LkzpUqVYteuXSxZsoRffvklQyc1ffp0hg8fzjPPPENkZCQrV66kRo0aGT7j3Xff5fHHH2ffvn1069aNoKAgLl26ZPv8AwcOsGrVKg4ePMj06dPx9vbOvy9ARETsivolkX9gERFDDBw40OLo6GgpXrx4hmncuHEWi8ViASzPPvtshm0CAgIsw4YNs1gsFsvnn39uKVWqlCUpKcm2/qeffrI4ODhYYmNjLRaLxVK+fHnLm2++mW0GwPLWW2/Zfk5KSrIAllWrVlksFoulR48elpCQkNw5YBERsWvql0TunZ65EjHQgw8+yPTp0zMsK126tG0+MDAww7rAwED27NkDwMGDB2nUqBHFixe3rW/Tpg1ms5nDhw9jMpk4d+4cDz300G0zNGzY0DZfvHhxPD09iY+PB2DYsGH07duXiIgIOnXqRK9evWjduvVdHauIiNg/9Usi90bFlYiBihcvnul2iNzi7u5+R+2cnZ0z/GwymTCbzQB07dqVqKgofv75Z9atW8dDDz3E8OHD+fDDD3M9r4iIGE/9ksi90TNXInZs+/btmX6uU6cOAHXq1GHv3r0kJyfb1m/ZsgUHBwdq1aqFh4cHVapUISws7J4y+Pj4MHDgQObPn8/kyZP5/PPP72l/IiJScKlfErk9XbkSMVBKSgqxsbEZljk5Odkezl2yZAnNmzenbdu2LFiwgJ07d/LFF18AEBQUxJgxYxg4cCDvvPMO58+fZ8SIETz11FP4+voC8M477/Dss89StmxZunbtytWrV9myZQsjRoy4o3yjR4+mWbNm1KtXj5SUFH788UdbJyoiIoWP+iWRe6PiSsRAq1evply5chmW1apVi0OHDgHWEZMWLVrEc889R7ly5fjmm2+oW7cuAMWKFWPNmjWMHDmSFi1aUKxYMfr27ctHH31k29fAgQO5ceMGH3/8Ma+88gre3t783//93x3nc3FxITQ0lFOnTuHu7k67du1YtGhRLhy5iIjYI/VLIvfGZLFYLEaHEJHMTCYT33//Pb169TI6ioiIiPolkTugZ65ERERERERygYorERERERGRXKDbAkVERERERHKBrlyJiIiIiIjkAhVXIiIiIiIiuUDFlYiIiIiISC5QcSVyl06dOoXJZGLu3Lm2Ze+88w4mk+mOtjeZTLzzzju5mumBBx7ggQceyNV93on169djMplYv359vn+2iEhBpX5EpPBRcSVFwqOPPkqxYsW4evVqtm2CgoJwcXHh4sWL+Zgs5w4cOMA777zDqVOnjI4iIlJkqB8RkTuh4kqKhKCgIK5fv87333+f5fpr166xYsUKunTpQpkyZe76c9566y2uX79+19vfiQMHDvDuu+9m2SmuXbuWtWvX5unni4gURepHROROqLiSIuHRRx/Fw8ODhQsXZrl+xYoVJCcnExQUdE+f4+TkhJub2z3t4164uLjg4uJi2OeLiBRW6kfk75KTk42OIHZKxZUUCe7u7vTp04ewsDDi4+MzrV+4cCEeHh48+uijXLp0iVdeeYUGDRpQokQJPD096dq1K3v37v3Hz8nqXvmUlBReeuklfHx8bJ9x5syZTNtGRUXx3HPPUatWLdzd3SlTpgyPPfZYht8szp07l8ceewyABx98EJPJlOFZp6zulY+Pj2fw4MH4+vri5uZGo0aNmDdvXoY2t+77//DDD/n888+pXr06rq6utGjRgl27dv3jcWdnyZIlNGvWDHd3d7y9vXnyySc5e/ZshjaxsbGEhIRQsWJFXF1dKVeuHD179sxw3L///judO3fG29sbd3d3qlatyqBBg+46l4hITqkfydt+JCff2Y0bN3jnnXe47777cHNzo1y5cvTp04fjx4/b2pjNZj755BMaNGiAm5sbPj4+dOnShd9//z1D3r8/73bL/z7Lduu/yYEDB3jiiScoVaoUbdu2BWDfvn08/fTTVKtWDTc3N/z8/Bg0aFCWt4aePXuWwYMHU758eVxdXalatSrDhg0jNTWVEydOYDKZ+PjjjzNtt3XrVkwmE998880/fo9iPCejA4jkl6CgIObNm8e3337L888/b1t+6dIl1qxZw4ABA3B3d2f//v0sX76cxx57jKpVqxIXF8fMmTNp3749Bw4coHz58jn63CFDhjB//nyeeOIJWrduza+//kr37t0ztdu1axdbt26lf//+VKxYkVOnTjF9+nQeeOABDhw4QLFixbj//vt54YUXmDJlCm+88QZ16tQBsP35v65fv84DDzzAsWPHeP7556latSpLlizh6aef5sqVK4wcOTJD+4ULF3L16lX+9a9/YTKZ+OCDD+jTpw8nTpzA2dk5R8c9d+5cQkJCaNGiBePHjycuLo5PPvmELVu2sHv3bkqWLAlA37592b9/PyNGjKBKlSrEx8ezbt06oqOjbT936tQJHx8fXn/9dUqWLMmpU6dYtmxZjvKIiNwr9SN514+cOHHijr6z9PR0HnnkEcLCwujfvz8jR47k6tWrrFu3jj/++IPq1asDMHjwYObOnUvXrl0ZMmQIN2/eZNOmTWzfvp3mzZvn6Pu/5bHHHqNmzZq89957WCwWANatW8eJEycICQnBz8+P/fv38/nnn7N//362b99uK5TPnTtHy5YtuXLlCs888wy1a9fm7NmzLF26lGvXrlGtWjXatGnDggULeOmllzJ87oIFC/Dw8KBnz553lVvymUWkiLh586alXLlylsDAwAzLZ8yYYQEsa9assVgsFsuNGzcs6enpGdqcPHnS4urqahk7dmyGZYDlyy+/tC0bM2aM5e9/rfbs2WMBLM8991yG/T3xxBMWwDJmzBjbsmvXrmXKvG3bNgtg+eqrr2zLlixZYgEsv/32W6b27du3t7Rv39728+TJky2AZf78+bZlqamplsDAQEuJEiUsiYmJGY6lTJkylkuXLtnarlixwgJYfvjhh0yf9Xe//fZbhkypqamWsmXLWurXr2+5fv26rd2PP/5oASyjR4+2WCwWy+XLly2AZeLEidnu+/vvv7cAll27dt02g4hIXlM/YpUX/cidfmdz5syxAJaPPvoo0z7MZrPFYrFYfv31VwtgeeGFF7Jtk9V3f8v/fq+3/psMGDAgU9usvvNvvvnGAlg2btxoWxYcHGxxcHDIsi+7lWnmzJkWwHLw4EHbutTUVIu3t7dl4MCBmbYT+6TbAqXIcHR0pH///mzbti3DLRILFy7E19eXhx56CABXV1ccHKx/NdLT07l48SIlSpSgVq1aRERE5Ogzf/75ZwBeeOGFDMtffPHFTG3d3d1t82lpaVy8eJEaNWpQsmTJHH/u3z/fz8+PAQMG2JY5OzvzwgsvkJSUxIYNGzK079evH6VKlbL93K5dO8D6G8Wc+P3334mPj+e5557L8OxA9+7dqV27Nj/99BNgPWYXFxfWr1/P5cuXs9zXrStcP/74I2lpaTnKISKSm9SPWOVFP3Kn39l3332Ht7c3I0aMyLSPW1eJvvvuO0wmE2PGjMm2zd149tlnMy37+3d+48YNLly4QKtWrQBsuc1mM8uXL6dHjx5ZXjW7lenxxx/Hzc2NBQsW2NatWbOGCxcu8OSTT951bslfKq6kSLn1oPGtB5LPnDnDpk2b6N+/P46OjoD1JPjxxx9Ts2ZNXF1d8fb2xsfHh3379pGQkJCjz4uKisLBwcF2m8IttWrVytT2+vXrjB49Gn9//wyfe+XKlRx/7t8/v2bNmrYO65Zbt39ERUVlWF6pUqUMP9/qILMrfG73uZD1cdauXdu23tXVlffff59Vq1bh6+vL/fffzwcffEBsbKytffv27enbty/vvvsu3t7e9OzZky+//JKUlJQcZRIRyQ3qR6xyux+50+/s+PHj1KpVCyen7J9sOX78OOXLl6d06dL/fIA5ULVq1UzLLl26xMiRI/H19cXd3R0fHx9bu1u5z58/T2JiIvXr17/t/kuWLEmPHj0yDJqyYMECKlSoQIcOHXLxSCQvqbiSIqVZs2bUrl3b9lDoN998g8ViyTC603vvvceoUaO4//77mT9/PmvWrGHdunXUq1cPs9mcZ9lGjBjBuHHjePzxx/n2229Zu3Yt69ato0yZMnn6uX936x8G/8vy573leeHFF1/kyJEjjB8/Hjc3N95++23q1KnD7t27Aetv9JYuXcq2bdt4/vnnOXv2LIMGDaJZs2YkJSXlWS4RkayoH7m9u+1H8vs7y+4KVnp6erbb/P0q1S2PP/44s2bN4tlnn2XZsmWsXbuW1atXA9xV7uDgYE6cOMHWrVu5evUqK1euZMCAAZmKW7FfGtBCipygoCDefvtt9u3bx8KFC6lZsyYtWrSwrV+6dCkPPvggX3zxRYbtrly5gre3d44+q3LlypjNZttv2m45fPhwprZLly5l4MCBTJo0ybbsxo0bXLlyJUO7nNzSULlyZfbt24fZbM5wYj506JBtfV64td/Dhw9n+m3b4cOHM31u9erVefnll3n55Zc5evQojRs3ZtKkScyfP9/WplWrVrRq1Ypx48axcOFCgoKCWLRoEUOGDMmTYxARyY76kdzvR+70O6tevTo7duwgLS0t2wEyqlevzpo1a7h06VK2V69uXVH73+/mf6/E3c7ly5cJCwvj3XffZfTo0bblR48ezdDOx8cHT09P/vjjj3/cZ5cuXfDx8WHBggUEBARw7do1nnrqqTvOJMZTGSxFzq3fLo4ePZo9e/ZkeieJo6Njpt+wLVmyJNMQ4neia9euAEyZMiXD8smTJ2dqm9Xnfvrpp5l+i1a8eHEgc4eQlW7duhEbG8vixYtty27evMmnn35KiRIlaN++/Z0cRo41b96csmXLMmPGjAy3761atYqDBw/aRrm6du0aN27cyLBt9erV8fDwsG13+fLlTN9L48aNAXRroIgYQv1I7vcjd/qd9e3blwsXLjB16tRM+7i1fd++fbFYLLz77rvZtvH09MTb25uNGzdmWP/ZZ5/lKPPf93nL//63cXBwoFevXvzwww+2oeCzygTW95wNGDCAb7/9lrlz59KgQQMaNmx4x5nEeLpyJUVO1apVad26NStWrADI1Ck+8sgjjB07lpCQEFq3bk1kZCQLFiygWrVqOf6sxo0bM2DAAD777DMSEhJo3bo1YWFhHDt2LFPbRx55hK+//hovLy/q1q3Ltm3b+OWXXyhTpkymfTo6OvL++++TkJCAq6srHTp0oGzZspn2+cwzzzBz5kyefvppwsPDqVKlCkuXLmXLli1MnjwZDw+PHB/TnXB2dub9998nJCSE9u3bM2DAANtQ7FWqVLENM3vkyBEeeughHn/8cerWrYuTkxPff/89cXFx9O/fH4B58+bx2Wef0bt3b6pXr87Vq1eZNWsWnp6edOvWLU/yi4jcjvqR3O9H7vQ7Cw4O5quvvmLUqFHs3LmTdu3akZyczC+//MJzzz1Hz549efDBB3nqqaeYMmUKR48epUuXLpjNZjZt2sSDDz5oG0Z/yJAhTJgwgSFDhtC8eXM2btzIkSNH7jizp6en7VnhtLQ0KlSowNq1azl58mSmtu+99x5r166lffv2PPPMM9SpU4eYmBiWLFnC5s2bbYM33TrGKVOm8Ntvv/H+++/f3RcqxjFghEIRw02bNs0CWFq2bJlp3Y0bNywvv/yypVy5chZ3d3dLmzZtLNu2bcs0PO2dDKFrsVgs169ft7zwwguWMmXKWIoXL27p0aOH5fTp05mGer18+bIlJCTE4u3tbSlRooSlc+fOlkOHDlkqV66caQjWWbNmWapVq2ZxdHTMMJzu/2a0WCyWuLg4235dXFwsDRo0yDT07K1jyWpI9P/NmZX/HYr9lsWLF1uaNGlicXV1tZQuXdoSFBRkOXPmjG39hQsXLMOHD7fUrl3bUrx4cYuXl5clICDA8u2339raREREWAYMGGCpVKmSxdXV1VK2bFnLI488Yvn9999vm0lEJC+pH/kyQ5t77Ufu9DuzWKzDn7/55puWqlWrWpydnS1+fn6W//u//7McP37c1ubmzZuWiRMnWmrXrm1xcXGx+Pj4WLp27WoJDw/PsJ/BgwdbvLy8LB4eHpbHH3/cEh8fn+1Q7OfPn8+U+8yZM5bevXtbSpYsafHy8rI89thjlnPnzmV5zFFRUZbg4GCLj4+PxdXV1VKtWjXL8OHDLSkpKZn2W69ePYuDg0OGPlMKBpPFkodPqouIiIiISI40adKE0qVLExYWZnQUySE9cyUiIiIiYid+//139uzZQ3BwsNFR5C7oypWIiIiIiMH++OMPwsPDmTRpEhcuXODEiRO4ubkZHUtySFeuREREREQMtnTpUkJCQkhLS+Obb75RYVVA6cqViIiIiIhILtCVKxERERERkVyg4kpERERERCQX6CXCWTCbzZw7dw4PDw9MJpPRcUREigyLxcLVq1cpX748Dg76/d/fqW8SETFGTvomFVdZOHfuHP7+/kbHEBEpsk6fPk3FihWNjmFX1DeJiBjrTvomuymuJkyYQGhoKCNHjmTy5MlZttm/fz+jR48mPDycqKgoPv74Y1588cVM7aZNm8bEiROJjY2lUaNGfPrpp7Rs2fKOs3h4eADWL9DT0/NuDkdERO5CYmIi/v7+tvOw/EV9k4iIMXLSN9lFcbVr1y5mzpxJw4YNb9vu2rVrVKtWjccee4yXXnopyzaLFy9m1KhRzJgxg4CAACZPnkznzp05fPgwZcuWvaM8t2638PT0VAcmImIA3faWmfomERFj3UnfZPgN7UlJSQQFBTFr1ixKlSp127YtWrRg4sSJ9O/fH1dX1yzbfPTRRwwdOpSQkBDq1q3LjBkzKFasGHPmzMmL+CIiIiIiIoAdFFfDhw+ne/fudOzY8Z73lZqaSnh4eIZ9OTg40LFjR7Zt25btdikpKSQmJmaYREREREREcsLQ4mrRokVEREQwfvz4XNnfhQsXSE9Px9fXN8NyX19fYmNjs91u/PjxeHl52SY9MCwiIiIiIjllWHF1+vRpRo4cyYIFC3BzczMqBgChoaEkJCTYptOnTxuaR0RERERECh7DBrQIDw8nPj6epk2b2palp6ezceNGpk6dSkpKCo6Ojjnap7e3N46OjsTFxWVYHhcXh5+fX7bbubq6ZvsMl4iIiIiIyJ0w7MrVQw89RGRkJHv27LFNzZs3JygoiD179uS4sAJwcXGhWbNmhIWF2ZaZzWbCwsIIDAzMzfgiIiIiIiIZGHblysPDg/r162dYVrx4ccqUKWNbHhwcTIUKFWzPZKWmpnLgwAHb/NmzZ9mzZw8lSpSgRo0aAIwaNYqBAwfSvHlzWrZsyeTJk0lOTiYkJCQfj05ERERERIoau3jPVXaio6NxcPjr4tq5c+do0qSJ7ecPP/yQDz/8kPbt27N+/XoA+vXrx/nz5xk9ejSxsbE0btyY1atXZxrkQkREREREJDeZLBaLxegQ9iYxMREvLy8SEhL0okYRkXyk82/29N2IiBgjJ+dfw99zJSIiIiIiUhiouBIREREREckFKq5yWbo5ndXHVjNu4zijo4iIyF2aNm0aVapUwc3NjYCAAHbu3Hnb9leuXGH48OGUK1cOV1dX7rvvPn7++ed72qeIiOSCm8lwZgXsn5AvH2fXA1oURFEJUXRd0BUTJp5q9BSVvCoZHUlERHJg8eLFjBo1ihkzZhAQEMDkyZPp3Lkzhw8fpmzZspnap6am8vDDD1O2bFmWLl1KhQoViIqKomTJkne9TxGRHEm/AWd/AgcX8G0PzkX8ucykk9bv49yPELcezClgcoAaQ8G1TJ5+tAa0yMK9PjT80FcP8evJX3mn/TuMeWBMHiQUESmc7GHQhoCAAFq0aMHUqVMB6/sS/f39GTFiBK+//nqm9jNmzGDixIkcOnQIZ2fnXNlnVuzhuxERO3M9Do5Oh6OfQcp56zKTI3i3At+OUO5hKNMSHLI+NxUa5ptwYetfBVXCgYzri1eBCo9A3VAoVj7Hu8/J+VdXrvLAkCZD+PXkr8zZM4e37n8LR4ecvxBZRETyX2pqKuHh4YSGhtqWOTg40LFjR7Zt25blNitXriQwMJDhw4ezYsUKfHx8eOKJJ/j3v/+No6PjXe0TICUlhZSUFNvPiYmJuXCEIlIoXPkDDn0Mp+aDOdW6rFhFcHCFpONwfot1+uNdcPIA3wfA72Hw6wietcFkMjR+rki5COdWW4upc6sh7cpf60yO4NMGyj8CFbqDZ518O2YVV3mgd53elHIrRXRCNL+c+IXONTobHUlERO7AhQsXSE9Pz/RuRF9fXw4dOpTlNidOnODXX38lKCiIn3/+mWPHjvHcc8+RlpbGmDFj7mqfAOPHj+fdd9+994MSkcLBYoaYNdaiKnbdX8vLtITao8C/j/UKVdJJiP3FOsWFWYuQsz9YJwD3CtYiy+9h8HsI3P2MOZ6cslgg4Y+/rk5d2Gb9Tm5xKQ3lu1oLqvKdwaWUITFVXOUBNyc3nmr4FFN2TmH27tkqrkRECjGz2UzZsmX5/PPPcXR0pFmzZpw9e5aJEycyZszd3xoeGhrKqFGjbD8nJibi7++fG5FFpCC5eR1OfW0tqhL//IWMyQEq9oHaL4F3YMarMiWqWp8tqjHUWnxc3mMtxmJ/gfhNcP0snJxnnQBKNvjrFsKy94NT8Xw/xGzdvA5xv1mLqbM/wbXojOtLNvjr6lSZVmAHd4upuMojQ5oOYcrOKaw4tIL45HjKFtcDyyIi9s7b2xtHR0fi4uIyLI+Li8PPL+vf7pYrVw5nZ2ccHf/q1OvUqUNsbCypqal3tU8AV1dXXF1d7+FoRKRAux4DR6bBsRnWq09gvcWv+hCo9QKUqPLP+zA5QOmm1qnuv63FyvnNf17ZWgeXd8OVSOt0+GPrlS/v1n/dQli6ef4XLNfOWAupsz9ar7ylX/9rnaMb+D5kLabKd4fi9jdwnIqrPNLAtwEBFQLYcXYHX+39ildav2J0JBER+QcuLi40a9aMsLAwevXqBVivTIWFhfH8889nuU2bNm1YuHAhZrMZBwfrG06OHDlCuXLlcHFxAcjxPkWkCLu8x3qVKuobMKdZlxWvArVGQvVB9zYSoJO79QpVuYeB9+HGeYj79a9iKzkK4jdYp31vgXNJ8H3Q2t63I3jUyP1nl8zpcHHnX1enruzNuL5Yxb+uTvl2AKdiufv5uUzFVR4a0nQIO87uYHbEbF4OfBlTYXh4UESkkBs1ahQDBw6kefPmtGzZksmTJ5OcnExISAgAwcHBVKhQgfHjxwMwbNgwpk6dysiRIxkxYgRHjx7lvffe44UXXrjjfYpIEWcxWwuLwx9bb4O7xacN1HoJKvYEhzz4Z7ubD1TuZ50sFutgGLHrIGadtehKuwJnvrdOAMUr//W8lu9D4OZ9d5+besX6/NjZnyBmFaRc+NtKk/VWxwrdrUVVyQYFagAOFVd5qF+9fry4+kUOXzzMltNbaFuprdGRRETkH/Tr14/z588zevRoYmNjady4MatXr7YNSBEdHW27QgXg7+/PmjVreOmll2jYsCEVKlRg5MiR/Pvf/77jfYpIEXUzGU7Mg8OT4epR6zKTI1R6zFpUebfMvywmk/XKlEcNqDnMOrz5pfC/rmpd2Gq9snX8C+sEUKrJX7cQ+rS1XhnLisUCiYf/ujp1fhNY0v9a7+wF5bpYh0sv1+XuizY7oPdcZSE33yUyZOUQvtj9BQMbDWRur7m5E1BEpJDSu5yyp+9GpBC5dhaOTIVjMyH1snWZsxfUeAbuGwHF7XDwmpvJEL/xr2LrSmTG9Q6u1gKr3K0h3+tai6hbo/slncjY3rPOX1enfFrb9bu4cnL+VXGVhdzswLaf2U7gF4G4O7lz7uVzlHQrmTshRUQKIRUQ2dN3I1IIXPzd+jxV9LdguWldVqKG9Xmqak+DcwlD4+XI9ViIDftzJMJ1cP3c/zQwAX8rMxxcoOwD1qtTFbpDiWr5GPbe6CXCdiSgQgD1y9bnj/g/+CbyG4a1GGZ0JBERERHJL+Z0OLvSWlSd3/TX8rLtrUOpl3/ELoYQzzF3P6gaZJ0sFusw8beuasWth5tXwc3vr6tTfh0LVvF4l1Rc5TGTycSQJkN4cc2LzN49W8WViIiISFGQdhVOfAmHP/nrljiTE1Tuby2qSjc1Nl9uMpnAq451qjXCOsrhtbPWodJNDv+8fSFStI7WIE82fBIXRxciYiKIiIkwOo6IiIiI5JXkaNj9Kiz3h/CR1sLKpTTUewN6RkHrrwtXYZUVB2fre7iKWGEFKq7yRZliZehTpw8AX0R8YXAaEREREcl1F3bA5n6wshoc/BDSEsCzFrSYDr1OQ6NxUKy80Sklj6m4yidDmgwBYEHkAq6lXTM4jYiIiIjcM/NNiF4Ca1vD2lZ/DlSRbn0HVPsfofsBqPms3b/4VnKPnrnKJw9WfZCqJaty8spJlh5YSnCjYKMjiYiIiMjdOrUI9r5uffcTWEfDq/IE1HoRSjUyNJoYR1eu8omDyYEhTa1Xr2ZHzDY4jYiIiIjcFYsF9o2BrQOshZWrN9QfbX2eqtWXKqyKOBVX+ejpxk/jYHJgU/QmDl84bHQcEREREcmJ9BTY+iT8Mdb6c53XoGc0NHzXOjS5FHkqrvJReY/ydK/ZHYAvdmtgCxEREZEC48YF+LUjRC20DqkeMBuavA9O7kYnEzui4iqf3bo1cN7eeaSmpxqcRkRERET+UeIRWBsI5zeDsxc8uBqqDzY6ldghFVf5rFvNbpQrUY745Hh+OPyD0XFERERE5HbiN1oLq6RjULwKdNoKfg8ZnUrslIqrfObk4ERI4xAAZu/WwBYiIiIiduvkfOutgKmXoEwAdNoOXnWNTiV2TMWVAQY1GQTAmmNriE6INjiNiIiIiGRgscC+d2DbU2BOA///g4d+A3dfo5OJnVNxZYDqpavToWoHLFj4cveXRscRERERkVvSU2BbMPzxrvXnuv+Gtos1cIXcERVXBhnSxDqwxZw9c0g3pxucRkRERERIuQi/Pgyn5oPJEVp+Do0ngEn/ZJY7o/9TDNK7Tm9KuZUiOiGadSfWGR1HREREpGhLPPrniICbwNkTHlgFNYYanUoKGBVXBnFzcuOphk8BMDtCA1uIiIiIGCZ+E6xtBVePQvHK8PBWKPew0amkAFJxZaBb77xacXgF8cnxBqcRERERKYJOLvhrRMDSLawjApasZ3QqKaBUXBmogW8DAioEcNN8k6/2fmV0HBEREZGiw2KByLGw7Ukwp4J/H+i4Htz9jE4mBZiKK4Pduno1O2I2FovF4DQiIiIiRUB6CmwbCJFjrD/XeRXaLgGnYsbmkgJPxZXB+tXrR3Hn4hy+eJgtp7cYHUdERESkcEu5BL91glNf/zki4Exo8oFGBJRcof+LDObh6kH/+v0BmBUxy+A0IiIiIoXY1WPWEQHjN4KTBzzwM9R4xuhUUoiouLIDQ5tah/lcsn8JV25cMTaMiIiISGF0fsufIwIegWKVoNNWKNfJ6FRSyNhNcTVhwgRMJhMvvvjibdstWbKE2rVr4+bmRoMGDfj5558zrH/66acxmUwZpi5duuRh8nvXskJL6petz/Wb1/km8huj44iIiIgULqe+gbAO1pcEl24OnXdAyfpGp5JCyC6Kq127djFz5kwaNmx423Zbt25lwIABDB48mN27d9OrVy969erFH3/8kaFdly5diImJsU3ffGPfBYvJZGJIkz8Httitd16JiIiI5AqLBf74L2x9wjoiYMXe0HGDRgSUPGN4cZWUlERQUBCzZs2iVKlSt237ySef0KVLF1599VXq1KnDf/7zH5o2bcrUqVMztHN1dcXPz882/dN+7cGTDZ/ExdGFiJgIImIijI4jIiIiUrClp8L2ENj3tvXn2i9rREDJc4YXV8OHD6d79+507NjxH9tu27YtU7vOnTuzbdu2DMvWr19P2bJlqVWrFsOGDePixYu33W9KSgqJiYkZpvxWplgZ+tTpA1iHZRcRERGRu5R6GX7rDCfnWUcEbDEdmn4IDo5GJ5NCztDiatGiRURERDB+/Pg7ah8bG4uvr2+GZb6+vsTGxtp+7tKlC1999RVhYWG8//77bNiwga5du5Kenp7tfsePH4+Xl5dt8vf3v7sDuke3bg1cELmAa2nXDMkgIiIiUqBdPf7niIDrrSMCtv8Jaj5rdCopIgwrrk6fPs3IkSNZsGABbm5uubbf/v378+ijj9KgQQN69erFjz/+yK5du1i/fn2224SGhpKQkGCbTp8+nWt5cuLBqg9SrVQ1ElMSWXpgqSEZRERERAqs81utIwImHoZi/tBpC5TvbHQqKUIMK67Cw8OJj4+nadOmODk54eTkxIYNG5gyZQpOTk5ZXmny8/MjLi4uw7K4uDj8/LJ/KLFatWp4e3tz7NixbNu4urri6emZYTKCg8mBwU0GA7o1UERERCRHohb/OSLgBSjd7M8RARsYnUqKGMOKq4ceeojIyEj27Nljm5o3b05QUBB79uzB0THzPbGBgYGEhYVlWLZu3ToCAwOz/ZwzZ85w8eJFypUrl+vHkBeebvw0DiYHNkVv4vCFw0bHEREREbFvFgvsfw+29AdzClTs+eeIgAXj335SuBhWXHl4eFC/fv0MU/HixSlTpgz161vfOxAcHExoaKhtm5EjR7J69WomTZrEoUOHeOedd/j99995/vnnAevIg6+++irbt2/n1KlThIWF0bNnT2rUqEHnzgXjknB5j/J0r9kd0NUrERERkdtKT4Udg2Dvm9afa4+Ctt+BU3Fjc0mRZfhogbcTHR1NTEyM7efWrVuzcOFCPv/8cxo1asTSpUtZvny5rRhzdHRk3759PProo9x3330MHjyYZs2asWnTJlxdXY06jBwb0tQ6sMW8vfNITU81OI2IiIiIHUq9DOu7wIm5YHKAFp9B00kaEVAMZbJYLBajQ9ibxMREvLy8SEhIMOT5q5vmm1T6uBIxSTEsfWwpfev2zfcMIiJGMPr8a8/03Yj8TdIJWN8dEg+BUwlo+y2U72p0KimkcnL+tesrV0WVk4MTIY1DAJi9W7cGioiIiNic3wZrWlkLq2IV4eHNKqzEbqi4slODmgwCYM2xNUQnRBucRkRERMQORH0LYQ9Cynko1RQ67YBSjYxOJWKj4spOVS9dnQ5VO2DBwpe7vzQ6joiIiIixTn8PW/pZRwSs8Cg8vBGKlTc6lUgGKq7s2JAm1oEtvtj9BenmzO/9EhERESkSrp2FHdZ3gVLjGWi3TCMCil1ScWXHetfpTWn30pxOPM26E+uMjiMiIiKS/yxm2DbQOjpg6WbQ7FONCCh2S8WVHXNzcuOphk8BeueViEh+mjZtGlWqVMHNzY2AgAB27tyZbdu5c+diMpkyTG5ubhnaxMXF8fTTT1O+fHmKFStGly5dOHr0aF4fhkjhcOhjiAsDx2LQegE4uhidSCRbKq7s3OAm1kvgKw6vID453uA0IiKF3+LFixk1ahRjxowhIiKCRo0a0blzZ+Ljsz8He3p6EhMTY5uioqJs6ywWC7169eLEiROsWLGC3bt3U7lyZTp27EhycnJ+HJJIwXV5D+x9wzrf7GPwrGVoHJF/ouLKzjXwbUBAhQBumm/y1d6vjI4jIlLoffTRRwwdOpSQkBDq1q3LjBkzKFasGHPmzMl2G5PJhJ+fn23y9fW1rTt69Cjbt29n+vTptGjRglq1ajF9+nSuX7/ON998kx+HJFIw3bwOW54AcypU7AnVhxqdSOQfqbgqAIY0tQ5sMTtiNnrns4hI3klNTSU8PJyOHTvaljk4ONCxY0e2bduW7XZJSUlUrlwZf39/evbsyf79+23rUlJSADLcKujg4ICrqyubN2/Odp8pKSkkJiZmmESKlD2vQeJBcPODlrPBZDI6kcg/UnFVAPSr14/izsU5fPEwm6Oz74hFROTeXLhwgfT09AxXngB8fX2JjY3NcptatWoxZ84cVqxYwfz58zGbzbRu3ZozZ84AULt2bSpVqkRoaCiXL18mNTWV999/nzNnzhATE5NtlvHjx+Pl5WWb/P39c+9ARezd2Z/hyFTrfKu54OZtaByRO6XiqgDwcPWgf/3+AMzerYEtRETsSWBgIMHBwTRu3Jj27duzbNkyfHx8mDlzJgDOzs4sW7aMI0eOULp0aYoVK8Zvv/1G165dcXDIvhsODQ0lISHBNp0+fTq/DknEWDfiYUeIdb7WSCjf2dg8Ijmg4qqAGNrUep/xkv1LuHLjirFhREQKKW9vbxwdHYmLi8uwPC4uDj8/vzvah7OzM02aNOHYsWO2Zc2aNWPPnj1cuXKFmJgYVq9ezcWLF6lWrVq2+3F1dcXT0zPDJFLoWSywfZC1wPKqD40nGJ1IJEdUXBUQLSu0pH7Z+ly/eZ1vIvUAtIhIXnBxcaFZs2aEhYXZlpnNZsLCwggMDLyjfaSnpxMZGUm5cuUyrfPy8sLHx4ejR4/y+++/07Nnz1zLLlIoHJsB534CB1dosxAc3f55GxE7ouKqgDCZTAxpYh3YYlbELIPTiIgUXqNGjWLWrFnMmzePgwcPMmzYMJKTkwkJsd6mFBwcTGhoqK392LFjWbt2LSdOnCAiIoInn3ySqKgohgwZYmuzZMkS1q9fbxuO/eGHH6ZXr1506tQp349PxG4lHISIUdb5xu9DyQbG5hG5C05GB5A792TDJ3ntl9fYHbubiJgImpZranQkEZFCp1+/fpw/f57Ro0cTGxtL48aNWb16tW2Qi+jo6AzPSl2+fJmhQ4cSGxtLqVKlaNasGVu3bqVu3bq2NjExMYwaNYq4uDjKlStHcHAwb7/9dr4fm4jdSk+BrU9A+g3w6wS1RhidSOSumCwa2zuTxMREvLy8SEhIsLt73Ad8N4BFfyxiWPNhfNb9M6PjiIjkKns+/xpN340Uartfg4MTwbUMdIsE98y31YoYJSfnX90WWMDcGthiQeQCrqVdMziNiIiIyD2K/RUOfmidD/hChZUUaCquCpgHqjxAtVLVSExJZOmBpUbHEREREbl7KZdgWzBggRrPQEUN8iIFm4qrAsbB5MDgJoMBmB2hd16JiIhIAWWxwM5/wfWz4HEfNP3I6EQi90zFVQH0dOOncTA5sCl6E4cuHDI6joiIiEjOnZwHp5eCyQlaLwCn4kYnErlnKq4KoPIe5eleszsAX0R8YXAaERERkRy6ehx+/3NEwIZjoUxzY/OI5BIVVwXUkKbW96fM2zuP1PRUg9OIiIiI3CFzGmwNgptJUPZ+qPOa0YlEco2KqwKqW81ulCtRjvPXzvPD4R+MjiMiIiJyZ/74L1zcAc5eEPg1ODganUgk16i4KqCcHJwIaRwCwOzdGthCRERECoDzW2H/f63zLWZA8UrG5hHJZSquCrBBTQYBsObYGqKuRBmcRkREROQ20hKttwNazFDlSajS3+hEIrlOxVUBVr10dTpU7YAFC1/u+dLoOCIiIiLZ+30EJJ+C4lWg+VSj04jkCRVXBdyQJtaBLebsnkO6Od3gNCIiIiJZiFoMJ78CkwO0ng8uXkYnEskTKq4KuN51elPavTSnE0+z7sQ6o+OIiIiIZJQcDTuftc7XexN82hibRyQPqbgq4Nyc3Hiq4VMAzI7QwBYiIiJiR8zpsC0Y0q5AmQCo/7bRiUTylIqrQmBwk8EArDi8grikOIPTiIiIiPzp4ESI3wBOxa23Azo4G51IJE+puCoEGvg2IKBCADfNN/lq71dGxxERERGBS+Gw788rVc0+BY8axuYRyQcqrgqJIU2tA1vM3j0bi8VicBoREREp0m4mw5YnwHIT/PtCtaeNTiSSL1RcFRL96vWjuHNxjlw8wubozUbHERERkaIs4mW4egTcK0DLz8FkMjqRSL5QcVVIeLh6MKD+AMB69UpERETEEGdWwLGZ1vnAeeBa2tg8IvlIxVUhcuvWwCX7l3DlxhVjw4iIiEjRcz0Gdlj/PUKdV8DvIWPziOQzFVeFSMsKLalftj7Xb15nYeRCo+OIiIhIUWIxw/YQSLkApRpDw/8anUgk36m4KkRMJhNDmvw5sIXeeSUiIiL56chUiFkDjm7QegE4uhqdSCTf2U1xNWHCBEwmEy+++OJt2y1ZsoTatWvj5uZGgwYN+PnnnzOst1gsjB49mnLlyuHu7k7Hjh05evRoHia3L082fBIXRxd2x+4mIibC6DgiIiJSFFyJhN2vWeebfAhedY3NI2IQuyiudu3axcyZM2nYsOFt223dupUBAwYwePBgdu/eTa9evejVqxd//PGHrc0HH3zAlClTmDFjBjt27KB48eJ07tyZGzdu5PVh2IUyxcrQt05fQFevREREJB+k34CtQWBOgfLdoOZzRicSMYzhxVVSUhJBQUHMmjWLUqVK3bbtJ598QpcuXXj11VepU6cO//nPf2jatClTp04FrFetJk+ezFtvvUXPnj1p2LAhX331FefOnWP58uXZ7jclJYXExMQMU0F2a2CLBZELuJZ2zeA0IiIiUqjtCbVeuXL1gYA5GnZdijTDi6vhw4fTvXt3Onbs+I9tt23blqld586d2bZtGwAnT54kNjY2QxsvLy8CAgJsbbIyfvx4vLy8bJO/v/9dHo19eKDKA1QrVY3ElESW7F9idBwREREprGLWwuHJ1vlWX4K7r6FxRIxmaHG1aNEiIiIiGD9+/B21j42Nxdc3419aX19fYmNjbetvLcuuTVZCQ0NJSEiwTadPn87JYdgdB5MDg5sMBvTOKxEREckjNy7AtoHW+ZrPQYXuxuYRsQOGFVenT59m5MiRLFiwADc3N6NiAODq6oqnp2eGqaB7uvHTOJgc2By9mUMXDhkdR0RERAoTiwV2DoEbseBZB5pMNDqRiF0wrLgKDw8nPj6epk2b4uTkhJOTExs2bGDKlCk4OTmRnp6eaRs/Pz/i4uIyLIuLi8PPz8+2/tay7NoUFeU9ytO9pvU3SF9EfGFwGhERESlUjs+GMyvAwRnaLASnYkYnErELhhVXDz30EJGRkezZs8c2NW/enKCgIPbs2YOjo2OmbQIDAwkLC8uwbN26dQQGBgJQtWpV/Pz8MrRJTExkx44dtjZFydCmQwGYt3ceqempBqcRERGRQiHxCIS/aJ1v9J71hcEiAoCTUR/s4eFB/fr1MywrXrw4ZcqUsS0PDg6mQoUKtmeyRo4cSfv27Zk0aRLdu3dn0aJF/P7773z++ecAtvdk/fe//6VmzZpUrVqVt99+m/Lly9OrV698PT570LVmV8qVKEdMUgwrDq3gsXqPGR1JRERECrL0VNj6BKRfA98OUHuU0YlE7IrhowXeTnR0NDExMbafW7duzcKFC/n8889p1KgRS5cuZfny5RmKtNdee40RI0bwzDPP0KJFC5KSkli9erXhz3UZwcnBiZDGIQA8+9OzbDi1weBEIiIiUqBFvgOXwsGlFATOA5Nd/1NSJN+ZLBaLxegQ9iYxMREvLy8SEhIK/OAWV25cocv8Luw4uwNnB2dmPjKTkCYhRscSEclSYTr/5jZ9N2K4+I3wywOABdougUr/Z3QikXyRk/Ovft1QyJV0K8lvA3+jX71+pJnTGLRyEK//8jpmi9noaCIiIlJQpF6BrU8CFqgWosJKJBsqrooAd2d3FvZdyNv3vw3A+1ve5/++/T+SU5MNTiYiIiJ2z2KBXcPg2mkoUR2afWJ0IhG7peKqiHAwOTD2wbHM7z0fF0cXvj/0PffPvZ9zV88ZHU1ERETs2akFELUITI7QegE4exidSMRuqbgqYoIaBvFr8K94F/MmIiaClrNaEhETYXQsERERsUdJJ+H34db5+mPAO8DYPCJ2TsVVEdSmUht2DNlBXZ+6nL16lnZftmP5oeVGxxIRERF7YjHDtmBISwTv1lAv1OhEInZPxVURVa1UNbYO2kqn6p24lnaNPov7MHHLRDR4pIiIiABwdDqc3wxOJaD1fHAw7PWoIgWGiqsizMvNi5+e+Innmj+HBQuv/fIaQ38YSmp6qtHRRERExEjJp2HP69b5xhOgRFVj84gUECquijgnByemdpvKlC5TcDA58MXuL+g8vzOXrl8yOpqIiGGmTZtGlSpVcHNzIyAggJ07d2bbdu7cuZhMpgzT/764Pikpieeff56KFSvi7u5O3bp1mTFjRl4fhsjduTU64M0k8A6EmsOMTiRSYKi4EkwmEyMCRvDDgB/wcPFg/an1tJrdiqMXjxodTUQk3y1evJhRo0YxZswYIiIiaNSoEZ07dyY+Pj7bbTw9PYmJibFNUVFRGdaPGjWK1atXM3/+fA4ePMiLL77I888/z8qVK/P6cERyLmoxnPsJHFwgYDaY9M9FkTulvy1i061mN7YM2kIlr0ocvXSUgNkBrD+13uhYIiL56qOPPmLo0KGEhITYrjAVK1aMOXPmZLuNyWTCz8/PNvn6+mZYv3XrVgYOHMgDDzxAlSpVeOaZZ2jUqNFtr4iJGCLlIoS/YJ2v9yZ41TU2j0gBo+JKMmjg24CdQ3YSUCGAyzcu8/DXDzNnd/b/oBARKUxSU1MJDw+nY8eOtmUODg507NiRbdu2ZbtdUlISlStXxt/fn549e7J///4M61u3bs3KlSs5e/YsFouF3377jSNHjtCpU6ds95mSkkJiYmKGSSTPRYyClPPgVQ/qvm50GpECR8WVZOJbwpffBv5G//r9uWm+yeCVg/n3un9jtpiNjiYikqcuXLhAenp6pitPvr6+xMbGZrlNrVq1mDNnDitWrGD+/PmYzWZat27NmTNnbG0+/fRT6tatS8WKFXFxcaFLly5MmzaN+++/P9ss48ePx8vLyzb5+/vnzkGKZCdmLZz8CjBBy1ng6GJ0IpECR8WVZMnd2Z2FfRYy+v7RAHyw9QP6ftuX5NRkg5OJiNiXwMBAgoODady4Me3bt2fZsmX4+Pgwc+ZMW5tPP/2U7du3s3LlSsLDw5k0aRLDhw/nl19+yXa/oaGhJCQk2KbTp0/nx+FIUXUzGXb+yzp/3wjwCTQ2j0gBpRcWSLZMJhPvPvgu95W5j0ErB7H80HLafdmOHwb8QAXPCkbHExHJdd7e3jg6OhIXF5dheVxcHH5+fne0D2dnZ5o0acKxY8cAuH79Om+88Qbff/893bt3B6Bhw4bs2bOHDz/8MMMtiH/n6uqKq6vrPRyNSA7sfRuST0GxStDov0anESmwdOVK/lFQwyB+G/gbPsV82B27m5azWxIRE2F0LBGRXOfi4kKzZs0ICwuzLTObzYSFhREYeGe/yU9PTycyMpJy5coBkJaWRlpaGg4OGbtcR0dHzGbdbi124MJOOPKJdb7lDHD2MDaPSAGm4kruSGv/1uwYsoO6PnU5d/Uc7b5sx/JDy42OJSKS60aNGsWsWbOYN28eBw8eZNiwYSQnJxMSEgJAcHAwoaGhtvZjx45l7dq1nDhxgoiICJ588kmioqIYMmQIYB2mvX379rz66qusX7+ekydPMnfuXL766it69+5tyDGK2JjTYOcQsJihShCU72p0IpECTbcFyh2rWqoqWwdtpd/Sfqw5voY+i/swoeMEXm39KiaTyeh4IiK5ol+/fpw/f57Ro0cTGxtL48aNWb16tW2Qi+jo6AxXoS5fvszQoUOJjY2lVKlSNGvWjK1bt1K37l9DWC9atIjQ0FCCgoK4dOkSlStXZty4cTz77LP5fnwiGRz4AK5EgmsZaPqx0WlECjyTxWKxGB3C3iQmJuLl5UVCQgKenp5Gx7E7N803eXH1i0zbNQ2AQY0HMf2R6bhoVCERuUc6/2ZP343kuoRDsKoRmFMh8Guo+qTRiUTsUk7Ov7otUHLMycGJqd2mMqXLFBxMDszZM4fO8ztz6folo6OJiIjInbCYYecz1sKqXBfrLYEics9UXMldGxEwgh8H/IiHiwfrT62n1exWHLl4xOhYIiIi8k+OfQ7nN4FTcesgFrq9XyRXqLiSe9K1Zle2Dt5KZa/KHL10lFazW/Hbyd+MjiUiIiLZuXYWdr9mnW84DopXNjaPSCGi4kruWf2y9dkxZAetKrbi8o3LdJrfiS8ivjA6loiIiPwviwV2PQc3r0KZALjveaMTiRQqKq4kV/iW8OXX4F/pX78/N803GfLDEF5b9xrp5nSjo4mIiMgtp5fC2ZVgcoKA2eDgaHQikUJFxZXkGndndxb2WciY9mMAmLh1In2/7UtSapLByURERISUS/D7n1eq6oVCyfrG5hEphFRcSa4ymUy888A7LOizAFdHV1YcXkG7L9txJvGM0dFERESKtt2vwo148KwN9d40Oo1IoaTiSvLEEw2e4NeBv+JTzIc9sXsImB1A+Llwo2OJiIgUTbFhcGKOdT5gNji6GptHpJBScSV5prV/a3YO3Uk9n3qcu3qOdl+2Y9nBZUbHEhERKVpuXrO+0wqg5nPg08bYPCKFmIoryVNVSlZhy6AtdKnRhes3r9P3275M2DwBi8VidDQREZGiIfIdSDoBxSpC4/FGpxEp1FRcSZ7zcvPihwE/8HwL60O0oWGhjNs0zuBUIiIiRcClcDg0yTrfYjo4exqbR6SQU3El+cLJwYlPu33KxIcnAvD2b28zfdd0g1OJiIgUYuY02DEELGao1A8qPGJ0IpFCT8WV5KtXWr/C2/e/DcDwn4ez+I/FBicSEREppA59BJf3gEtpaD7F6DQiRYKKK8l37z7wLs81fw4LFp76/inWHFtjdCQREZHCJfGo9VkrgKYfgVtZQ+OIFBUqriTfmUwmPu32Kf3r9yfNnEafb/uw7fQ2o2OJiIgUDhYz7BwK6TfA72GoGmx0IpEiQ8WVGMLB5MC8XvPoXL0z19Ku0X1hd/6I/8PoWCIiIgXf8TkQvwEci0HLmWAyGZ1IpMhQcSWGcXF04bvHvyOwYiCXb1ym09edOHn5pNGxRERECq5r52D3K9b5hv+BElWNzSNSxKi4EkMVdynOj0/8SP2y9YlJiuHhrx8mLinO6FgiIiIFU/gISEuA0s2h1gtGpxEpcgwtrqZPn07Dhg3x9PTE09OTwMBAVq1alW37tLQ0xo4dS/Xq1XFzc6NRo0asXr06Q5t33nkHk8mUYapdu3ZeH4rcg9LupVnz5BqqlKzC8cvH6Ty/M1duXDE6loiISMFyepl1MjlBwGxwcDI6kUiRY2hxVbFiRSZMmEB4eDi///47HTp0oGfPnuzfvz/L9m+99RYzZ87k008/5cCBAzz77LP07t2b3bt3Z2hXr149YmJibNPmzZvz43DkHpT3KM+6p9bhW9yXvXF76fFND66lXTM6loiISMGQegV+f946X/c1KNXI0DgiRZWhxVWPHj3o1q0bNWvW5L777mPcuHGUKFGC7du3Z9n+66+/5o033qBbt25Uq1aNYcOG0a1bNyZNmpShnZOTE35+frbJ29s7Pw5H7lGN0jVY8+QavFy92By9mX5L+5GWnmZ0LBEpAKpUqcLYsWOJjo42OoqIMXa/BtdjwOM+qP+20WlEiiy7eeYqPT2dRYsWkZycTGBgYJZtUlJScHNzy7DM3d0905Wpo0ePUr58eapVq0ZQUNA/drYpKSkkJiZmmMQYjfwa8cOAH3BzcuPHIz8yaOUgzBaz0bFExM69+OKLLFu2jGrVqvHwww+zaNEiUlJSjI4lkj/i1sPxWdb5gFng6Hbb5iKSdwwvriIjIylRogSurq48++yzfP/999StWzfLtp07d+ajjz7i6NGjmM1m1q1bx7Jly4iJibG1CQgIYO7cuaxevZrp06dz8uRJ2rVrx9WrV7PNMH78eLy8vGyTv79/rh+n3Ll2ldux9LGlOJocmb9vPi+tfgmLxWJ0LBGxYy+++CJ79uxh586d1KlThxEjRlCuXDmef/55IiIijI4nknduXocdQ63zNf4FZe83No9IEWeyGPyv1tTUVKKjo0lISGDp0qXMnj2bDRs2ZFlgnT9/nqFDh/LDDz9gMpmoXr06HTt2ZM6cOVy/fj3L/V+5coXKlSvz0UcfMXjw4CzbpKSkZPgNZ2JiIv7+/iQkJODp6Zk7Byo5Nn/ffJ76/ikA/vPgf3jr/rcMTiQieS0xMREvL697Pv+mpaXx2Wef8e9//5u0tDQaNGjACy+8QEhICKYC+s6f3PpupJDZEwoHJoB7eeh+AFy8jE4kUujk5Pxr+JUrFxcXatSoQbNmzRg/fjyNGjXik08+ybKtj48Py5cvJzk5maioKA4dOkSJEiWoVq1atvsvWbIk9913H8eOHcu2jaurq23EwluTGO/Jhk/ySRfr/wtv//Y203dNNziRiNi7tLQ0vv32Wx599FFefvllmjdvzuzZs+nbty9vvPEGQUFBRkcUyT2X98DBidb5Fp+psBKxA3Y3RqfZbP7H++Td3NyoUKECaWlpfPfddzz++OPZtk1KSuL48eM89dRTuR1V8sELAS9w8dpFxm4cy/Cfh1PKvRT96/c3OpaI2JmIiAi+/PJLvvnmGxwcHAgODubjjz/O8CqO3r1706JFCwNTiuQi803YPhgs6eD/f1Cxp9GJRASDi6vQ0FC6du1KpUqVuHr1KgsXLmT9+vWsWbMGgODgYCpUqMD48eMB2LFjB2fPnqVx48acPXuWd955B7PZzGuvvWbb5yuvvEKPHj2oXLky586dY8yYMTg6OjJgwABDjlHu3TsPvMPF6xeZtmsaT33/FCXdStKlRhejY4mIHWnRogUPP/ww06dPp1evXjg7O2dqU7VqVfr31y9npJA4PBkuR4BzSWj+qdFpRORPhhZX8fHxBAcHExMTg5eXFw0bNmTNmjU8/PDDAERHR+Pg8Nedizdu3OCtt97ixIkTlChRgm7duvH1119TsmRJW5szZ84wYMAALl68iI+PD23btmX79u34+Pjk9+FJLjGZTEzpOoVL1y/xzR/f0GdxH34J/oXW/q2NjiYiduLEiRNUrlz5tm2KFy/Ol19+mU+JRPLQ1eOwb7R1vukkcPczNo+I2Bg+oIU90kPD9ik1PZWei3qy+thqSrqVZOPTG2ng28DoWCKSi+72/Ltr1y7MZjMBAQEZlu/YsQNHR0eaN2+e21HznfomAcBigV87Qtyv4NsBOvwCBXSQFpGCokANaCFyp1wcXVj62FJa+7fmyo0rdJ7fmROXTxgdS0TswPDhwzl9+nSm5WfPnmX48OEGJBLJIyfmWgsrRzdoOVOFlYidUXElBUpxl+L8OOBH6petT0xSDJ2+7kRsUqzRsUTEYAcOHKBp06aZljdp0oQDBw4YkEgkD1yPhYhR1vkGY8GjhrF5RCQTFVdS4JRyL8WaJ9dQtWRVjl8+Tpf5Xbhy44rRsUTEQK6ursTFxWVaHhMTg5OT3Q2MK3J3wl+AtCtQqinUfsnoNCKSBRVXUiCV9yjP2qfW4lvcl71xe+nxTQ+upV0zOpaIGKRTp06EhoaSkJBgW3blyhXeeOMN2yBJIgXamRUQvQRMjhAwGxz0SwMRe6TiSgqsGqVrsObJNXi5erE5ejOPL3mctPQ0o2OJiAE+/PBDTp8+TeXKlXnwwQd58MEHqVq1KrGxsUyaNMnoeCL3JjUBdj1nna/zCpRuYmweEcmWiisp0Br5NeLHJ37E3cmdn47+xKCVgzBbzEbHEpF8VqFCBfbt28cHH3xA3bp1adasGZ988gmRkZH4+/sbHU/k3ux5Ha6fgxI1oP4Yo9OIyG3omrIUeG0rtWXp40vpuagn8/fNp7RbaSZ3mYxJIyiJFCnFixfnmWeeMTqGSO6K3wTHZljnAz4HJ3dj84jIbam4kkKhW81uzO05lye/f5IpO6fgXcybt9u/bXQsEclnBw4cIDo6mtTU1AzLH330UYMSidyD9BuwY4h1vvoQ8H3Q2Dwi8o/uqrg6ffo0JpOJihUrArBz504WLlxI3bp19VtDMUxQwyAuXb/EC6tfYPT60ZQpVobnWjxndCwRyQcnTpygd+/eREZGYjKZsFgsALYr2Onp6UbGE7k7f/wXrh4BNz9o8oHRaUTkDtzVM1dPPPEEv/32GwCxsbE8/PDD7Ny5kzfffJOxY8fmakCRnBgRMIIx7a33oz//8/N8E/mNwYlEJD+MHDmSqlWrEh8fT7Fixdi/fz8bN26kefPmrF+/3uh4Ijl3eR8ceN8632IauJQyNo+I3JG7Kq7++OMPWrZsCcC3335L/fr12bp1KwsWLGDu3Lm5mU8kx8a0H8PwFsOxYCF4eTCrj602OpKI5LFt27YxduxYvL29cXBwwMHBgbZt2zJ+/HheeOEFo+OJ5Iw53Xo7oOUmVOwN/n2MTiQid+iuiqu0tDRcXV0B+OWXX2z3steuXZuYmJjcSydyF0wmE1O6TmFA/QHcNN+kz+I+bD291ehYIpKH0tPT8fDwAMDb25tz584BULlyZQ4fPpzj/U2bNo0qVarg5uZGQEAAO3fuzLbt3LlzMZlMGSY3N7cMbf53/a1p4sSJOc4mRcCRKXBpFzh7QfOpRqcRkRy4q+KqXr16zJgxg02bNrFu3Tq6dOkCwLlz5yhTpkyuBhS5Gw4mB+b2mkvXGl25fvM63Rd2JzIu0uhYIpJH6tevz969ewEICAjggw8+YMuWLYwdO5Zq1arlaF+LFy9m1KhRjBkzhoiICBo1akTnzp2Jj4/PdhtPT09iYmJsU1RUVIb1f18XExPDnDlzMJlM9O3bN+cHK4Xb1WOw9y3rfJOJUKy8sXlEJEfuqrh6//33mTlzJg888AADBgygUaNGAKxcudJ2u6CI0VwcXVj6+FJa+7fmyo0rdJ7fmROXTxgdS0TywFtvvYXZbH3H3dixYzl58iTt2rXj559/ZsqUKTna10cffcTQoUMJCQmhbt26zJgxg2LFijFnzpxstzGZTPj5+dkmX1/fDOv/vs7Pz48VK1bw4IMP3rbwS0lJITExMcMkhdyFHbCuLaRfg7LtofpgoxOJSA7d1WiBDzzwABcuXCAxMZFSpf56wPKZZ56hWLFiuRZO5F4Vcy7GjwN+pP3c9kTGR9Lp605sHrQZvxJ+RkcTkVzUuXNn23yNGjU4dOgQly5dolSpUjl6511qairh4eGEhobaljk4ONCxY0e2bduW7XZJSUlUrlwZs9lM06ZNee+996hXr16WbePi4vjpp5+YN2/ebbOMHz+ed999946zSwF3cgHsGAzmFCjZAFrPB9Nd/Q5cRAx0V39rr1+/TkpKiq2wioqKYvLkyRw+fJiyZcvmakCRe1XKvRRrnlxD1ZJVOX75OJ3nd+bKjStGxxKRXJKWloaTkxN//PFHhuWlS5fO8cvEL1y4QHp6eqYrT76+vsTGxma5Ta1atZgzZw4rVqxg/vz5mM1mWrduzZkzZ7JsP2/ePDw8POjT5/aDFISGhpKQkGCbTp8+naNjkQLCYoY9b8C2J62FVYVH4eEtUKyi0clE5C7cVXHVs2dPvvrqKwCuXLlCQEAAkyZNolevXkyfPj1XA4rkhnIe5Vj31Dr8SvixL24fPb7pwbW0a0bHEpFc4OzsTKVKlQx7l1VgYCDBwcE0btyY9u3bs2zZMnx8fJg5c2aW7efMmUNQUFCmQS/+l6urK56enhkmKWTSkmBTXzgw3vpz3dfh/u/B2cPYXCJy1+6quIqIiKBdu3YALF26FF9fX6Kiovjqq69yfG+7SH6pXro6a55cg5erF5ujN/P4ksdJS08zOpaI5II333yTN954g0uXLt3Tfry9vXF0dCQuLi7D8ri4OPz87ux2YmdnZ5o0acKxY8cyrdu0aROHDx9myJAh95RTCoHkKFjXBs4sBwcXCPwKGo/XrYAiBdxd/Q2+du2abcjbtWvX0qdPHxwcHGjVqlWmEZJE7ElD34b8+MSPuDu589PRnwhZEYLZYjY6lojco6lTp7Jx40bKly9PrVq1aNq0aYbpTrm4uNCsWTPCwsJsy8xmM2FhYQQGBt7RPtLT04mMjKRcuXKZ1n3xxRc0a9bMNhCUFFHnt8DqFnBlH7j5wkProepTRqcSkVxwVwNa1KhRg+XLl9O7d2/WrFnDSy+9BEB8fLxuWxC717ZSW5Y+vpSei3qyIHIBFT0rMqHjBKNjicg96NWrV67ta9SoUQwcOJDmzZvTsmVLJk+eTHJyMiEhIQAEBwdToUIFxo+33so1duxYWrVqRY0aNbhy5QoTJ04kKioq09WpxMRElixZwqRJk3ItqxRAJ+bBzmfAnAqlGsP9K6B4JaNTiUguuaviavTo0TzxxBO89NJLdOjQwfbbvLVr19KkSZNcDSiSF7rV7MbcnnN58vsnmbRtEs+1eI5KXurcRAqqMWPG5Nq++vXrx/nz5xk9ejSxsbE0btyY1atX2wa5iI6OxsHhrxs/Ll++zNChQ4mNjaVUqVI0a9aMrVu3Urdu3Qz7XbRoERaLhQEDBuRaVilAzOmwNxQO/vni6Iq9ofXX4FTc2FwikqtMFovFcjcbxsbGEhMTQ6NGjWydzM6dO/H09KR27dq5GjK/JSYm4uXlRUJCgq7EFXId5nXgt1O/MaLlCKZ01fOCIkbT+Td7+m4KsLSrsOUJOPej9ed6b0HDd/V8lUgBkZPz713/rfbz86NJkyacO3fONtxsy5YtC3xhJUXLm+3eBGBWxCzik+MNTiMid8vBwQFHR8dsJxHDJJ2Eta2thZWDK7ReCI3+o8JKpJC6q9sCzWYz//3vf5k0aRJJSUkAeHh48PLLL/Pmm29muF1CxJ51qNqBlhVasvPsTiZvn8x7D71ndCQRuQvff/99hp/T0tLYvXs38+bN04t4xTjxm2BTH0i5AO7loN1y8G5pdCoRyUN3VVy9+eabfPHFF0yYMIE2bdoAsHnzZt555x1u3LjBuHHjcjWkSF4xmUy80fYNei3uxbRd03itzWuUdCtpdCwRyaGePXtmWvZ///d/1KtXj8WLFzN48GADUkmRdvwL2DUMzGlQupl14IpiFYxOJSJ57K4uMc2bN4/Zs2czbNgwGjZsSMOGDXnuueeYNWsWc+fOzeWIInmrR60e1POpR2JKItN2TjM6jojkolatWmUYVl0kz5nTIXwU7BhiLawqPQYdN6qwEiki7qq4unTpUpbPVtWuXfueX+Aokt8cTA680e4NACbvmExyarLBiUQkN1y/fp0pU6ZQoYL+USv5JDUBNjwChz+2/tzgHWizGJyKGRpLRPLPXRVXjRo1YurUqZmWT506lYYNG95zKJH89ni9x6lWqhoXrl1gdsRso+OISA6VKlWK0qVL26ZSpUrh4eHBnDlzmDhxotHxpCi4ehzWBkLManB0h7bfQoMxYDIZnUxE8tFdPXP1wQcf0L17d3755RfbO662bdvG6dOn+fnnn3M1oEh+cHJw4t9t/s2/fvwXE7dO5Nnmz+Lq5Gp0LBG5Qx9//DGmv/0j1sHBAR8fHwICAihVqpSByaRIiFsPm/pC6iVwLw/tV1qfsxKRIueu33N17tw5pk2bxqFDhwCoU6cOzzzzDP/973/5/PPPczVkftO7RIqmlJspVJtSjXNXzzGrxyyGNB1idCSRIkfn3+zpu7FTxz6HXcPBchNKt4D7l0Ox8kanEpFclJPz710XV1nZu3cvTZs2JT09Pbd2aQh1YEXXx9s+ZtTaUVQvVZ1Dzx/CyeGuLu6KyF262/Pvl19+SYkSJXjssccyLF+yZAnXrl1j4MCBuR0136lvsjPmmxAxCo58av258gAI+AKc3I3NJSK5Ll9eIixSGA1tNpQy7mU4fvk4Sw8sNTqOiNyh8ePH4+3tnWl52bJlee89vb9OclnqZVjf7a/CquF/ofUCFVYiouJK5O9KuJRgZMBIAN7b9B5mi9ngRCJyJ6Kjo6latWqm5ZUrVyY6OtqARFJoJR6BNa0gdh04FoN230H9NzVwhYgAKq5EMnm+5fN4uHgQGR/JT0d+MjqOiNyBsmXLsm/fvkzL9+7dS5kyZQxIJIVS7C+wJgCuHoFi/tBpC/j3MTqViNiRHD1Q0qfP7U8gV65cuZcsInahlHspnmvxHO9veZ9xm8bxyH2PZBiFTETsz4ABA3jhhRfw8PDg/vvvB2DDhg2MHDmS/v37G5xOCoUjn0H4C2BJhzKt4P7vwd3P6FQiYmdyVFx5eXn94/rg4OB7CiRiD15q9RKf7PiEHWd38Nup3+hQtYPRkUTkNv7zn/9w6tQpHnroIZycrF2b2WwmODhYz1zJvTGnQfhIODrd+nOVpyDgc3B0MzaXiNilXB0tsLDQiEwCMOLnEUzdNZWHqj7EL8G/GB1HpEi41/Pv0aNH2bNnD+7u7jRo0IDKlSvnQUpjqG8yQMol2Pw4xIUBJmg8Huq8puerRIqYAjNa4PTp02nYsCGenp54enoSGBjIqlWrsm2flpbG2LFjqV69Om5ubjRq1IjVq1dnajdt2jSqVKmCm5sbAQEB7Ny5My8PQwqpV1q/gpODE2Enw9hxZofRcUTkDtSsWZPHHnuMRx55pFAVVmKAhEPW56viwsCpuPX9VXX/rcJKRG7L0OKqYsWKTJgwgfDwcH7//Xc6dOhAz5492b9/f5bt33rrLWbOnMmnn37KgQMHePbZZ+nduze7d++2tVm8eDGjRo1izJgxRERE0KhRIzp37kx8fHx+HZYUEpVLVubJhk8CMH7zeIPTiMjt9O3bl/fffz/T8g8++CDTu69E/tG5NbC2FSQdg+KV4eGtUPFRo1OJSAFgd7cFli5dmokTJzJ48OBM68qXL8+bb77J8OHDbcv69u2Lu7s78+fPByAgIIAWLVowdepUwHrPvb+/PyNGjOD111+/owy69UJuOXzhMHWm1cGChX3P7qOBbwOjI4kUand7/vXx8eHXX3+lQYOMf0cjIyPp2LEjcXFxuR0136lvygcWCxyeArtHgcUMPm2g3TJwK2t0MhExUIG5LfDv0tPTWbRoEcnJyQQGBmbZJiUlBTe3jA+Quru7s3nzZgBSU1MJDw+nY8eOtvUODg507NiRbdu2ZfvZKSkpJCYmZphEAGp51+L/6v4fABO2TDA4jYhkJykpCRcXl0zLnZ2ddU6XO5OeCjv/BREvWgurak9DhzAVViKSI4YXV5GRkZQoUQJXV1eeffZZvv/+e+rWrZtl286dO/PRRx9x9OhRzGYz69atY9myZcTExABw4cIF0tPT8fX1zbCdr68vsbGx2WYYP348Xl5etsnf3z/3DlAKvNC2oQAs+mMRxy8dNziNiGSlQYMGLF68ONPyRYsWZduniNikXITfOsHxWYAJmnwIAXPA0dXoZCJSwORoKPa8UKtWLfbs2UNCQgJLly5l4MCBbNiwIcvO8JNPPmHo0KHUrl0bk8lE9erVCQkJYc6cOfeUITQ0lFGjRtl+TkxMVIElNk3KNaFrja6sOraK97e8z+c9Pjc6koj8j7fffps+ffpw/PhxOnSwvjohLCyMhQsXsnTpUoPTiV27EQ9r21ifr3LygDaLoEI3o1OJSAFl+JUrFxcXatSoQbNmzRg/fjyNGjXik08+ybKtj48Py5cvJzk5maioKA4dOkSJEiWoVq0aAN7e3jg6Oma6tz4uLg4/v+xf9Ofq6mobsfDWJPJ3b7R7A4C5e+ZyNvGswWlE5H/16NGD5cuXc+zYMZ577jlefvllzp49y6+//kqNGjWMjif2Kj0FNvb+a+CKTttUWInIPTG8uPpfZrOZlJSU27Zxc3OjQoUK3Lx5k++++46ePXsC1kKtWbNmhIWFZdhfWFhYts9xidyJtpXacn/l+0kzpzFp2ySj44hIFrp3786WLVtITk7mxIkTPP7447zyyis0atTI6GhijywW2PkMXNgKzl7w4BooWc/oVCJSwBlaXIWGhrJx40ZOnTpFZGQkoaGhrF+/nqCgIACCg4MJDQ21td+xYwfLli3jxIkTbNq0iS5dumA2m3nttddsbUaNGsWsWbOYN28eBw8eZNiwYSQnJxMSEpLvxyeFyxttrVevZobP5MK1CwanEZGsbNy4kYEDB1K+fHkmTZpEhw4d2L59u9GxxB4d/ABOfgUmR2i7BDxrGZ1IRAoBQ5+5io+PJzg4mJiYGLy8vGjYsCFr1qzh4YcfBiA6OhoHh7/qvxs3bvDWW29x4sQJSpQoQbdu3fj6668pWbKkrU2/fv04f/48o0ePJjY2lsaNG7N69epMg1yI5FSn6p1oVq4Z4THhfLL9E/7T4T9GRxIRIDY2lrlz5/LFF1+QmJjI448/TkpKCsuXL9dgFpK108thz5+/vG02Bco9bGgcESk87O49V/ZA7xKR7Cw7uIy+3/bFy9WL6Jei8XTV/x8iuSmn598ePXqwceNGunfvTlBQEF26dMHR0RFnZ2f27t1bqIor9U255PJeWNcGbiZDzeHQYqrRiUTEzhXI91yJFAS9aveitndtElISmL5rutFxRIq8VatWMXjwYN599126d++Oo6Oj0ZHEnl2PhQ09rIWVX0doNtnoRCJSyKi4EskBB5OD7b1XH23/iOtp1w1OJFK0bd68matXr9KsWTMCAgKYOnUqFy7omUjJQvoN68iA106Dx33Q9ltwMPyNNCJSyKi4EsmhAfUHUKVkFeKT4/li9xdGxxEp0lq1asWsWbOIiYnhX//6F4sWLaJ8+fK2F81fvXrV6IhiDywW2DEELm4Hl1LQ/kfrnyIiuUzFlUgOOTs681pr6wiVH2z5gNT0VIMTiUjx4sUZNGgQmzdvJjIykpdffpkJEyZQtmxZHn30UaPjidEOjIdTC8DkBG2XgmdNoxOJSCGl4krkLoQ0CcG3uC+nE0+zYN8Co+OIyN/UqlWLDz74gDNnzvDNN98YHUeMdnoZ7H3TOt98Kvh1MDaPiBRqKq5E7oKbkxsvB74MwIQtE0g3pxucSET+l6OjI7169WLlypVGRxGjXIqArU9Z5+97AWr+y9g8IlLoqbgSuUvPNn+WUm6lOHLxCMsOLjM6joiI/N31GNjwKKRfg3KdoekkoxOJSBGg4krkLnm4evBCwAsAvLf5PfTKOBERO3HzOmzoCdfPgmdtaLNYIwOKSL5QcSVyD0a0HEFx5+Lsid3DqmOrjI4jIiIWC+wYBJd2gUtpaP8DuHgZnUpEiggVVyL3oEyxMjzb/FkAxm0ap6tXIiJG++O/ELXIOjJgu+/Ao4bRiUSkCFFxJXKPXg58GRdHF7ae3sqm6E1GxxERKbqil0DkaOt8i+ng+4ChcUSk6FFxJXKPynmUY1DjQYD16pWIiBjg4u+wbaB1vtZLUGOIsXlEpEhScSWSC15r8xqOJkfWHl/L7+d+NzqOiEjRcu0sbOwJ6dehfDdoMtHoRCJSRKm4EskFVUtV5YkGTwAwfvN4g9OIyL2aNm0aVapUwc3NjYCAAHbu3Jlt27lz52IymTJMbm5umdodPHiQRx99FC8vL4oXL06LFi2Ijo7Oy8MoGm5esxZW18+BV11o8w04OBqdSkSKKBVXIrnk9bavA7Ds4DIOnD9gcBoRuVuLFy9m1KhRjBkzhoiICBo1akTnzp2Jj4/PdhtPT09iYmJsU1RUVIb1x48fp23bttSuXZv169ezb98+3n777SyLMMkBi9l6K+ClcHD1to4M6OxpdCoRKcJUXInkkro+delduzcAEzZPMDiNiNytjz76iKFDhxISEkLdunWZMWMGxYoVY86cOdluYzKZ8PPzs02+vr4Z1r/55pt069aNDz74gCZNmlC9enUeffRRypYtm9eHU7hFvgunl4KDM7RbBiWqGZ1IRIo4FVciueiNdm8AsDByIScvnzQ4jYjkVGpqKuHh4XTs2NG2zMHBgY4dO7Jt27Zst0tKSqJy5cr4+/vTs2dP9u/fb1tnNpv56aefuO++++jcuTNly5YlICCA5cuX3zZLSkoKiYmJGSb5m1OL4I+x1vkWM6BsO2PziIig4kokVzUv35xO1TuRbkln4lY9UC1S0Fy4cIH09PRMV558fX2JjY3NcptatWoxZ84cVqxYwfz58zGbzbRu3ZozZ84AEB8fT1JSEhMmTKBLly6sXbuW3r1706dPHzZs2JBtlvHjx+Pl5WWb/P39c+9AC7oLO2FHiHW+zitQfZCxeURE/qTiSiSXvdHWevVqzu45xFyNMTiNiOS1wMBAgoODady4Me3bt2fZsmX4+Pgwc+ZMwHrlCqBnz5689NJLNG7cmNdff51HHnmEGTNmZLvf0NBQEhISbNPp06fz5Xjs3rUzf44MeAPKPwKNdBu2iNgPFVciuez+yvfT2r81KekpfLTtI6PjiEgOeHt74+joSFxcXIblcXFx+Pn53dE+nJ2dadKkCceOHbPt08nJibp162ZoV6dOnduOFujq6oqnp2eGqci7mQwbHoUbseBVH9os1MiAImJXVFyJ5DKTycSb7d4EYPrv07l0/ZLBiUTkTrm4uNCsWTPCwsJsy8xmM2FhYQQGBt7RPtLT04mMjKRcuXK2fbZo0YLDhw9naHfkyBEqV66ce+ELO4sZtgXD5d3g6vPnyIAeRqcSEclAxZVIHuhaoyuNfBuRnJbMpzs+NTqOiOTAqFGjmDVrFvPmzePgwYMMGzaM5ORkQkKsz/gEBwcTGhpqaz927FjWrl3LiRMniIiI4MknnyQqKoohQ4bY2rz66qssXryYWbNmcezYMaZOncoPP/zAc889l+/HV2DtGw2nl4GDC9z/PZSoYnQiEZFMVFyJ5AGTyWQbOfCTHZ9wNeWqwYlE5E7169ePDz/8kNGjR9O4cWP27NnD6tWrbYNcREdHExPz1/OUly9fZujQodSpU4du3bqRmJjI1q1bM9wG2Lt3b2bMmMEHH3xAgwYNmD17Nt999x1t27bN9+MrkE4ugP3jrPMtZ4FPG2PziIhkw2SxWCxGh7A3iYmJeHl5kZCQoHvc5a6lm9Op+1ldjlw8wsSHJ/JK61eMjiRi93T+zV6R/W4ubIdfHgBzCtT9NzTWABYikr9ycv7VlSuRPOLo4MjrbV4HYNK2Sdy4ecPgRCIiBUxyNGzsZS2sKvaERu8ZnUhE5LZUXInkoaCGQfh7+hObFMuXu780Oo6ISMGRlvTnyIBxULIRBM4Hk/7ZIiL2TWcpkTzk4ujCq61fBeCDrR+Qlp5mcCIRkQLAYoZtT8KVveBWFtqvBOcSRqcSEflHKq5E8tiQpkMoW7wsp66cYtEfi4yOIyJi//a+CWdWgIMrtFsOxSsZnUhE5I6ouBLJY+7O7rzU6iUAxm8ej9liNjiRiIgdO/EVHPhz0IqAL8Dnzt4vJiJiD1RcieSDYc2H4eXqxcELB1l+aLnRcURE7NP5LbBzqHW+3htQNcjYPCIiOaTiSiQfeLl58XzL5wF4b9N76A0IIiL/I+kUbOwN5lSo2Bsa/sfoRCIiOabiSiSfvNjqRYo5FyM8Jpx1J9YZHUdExH6kXYUNPSDlPJRqDK2/1siAIlIg6cwlkk+8i3nzTNNnABi3aZzBaURE7IQ5HbY8AQl/gJsf3L8SnIobnUpE5K6ouBLJRy+3fhlnB2c2Rm1kc/Rmo+OIiBhvbyic+xEc3eD+FVDc3+hEIiJ3TcWVSD6q6FmRpxs/DVhHDhQRKdKOfwkHJ1rnA74E75bG5hERuUcqrkTy2WttXsPB5MDPR39mT+weo+OIiBgjfhPs+pd1vv5oqNLf2DwiIrlAxZVIPqtRugb96vUDrCMHiogUOUknYVMfMKdBpcegwRijE4mI5ApDi6vp06fTsGFDPD098fT0JDAwkFWrVt12m8mTJ1OrVi3c3d3x9/fnpZde4saNG7b177zzDiaTKcNUu3btvD4UkRwJbRsKwNIDSzl84bDBaURE8tnvL0DKBSjdDFrN1ciAIlJoGHo2q1ixIhMmTCA8PJzff/+dDh060LNnT/bv359l+4ULF/L6668zZswYDh48yBdffMHixYt54403MrSrV68eMTExtmnzZg0cIPalgW8DHq31KBYsvL/lfaPjiIjkn2tnIeZn63zgfHAqZmweEZFcZGhx1aNHD7p160bNmjW57777GDduHCVKlGD79u1Ztt+6dStt2rThiSeeoEqVKnTq1IkBAwawc+fODO2cnJzw8/OzTd7e3vlxOCI5cuvq1df7vibqSpTBaURE8snJr8BiBp924KU7S0SkcLGb6/Dp6eksWrSI5ORkAgMDs2zTunVrwsPDbcXUiRMn+Pnnn+nWrVuGdkePHqV8+fJUq1aNoKAgoqOjb/vZKSkpJCYmZphE8lqriq3oULUDN803+XDrh0bHERHJexYLnPjSOl99kLFZRETygOHFVWRkJCVKlMDV1ZVnn32W77//nrp162bZ9oknnmDs2LG0bdsWZ2dnqlevzgMPPJDhtsCAgADmzp3L6tWrmT59OidPnqRdu3ZcvXo12wzjx4/Hy8vLNvn76x0bkj/ebPcmALN3zyYuKc7gNCIieez8Frh61PqSYP//MzqNiEiuM7y4qlWrFnv27GHHjh0MGzaMgQMHcuDAgSzbrl+/nvfee4/PPvuMiIgIli1bxk8//cR//vMfW5uuXbvy2GOP0bBhQzp37szPP//MlStX+Pbbb7PNEBoaSkJCgm06ffp0rh+nSFYerPIgARUCuHHzBpO3TzY6johI3joxx/pnpX7gXMLYLCIiecBksVgsRof4u44dO1K9enVmzpyZaV27du1o1aoVEydOtC2bP38+zzzzDElJSTg4ZF0rtmjRgo4dOzJ+/J29tDUxMREvLy8SEhLw9PS8uwMRuUMrD6+k56KeeLh4EPViFKXcSxkdScQwOv9mr8B/N2lX4ftycDMZHt4MPm2MTiQickdycv41/MrV/zKbzaSkpGS57tq1a5kKKEdHRwCyqxGTkpI4fvw45cqVy92gIrnkkfseoX7Z+lxNvcq0XdOMjiMikjeil1gLK4/7wLu10WlERPKEocVVaGgoGzdu5NSpU0RGRhIaGsr69esJCgoCIDg4mNDQUFv7Hj16MH36dBYtWsTJkydZt24db7/9Nj169LAVWa+88gobNmzg1KlTbN26ld69e+Po6MiAAQMMOUaRf+JgcuCNttbnBidvn8ypK6eMDSQikhduDWRRLQRMJmOziIjkEScjPzw+Pp7g4GBiYmLw8vKiYcOGrFmzhocffhiA6OjoDFeq3nrrLUwmE2+99RZnz57Fx8eHHj16MG7cOFubM2fOMGDAAC5evIiPjw9t27Zl+/bt+Pj45Pvxidypx+o9xtu/vc3xy8ep+klVqpSsQvvK7WlfuT0PVHmAKiWrYNI/RkSkoEo8Auc3W18WXDXY6DQiInnG7p65sgcF/r52KZB2nt3JiFUjCD8XTrolPcM6f09/2ldpbyu4apSuoWJLCiWdf7NXoL+bPaFwYAKU7w4P/Gh0GhGRHMnJ+VfFVRYKdAcmBd7VlKtsOb2FDac2sCFqA7vO7eKm+WaGNuVKlMtQbNX2rq1iSwoFnX+zV2C/G/NNWFEJrsdAu+/Av4/RiUREckTF1T0qsB2YFErJqclsO7PNVmztOLuD1PTUDG3KFi/L/ZXvtxVb9crWw8Fkd+PViPwjnX+zV2C/m7M/w4bu4OoNvc6Co4vRiUREciQn519Dn7kSkX9W3KU4Hat1pGO1jgBcT7vOjrM7bMXWtjPbiE+OZ+mBpSw9sBSAMu5laFe5na3YaujbEEcHRyMPQ0SKqlvvtqrypAorESn0dOUqCwX2t4NSJKXcTGHXuV22YmvL6S1cS7uWoY2Xq1eGYqtJuSY4Oeh3K2J/dP7NXoH8bm6ch+UVwJwG3fZByQZGJxIRyTHdFniPCmQHJvKntPQ0wmPC2XBqA+uj1rM5ejNJqUkZ2ni4eNCmUhtbsdW8fHOcHZ0NSizyF51/s1cgv5tDkyHiJSjdHLrsMjqNiMhdUXF1jwpkByaSjZvmm+yO2c2GKOuVrU1Rm0hIScjQpphzMVr7t7YVWy0rtMTVydWgxFKU6fybvQL33VgssKoRXImEFp9BzWFGJxIRuSsqru5RgevARHIg3ZzOvrh9tmJrY9RGLl2/lKGNm5MbrSq2onm55lQuWZnKXpVtf3q5eRmUXIoCnX+zV+C+m0vhsLo5OLpB7xhwKWl0IhGRu6IBLUQkW44OjjQp14Qm5ZrwYqsXMVvM7I/fbyu2NpzawPlr51l/aj3rT63PtL2nq2eGYivDfMnKlC1eViMViggc/3Mgi4q9VViJSJGh4kqkiHMwOdDAtwENfBvwfMvnsVgsHLpwiI1RGzl44SDRCdFEJUQRdSWKi9cvkpiSSGR8JJHxkVnuz9XRFX8v/ywLr8pelanoWVHPd4kUdjevw6mF1vnqg4zNIiKSj1RciUgGJpOJOj51qONTJ9O6pNQka7F1JcpWcEUn/vXzuavnSElP4dilYxy7dCzL/TuYHCjvUZ5KXpWyLcCKuxTP68MUkbx0ZjmkXYFilcC3g9FpRETyjYorEbljJVxKUNenLnV96ma5Pi09jTOJZ2yF1/8WYNEJ0aSkp3Am8QxnEs+w9fTWLPdTxr0MlUtWzlCAVS9dnU7VO+Hm5JaXhygiueHWu62qhYBuExaRIkTFlYjkGmdHZ6qWqkrVUlWzXG+2mIlPjs9QeEUlRGW49TAhJYGL1y9y8fpFImIiMmxf27s283rNo2WFlvlxOCJyN5KjIDbMOl9toLFZRETymYorEck3DiYH/Er44VfCj4CKAVm2SbiRkOWVr/Wn1nPowiFaf9Ga19u+zuj2o3FxdMnnIxCRf3RiHmCx3g5YIutftIiIFFYqrkTErni5edHQrSENfRtmWH7x2kVGrBrBN398w7hN4/jhyA981esrGvk1MiipiGRiMcOJL63z1TSQhYgUPboRWkQKhDLFyrCw70KWPrYU72Le7IvbR/NZzfnPhv+Qlp5mdDwRAYhbD8mnwNkL/PsYnUZEJN+puBKRAqVv3b7sf24/vWv35qb5JqPXj6b1nNYcOH/A6GhSiEybNo0qVarg5uZGQEAAO3fuzLbt3LlzMZlMGSY3t4wDrzz99NOZ2nTp0iWvDyP/3bpqVXkAOLkbm0VExAAqrkSkwClbvCzfPf4d83vPp6RbSX4/9ztNZzZl4paJpJvTjY4nBdzixYsZNWoUY8aMISIigkaNGtG5c2fi4+Oz3cbT05OYmBjbFBUVlalNly5dMrT55ptv8vIw8l9qApxeap2vFmJsFhERg6i4EpECyWQyEdQwiP3P7adbzW6kpKfw2i+vcf/c+zl68ajR8aQA++ijjxg6dCghISHUrVuXGTNmUKxYMebMmZPtNiaTCT8/P9vk6+ubqY2rq2uGNqVKlcrLw8h/UYsg/QZ41YMyLYxOIyJiCBVXIlKglfcoz48DfmR2j9l4uHiw9fRWGs1oxKc7PsVsMRsdTwqY1NRUwsPD6dixo22Zg4MDHTt2ZNu2bdlul5SUROXKlfH396dnz57s378/U5v169dTtmxZatWqxbBhw7h48eJts6SkpJCYmJhhsmu2d1sNApPJ2CwiIgZRcSUiBZ7JZGJw08FEDoukQ9UOXL95nRdWv0DHrzpy6sopo+NJAXLhwgXS09MzXXny9fUlNjY2y21q1arFnDlzWLFiBfPnz8dsNtO6dWvOnDlja9OlSxe++uorwsLCeP/999mwYQNdu3YlPT3721jHjx+Pl5eXbfL398+dg8wLV/bDxZ1gcoKqTxqdRkTEMCquRKTQqFyyMuueWsfUrlMp5lyM3079RoPpDZgVPguLxWJ0PCmkAgMDCQ4OpnHjxrRv355ly5bh4+PDzJkzbW369+/Po48+SoMGDejVqxc//vgju3btYv369dnuNzQ0lISEBNt0+vTpfDiau3RrIIsKPcCtrLFZREQMpOJKRAoVB5MDw1sOZ++ze2lbqS1JqUk88+MzdFvYjbOJZ42OJ3bO29sbR0dH4uLiMiyPi4vDz8/vjvbh7OxMkyZNOHbsWLZtqlWrhre3923buLq64unpmWGyS+Y0OPmVdV4DWYhIEafiSkQKpRqla7B+4HomdZqEq6Mrq4+tpv70+ny992tdxZJsubi40KxZM8LCwmzLzGYzYWFhBAYG3tE+0tPTiYyMpFy5ctm2OXPmDBcvXrxtmwLj7E+Qch7c/KB8V6PTiIgYSsWViBRajg6OjAocxe5/7aZF+RZcuXGF4OXB9F7cm7ikuH/egRRJo0aNYtasWcybN4+DBw8ybNgwkpOTCQmxXpUJDg4mNDTU1n7s2LGsXbuWEydOEBERwZNPPklUVBRDhgwBrINdvPrqq2zfvp1Tp04RFhZGz549qVGjBp07dzbkGHPVrYEsqgaDg5OxWUREDKbiSkQKvTo+ddg6eCvjOozD2cGZFYdXUO+zeizZv8ToaGKH+vXrx4cffsjo0aNp3Lgxe/bsYfXq1bZBLqKjo4mJibG1v3z5MkOHDqVOnTp069aNxMREtm7dSt26dQFwdHRk3759PProo9x3330MHjyYZs2asWnTJlxdXQ05xlxzPRbO/Wyd1y2BIiKYLLo/JpPExES8vLxISEiw33vcReSu7I3dy8DlA9kbtxeAfvX6Ma3bNMoUK2NwMgGdf2/HLr+bAxNhz2vg3Ro6bTE6jYhInsjJ+VdXrkSkSGnk14idQ3fy9v1v42hyZPH+xdT7rB4rD680OppIwWKx/O3dVrpqJSICKq5EpAhycXRh7INj2T5kO3W86xCXHEfPRT15evnTXLlxxeh4IgXDhe2QeAgci0Hlx41OIyJiF1RciUiR1bx8cyL+FcGrrV/FhIl5e+dR/7P6rDm2xuhoIvbv1lWrSo+Bs53cpigiYjAVVyJSpLk5ufHBwx+wKWQTNUrX4OzVs3RZ0IV//fAvrqZcNTqeiH26mQxRi63z1QcZm0VExI6ouBIRAdpUasOef+1hRMsRAHwe8TkNZzRk/an1xgYTsUfR38HNq1CiOvi0MzqNiIjdUHElIvKn4i7FmdJ1Cr8G/0plr8qcunKKB+c9yMhVI7mWds3oeCL24+8DWZhMxmYREbEjKq5ERP7Hg1UfJHJYJEObDgVgys4pNJ7RmK2ntxqcTMQOXD0G8RsAE1QbaHQaERG7ouJKRCQLHq4efN7jc1YFraKCRwWOXjpKuy/b8e91/+bGzRtGxxMxzom51j/LdYZiFQ2NIiJib1RciYjcRpcaXYgcFslTDZ/CbDHzwdYPaPZ5M8LPhRsdTST/mdPh5DzrvAayEBHJRMWViMg/KOVeiq96f8XyfsspW7wsB84foPWc1vx68lejo4nkr9hf4NoZcCkNFR41Oo2IiN1RcSUicod61u7J/uf2061mN1LTU+m9uDf74vYZHUsk/9wayKJKEDi6GptFRMQOGVpcTZ8+nYYNG+Lp6YmnpyeBgYGsWrXqtttMnjyZWrVq4e7ujr+/Py+99BI3bmR8/mHatGlUqVIFNzc3AgIC2LlzZ14ehogUId7FvPnu8e+4v/L9JKYk0nVBV6IToo2OJZL3Ui7CmeXWed0SKCKSJUOLq4oVKzJhwgTCw8P5/fff6dChAz179mT//v1Ztl+4cCGvv/46Y8aM4eDBg3zxxRcsXryYN954w9Zm8eLFjBo1ijFjxhAREUGjRo3o3Lkz8fHx+XVYIlLIuTm5sbzfcur61OXc1XN0md+FS9cvGR1LJG+dWgjmVCjVBEo1NjqNiIhdMrS46tGjB926daNmzZrcd999jBs3jhIlSrB9+/Ys22/dupU2bdrwxBNPUKVKFTp16sSAAQMyXJn66KOPGDp0KCEhIdStW5cZM2ZQrFgx5syZk1+HJSJFQCn3UqwOWk0FjwocvHCQXot6aRRBKdxOfGn9s5quWomIZMdunrlKT09n0aJFJCcnExgYmGWb1q1bEx4ebiumTpw4wc8//0y3bt0ASE1NJTw8nI4dO9q2cXBwoGPHjmzbti3bz05JSSExMTHDJCLyT/y9/FkVtApPV082RW/iqe+fIt2cbnQskdx3aTdc3g0OLlDlCaPTiIjYLcOLq8jISEqUKIGrqyvPPvss33//PXXr1s2y7RNPPMHYsWNp27Ytzs7OVK9enQceeMB2W+CFCxdIT0/H19c3w3a+vr7ExsZmm2H8+PF4eXnZJn9//9w7QBEp1Br4NmB5v+W4OLqw9MBSXlrzEhaLxehYIrnr1lWrir3AtbShUURE7JnhxVWtWrXYs2cPO3bsYNiwYQwcOJADBw5k2Xb9+vW89957fPbZZ0RERLBs2TJ++ukn/vOf/9xThtDQUBISEmzT6dOn72l/IlK0PFj1Qb7q9RUAn+78lA+3fmhwIpFclH4DTs23zuuWQBGR23IyOoCLiws1atQAoFmzZuzatYtPPvmEmTNnZmr79ttv89RTTzFkyBAAGjRoQHJyMs888wxvvvkm3t7eODo6EhcXl2G7uLg4/Pz8ss3g6uqKq6uGlBWRu9evfj/OXT3HqLWjeO2X1yjvUZ6ghkFGxxK5d2dWQuplKFYR/Dr+c3sRkSLM8CtX/8tsNpOSkpLlumvXruHgkDGyo6MjABaLBRcXF5o1a0ZYWFiG/YWFhWX7HJeISG55KfAlRrUaBUDIihB+OfGLwYlEcsGtWwKrDgQHR2OziIjYOUOvXIWGhtK1a1cqVarE1atXWbhwIevXr2fNmjUABAcHU6FCBcaPHw9YRxf86KOPaNKkCQEBARw7doy3336bHj162IqsUaNGMXDgQJo3b07Lli2ZPHkyycnJhISEGHacIlJ0TOw0kbNXz7J4/2L6LO7DxpCNNPZrbHQskbuTfBpirH0y1Z42NIqISEFgaHEVHx9PcHAwMTExeHl50bBhQ9asWcPDDz8MQHR0dIYrVW+99RYmk4m33nqLs2fP4uPjQ48ePRg3bpytTb9+/Th//jyjR48mNjaWxo0bs3r16kyDXIiI5AUHkwPzes0jLjmO9afW03VBV7YP3k7lkpWNjiaScye/AixQtj141DA6jYiI3TNZNKxVJomJiXh5eZGQkICnp6fRcUSkALpy4wrtvmzHH/F/UNu7NlsGbaG0u0ZZ+yc6/2Yv378biwV+qAlJx6HVPKgWnPefKSJih3Jy/rW7Z65ERAqDkm4lWRW0ioqeFTl04RCPfvMo19OuGx1L5M6d32QtrJw8oFJfo9OIiBQIKq5ERPJIRc+KrA5aTUm3kmw5vYWgZUF6ybAUHMfnWP+s3A+cihubRUSkgFBxJSKSh+qVrceK/itwcXTh+0Pf88KqF/SSYbF/aYkQvcQ6r3dbiYjcMRVXIiJ57P7K9zO/93xMmPjs9894f8v7RkcSub2obyH9GnjWBu9WRqcRESkwVFyJiOSDx+o9xsedPwYgNCyUr/d+bXAikds48ectgdUGgclkbBYRkQJExZWISD4Z2WokrwS+AsCglYNYd3ydwYlEspBwCC5sA5MjVH3K6DQiIgWKiisRkXz0/sPvM6D+AG6ab9Ln2z7sjtltdCSRjE58af2zfDdw9zM2i4hIAaPiSkQkHzmYHPiy55d0qNqBpNQkui3sxsnLJ42OJWJlToOT86zzGshCRCTHVFyJiOQzVydXlj2+jIa+DYlNiqXLgi5cuHbB6FgicG413IgDt7JQobvRaUREChwVVyIiBvBy82JV0CoqeVXiyMUjPPrNo1xLu2Z0LCnqbg1kUeUpcHA2NouISAGk4kpExCDlPcqzOmg1pdxKse3MNgZ8Z30WS8QQN+Lh7I/W+WohxmYRESmgVFyJiBiojk8dVg5YiaujKysPr2TEzyP0kmExxsn5YLkJZVpCyXpGpxERKZBUXImIGKxtpbYs7LsQEyZmhM9g/ObxRkeSosZigRNfWOc1kIWIyF1TcSUiYgf61OnDlK5TAHjz1zeZu2eusYGkaLm4CxIOgKMbVO5vdBoRkQJLxZWIiJ14vuXz/LvNvwEYsnLI/7d3/1FR1fkfx18z/BgGAkKQXwqi4qKioICyaLu16fqr3OyQrmdRydo6Gpquu+5R27K2jNwfrn2zKFt0/R41ysqyH2oupeWvMBB/rKapG5mKqJkIFhpzv3/4bdpZGMMcvCM8H+fcE3Pn3svrfg5n3r67dt4UCQAAFZlJREFU935Gaw6sMTkRWo1vv9sq7g7JP9TcLABwDaO5AgAv8viAxzUmZYzqjXrd8dIdKj1aanYktHTfnJMqll/8mYksAOCK0FwBgBexWqwq/EWhBnYaqNoLtRq2fJgOnT5kdiy0ZIdXSheqpaAEKeoms9MAwDWN5goAvIy/j79eGfWKekX3UlVtlYYsHaITtSfMjoWW6tvvtuo0XrLwzwIAuBJ8igKAFwqxhejtX72tDqEd9MkXn2j4C8P5kuGr6Omnn1ZCQoICAgKUmZmpkpISt9v+4x//kMVicVkCAgLcbj9hwgRZLBbNnz+/GZJfppp/S8fflWSROuWanQYArnk0VwDgpWKCY7RmzBq1sbfRh0c+1OiXR/Mlw1fBiy++qGnTpmn27NkqKytTamqqBg8erKqqKrf7hISE6NixY86loqKi0e1WrlyprVu3KjY2trniX55DSy7+N3qgFNTB3CwA0ALQXAGAF+sa0VWrRq9SgG+A3tj/hu576z6+ZLiZzZs3T/fcc4/Gjx+v7t2769lnn1VgYKAWLVrkdh+LxaLo6GjnEhUV1WCbI0eOaPLkyVq2bJn8/Pya8xSaxnB8N0sgE1kAgEfQXAGAl+sf318vZL8gq8Wq58ue12PvP2Z2pBbr/PnzKi0t1cCBA53rrFarBg4cqC1btrjdr6amRh06dFBcXJxuu+02/etf/3J53+FwaOzYsZo+fbqSk5OblKWurk7V1dUui0cdf1c695nkd73UfoRnjw0ArRTNFQBcA0Z0HaEFQxdIkh5a/5AWbXd/FQU/3MmTJ1VfX9/gylNUVJQqKysb3ScpKUmLFi3S66+/rqVLl8rhcKhfv376/PPPndvMnTtXvr6+uv/++5ucJT8/X6Ghoc4lLi7uh52UOwf//28o4VeSr92zxwaAVormCgCuERP7TNSsG2ZJku594169/cnbJieCJGVlZWncuHHq1auXbrzxRr366qtq27atnnvuOUlSaWmpnnzySefEF001c+ZMnTlzxrkcPnzYc6HPn5YOv3rx5853ee64ANDK0VwBwDXksZsf07jUcao36jVyxUhtO7LN7EgtSkREhHx8fHT8+HGX9cePH1d0dHSTjuHn56fevXvrwIEDkqQPPvhAVVVVio+Pl6+vr3x9fVVRUaHf/va3SkhIcHscm82mkJAQl8VjKookR510fYoUlua54wJAK0dzBQDXEIvFor8P/7sGdx6scxfO6Zblt+jAFwfMjtVi+Pv7Kz09XcXFxc51DodDxcXFysrKatIx6uvrtWvXLsXExEiSxo4dq507d6q8vNy5xMbGavr06Vq7dm2znMf3Ovif323V9KtpAIBL8zU7AADg8vj5+GnFyBW6aclNKjtWpiFLh+idse+o4/UdL+u2MzRu2rRpys3NVUZGhvr27av58+ertrZW48dfnFFv3LhxateunfLz8yVJf/zjH/XjH/9YiYmJ+vLLL/XnP/9ZFRUV+vWvfy1JCg8PV3h4uMvv8PPzU3R0tJKSkq7uyUnS6Z3SFx9JVj8pIefq/34AaMForgDgGhRsC9Zbv3pLWYVZOnj6oDr/T2dFBUUpLSZNaTFpSo9JV1pMmuJD42m4LtMvf/lLnThxQg899JAqKyvVq1cvrVmzxjnJxWeffSar9bsbP06fPq177rlHlZWVCgsLU3p6ujZv3qzu3bubdQqX9u306+1+IQW0NTcLALQwFoMvTGmgurpaoaGhOnPmjGfvcQcAD9t/ar/ufO1OlRwpUb1R3+D9cHt4g4arU1gnr224+Px1zyNjU39eeq2dVHdSuvEtqd0wz4YEgBbocj5/uXIFANewH4X/SJvv3qyvLnylncd3quxYmcqOlan0WKl2V+3Wqa9Oad2hdVp3aJ1zn1BbqEuzlR6brsQ2ibJaeAy3xTv65sXGyh4jxQwyOw0AtDg0VwDQAtj97Mpsn6nM9pnOdXXf1Gl31W5ns1V2rEw7j+/Umbozeu/T9/Tep+85tw32D1bvmN5Ki05zNlxJ4UnysfqYcTpoLt9OZNExV7LyTwAA8DRuC2wEt6UAaKku1F/QnhN7nM1W6bFS7ajcoa+++arBtoF+geoV3cul4eoW0U1+Pn7Nlo/PX/eueGzOHZVej5MMh3TrPinkR54PCQAtELcFAgAa5efjp9ToVKVGp+qu3he/PPYbxzfad3KfS8O1/dh21V6o1ebDm7X58Gbn/gG+AUqJSlFa9MVmKy0mTT0ie8jfx9+sU0JT/ft/LzZWbW+gsQKAZkJzBQCtnK/VV8mRyUqOTNa41HGSpHpHvT754pOLzdbRUpVVXnyWq7quWiVHSlRypEQqvbi/n9VPPaN6ujRcKVEpCvANMPGs4MIwvpslsNNd5mYBgBaM2wIbwW0pANCQw3Do0OlDLg1X6dFSnf76dINtnxn2jCb2mXjZv4PPX/euaGxObJLW3SD5Bkm3V0p+1zVPSABogbgtEADgcVaLVYltEpXYJlGjkkdJkgzDUMWZiovN1v/fUlh6rFRpMWkmp4WLb2ql0GQpvC+NFQA0I5orAMAPZrFYlHB9ghKuT1B292xJFxsueJmYQdKwXVJ9w4lLAACeY+qXmhQUFCglJUUhISEKCQlRVlaWVq9e7Xb7m266SRaLpcFyyy23OLe58847G7w/ZMiQq3E6AADJ+dkLL2OxSL6BZqcAgBbN1CtX7du31xNPPKEuXbrIMAwtWbJEt912m7Zv367k5OQG27/66qs6f/688/WpU6eUmpqqkSNHumw3ZMgQLV682PnaZrM130kAAAAAgExuroYPH+7yes6cOSooKNDWrVsbba7atGnj8rqoqEiBgYENmiubzabo6Ogm56irq1NdXZ3zdXV1dZP3BQAAAADJ5NsC/1N9fb2KiopUW1urrKysJu1TWFio0aNHKygoyGX9+vXrFRkZqaSkJE2cOFGnTp265HHy8/MVGhrqXOLi4n7weQAAAABonUyfin3Xrl3KysrS119/reuuu07Lly/XsGHDvne/kpISZWZm6sMPP1Tfvn2d67+9mtWxY0cdPHhQs2bN0nXXXactW7bIx8en0WM1duUqLi6OqYAB4CpjKnb3GBsAMMc1NRV7UlKSysvLdebMGb388svKzc3Vhg0b1L1790vuV1hYqJ49e7o0VpI0evRo5889e/ZUSkqKOnfurPXr12vAgAGNHstms/FcFgAAAIArYvptgf7+/kpMTFR6erry8/OVmpqqJ5988pL71NbWqqioSHfffff3Hr9Tp06KiIjQgQMHPBUZAAAAABowvbn6bw6Hw+UWvcasWLFCdXV1GjNmzPce7/PPP9epU6cUExPjqYgAAAAA0ICptwXOnDlTQ4cOVXx8vM6ePavly5dr/fr1Wrt2rSRp3LhxateunfLz8132Kyws1IgRIxQeHu6yvqamRo888oiys7MVHR2tgwcP6ve//70SExM1ePDgq3ZeAAAAAFofU5urqqoqjRs3TseOHVNoaKhSUlK0du1a/fznP5ckffbZZ7JaXS+u7du3Txs3btQ777zT4Hg+Pj7auXOnlixZoi+//FKxsbEaNGiQHn30UZ6pAgAAANCsTJ8t0BsxIxMAmIPPX/cYGwAwx+V8/nrdM1cAAAAAcC2iuQIAAAAADzD9e6680bd3SlZXV5ucBABal28/d7ljvSFqEwCY43JqE81VI86ePStJiouLMzkJALROZ8+eVWhoqNkxvAq1CQDM1ZTaxIQWjXA4HDp69KiCg4NlsVgue//q6mrFxcXp8OHDPHT8Xxgb9xibS2N83GtJY2MYhs6ePavY2NgGs8W2dtSm5sPYuMfYuMfYuNfSxuZyahNXrhphtVrVvn37Kz5OSEhIi/iDag6MjXuMzaUxPu61lLHhilXjqE3Nj7Fxj7Fxj7FxryWNTVNrE/9bEAAAAAA8gOYKAAAAADyA5qoZ2Gw2zZ49WzabzewoXoexcY+xuTTGxz3GBk3B34l7jI17jI17jI17rXlsmNACAAAAADyAK1cAAAAA4AE0VwAAAADgATRXAAAAAOABNFcAAAAA4AE0V83g6aefVkJCggICApSZmamSkhKzI5kuPz9fffr0UXBwsCIjIzVixAjt27fP7Fhe6YknnpDFYtHUqVPNjuIVjhw5ojFjxig8PFx2u109e/bURx99ZHYs09XX1+vBBx9Ux44dZbfb1blzZz366KNijiI0hrrUOGpT01CXGqI2NY7aRHPlcS+++KKmTZum2bNnq6ysTKmpqRo8eLCqqqrMjmaqDRs2KC8vT1u3btW6det04cIFDRo0SLW1tWZH8yrbtm3Tc889p5SUFLOjeIXTp0+rf//+8vPz0+rVq7Vnzx799a9/VVhYmNnRTDd37lwVFBRowYIF2rt3r+bOnas//elPeuqpp8yOBi9DXXKP2vT9qEsNUZvcozYxFbvHZWZmqk+fPlqwYIEkyeFwKC4uTpMnT9aMGTNMTuc9Tpw4ocjISG3YsEE//elPzY7jFWpqapSWlqZnnnlGjz32mHr16qX58+ebHctUM2bM0KZNm/TBBx+YHcXr3HrrrYqKilJhYaFzXXZ2tux2u5YuXWpiMngb6lLTUZtcUZcaR21yj9rElSuPOn/+vEpLSzVw4EDnOqvVqoEDB2rLli0mJvM+Z86ckSS1adPG5CTeIy8vT7fccovL309rt2rVKmVkZGjkyJGKjIxU79699fzzz5sdyyv069dPxcXF2r9/vyRpx44d2rhxo4YOHWpyMngT6tLloTa5oi41jtrkHrVJ8jU7QEty8uRJ1dfXKyoqymV9VFSUPv74Y5NSeR+Hw6GpU6eqf//+6tGjh9lxvEJRUZHKysq0bds2s6N4lUOHDqmgoEDTpk3TrFmztG3bNt1///3y9/dXbm6u2fFMNWPGDFVXV6tr167y8fFRfX295syZo5ycHLOjwYtQl5qO2uSKuuQetck9ahPNFUyQl5en3bt3a+PGjWZH8QqHDx/WlClTtG7dOgUEBJgdx6s4HA5lZGTo8ccflyT17t1bu3fv1rPPPtvqC9hLL72kZcuWafny5UpOTlZ5ebmmTp2q2NjYVj82wA9BbfoOdenSqE3uUZtorjwqIiJCPj4+On78uMv648ePKzo62qRU3mXSpEl688039f7776t9+/Zmx/EKpaWlqqqqUlpamnNdfX293n//fS1YsEB1dXXy8fExMaF5YmJi1L17d5d13bp10yuvvGJSIu8xffp0zZgxQ6NHj5Yk9ezZUxUVFcrPz281BQzfj7rUNNQmV9SlS6M2uUdt4pkrj/L391d6erqKi4ud6xwOh4qLi5WVlWViMvMZhqFJkyZp5cqVevfdd9WxY0ezI3mNAQMGaNeuXSovL3cuGRkZysnJUXl5easuYP37928wLfL+/fvVoUMHkxJ5j3Pnzslqdf0I9/HxkcPhMCkRvBF16dKoTY2jLl0atck9ahNXrjxu2rRpys3NVUZGhvr27av58+ertrZW48ePNzuaqfLy8rR8+XK9/vrrCg4OVmVlpSQpNDRUdrvd5HTmCg4ObnB/f1BQkMLDw1v9ff+/+c1v1K9fPz3++OMaNWqUSkpKtHDhQi1cuNDsaKYbPny45syZo/j4eCUnJ2v79u2aN2+e7rrrLrOjwctQl9yjNjWOunRp1Cb3qE2SDHjcU089ZcTHxxv+/v5G3759ja1bt5odyXSSGl0WL15sdjSvdOONNxpTpkwxO4ZXeOONN4wePXoYNpvN6Nq1q7Fw4UKzI3mF6upqY8qUKUZ8fLwREBBgdOrUyXjggQeMuro6s6PBC1GXGkdtajrqkitqU+OoTYbB91wBAAAAgAfwzBUAAAAAeADNFQAAAAB4AM0VAAAAAHgAzRUAAAAAeADNFQAAAAB4AM0VAAAAAHgAzRUAAAAAeADNFQAAAAB4AM0V0IpZLBa99tprZscAAEASdQnXPporwCR33nmnLBZLg2XIkCFmRwMAtELUJeDK+ZodAGjNhgwZosWLF7uss9lsJqUBALR21CXgynDlCjCRzWZTdHS0yxIWFibp4q0RBQUFGjp0qOx2uzp16qSXX37ZZf9du3bp5ptvlt1uV3h4uO69917V1NS4bLNo0SIlJyfLZrMpJiZGkyZNcnn/5MmTuv322xUYGKguXbpo1apVzvdOnz6tnJwctW3bVna7XV26dGlQdAEALQd1CbgyNFeAF3vwwQeVnZ2tHTt2KCcnR6NHj9bevXslSbW1tRo8eLDCwsK0bds2rVixQv/85z9dilRBQYHy8vJ07733ateuXVq1apUSExNdfscjjzyiUaNGaefOnRo2bJhycnL0xRdfOH//nj17tHr1au3du1cFBQWKiIi4egMAAPAq1CXgexgATJGbm2v4+PgYQUFBLsucOXMMwzAMScaECRNc9snMzDQmTpxoGIZhLFy40AgLCzNqamqc77/11luG1Wo1KisrDcMwjNjYWOOBBx5wm0GS8Yc//MH5uqamxpBkrF692jAMwxg+fLgxfvx4z5wwAMCrUZeAK8czV4CJfvazn6mgoMBlXZs2bZw/Z2VlubyXlZWl8vJySdLevXuVmpqqoKAg5/v9+/eXw+HQvn37ZLFYdPToUQ0YMOCSGVJSUpw/BwUFKSQkRFVVVZKkiRMnKjs7W2VlZRo0aJBGjBihfv36/aBzBQB4P+oScGVorgATBQUFNbgdwlPsdnuTtvPz83N5bbFY5HA4JElDhw5VRUWF3n77ba1bt04DBgxQXl6e/vKXv3g8LwDAfNQl4MrwzBXgxbZu3drgdbdu3SRJ3bp1044dO1RbW+t8f9OmTbJarUpKSlJwcLASEhJUXFx8RRnatm2r3NxcLV26VPPnz9fChQuv6HgAgGsXdQm4NK5cASaqq6tTZWWlyzpfX1/nw7krVqxQRkaGbrjhBi1btkwlJSUqLCyUJOXk5Gj27NnKzc3Vww8/rBMnTmjy5MkaO3asoqKiJEkPP/ywJkyYoMjISA0dOlRnz57Vpk2bNHny5Cble+ihh5Senq7k5GTV1dXpzTffdBZRAEDLQ10CrgzNFWCiNWvWKCYmxmVdUlKSPv74Y0kXZ0wqKirSfffdp5iYGL3wwgvq3r27JCkwMFBr167VlClT1KdPHwUGBio7O1vz5s1zHis3N1dff/21/va3v+l3v/udIiIidMcddzQ5n7+/v2bOnKlPP/1UdrtdP/nJT1RUVOSBMwcAeCPqEnBlLIZhGGaHANCQxWLRypUrNWLECLOjAABAXQKagGeuAAAAAMADaK4AAAAAwAO4LRAAAAAAPIArVwAAAADgATRXAAAAAOABNFcAAAAA4AE0VwAAAADgATRXAAAAAOABNFcAAAAA4AE0VwAAAADgATRXAAAAAOAB/wdgIki4qvZb/wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# Đọc các kết quả huấn luyện mô hình qua từng epoch\n",
        "train_loss, train_acc = history.history['loss'], history.history['masked_accuracy'] # Đọc thông tin loss, acc trên tập train\n",
        "val_loss, val_acc = history.history['val_loss'], history.history['val_masked_accuracy'] # Đọc thông tin loss, acc trên tập val\n",
        "\n",
        "plt.figure(figsize=(10, 10)) # Cài đặt kích thước khung ảnh\n",
        "\n",
        "plt.subplot(2, 2, 1) # Khởi tạo khung ảnh cho training loss\n",
        "plt.xlabel('Epochs') # Hiển thị tên trục hoành là 'Epochs'\n",
        "plt.ylabel('Loss') # Hiển thị tên trục tung là 'Loss'\n",
        "plt.title('Training loss') # Hiển thị title của khung ảnh hiện tại là 'Training Loss'\n",
        "plt.plot(train_loss, color='green') # Vẽ đường giá trị loss trên tập train qua từng epoch (đường vẽ màu đỏ)\n",
        "\n",
        "plt.subplot(2, 2, 2) # Khởi tạo khung ảnh cho training acc\n",
        "plt.xlabel('Epochs') # Hiển thị tên trục hoành là 'Epochs'\n",
        "plt.ylabel('Accuracy') # Hiển thị tên trục tung là 'Accuracy'\n",
        "plt.title('Training accuracy') # Hiển thị title của khung ảnh hiện tại là 'Training accuracy'\n",
        "plt.plot(train_acc, color='orange') # Vẽ đường giá trị accuracy trên tập train qua từng epoch (đường vẽ màu cam)\n",
        "\n",
        "plt.subplot(2, 2, 3) # Khởi tạo khung ảnh cho val loss\n",
        "plt.xlabel('Epochs') # Hiển thị tên trục hoành là 'Epochs'\n",
        "plt.ylabel('Loss') # Hiển thị tên trục tung là 'Loss'\n",
        "plt.title('Validation loss') # Hiển thị title của khung ảnh hiện tại là 'Validation loss'\n",
        "plt.plot(val_loss, color='green') # Vẽ đường giá trị loss trên tập val qua từng epoch (đường vẽ màu đỏ)\n",
        "\n",
        "plt.subplot(2, 2, 4) # Khởi tạo khung ảnh cho val acc\n",
        "plt.xlabel('Epochs') # Hiển thị tên trục hoành là 'Epochs'\n",
        "plt.ylabel('Accuracy') # Hiển thị tên trục tung là 'Accuracy'\n",
        "plt.title('Validation accuracy') # Hiển thị title của khung ảnh hiện tại là 'Validation accuracy'\n",
        "plt.plot(val_acc, color='orange') # Vẽ đường giá trị accuracy trên tập val qua từng epoch (đường vẽ màu cam)\n",
        "\n",
        "plt.show() # Hiển thị 4 khung ảnh nhỏ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "un2-ZJ1CseWT"
      },
      "outputs": [],
      "source": [
        "def generate_text(\n",
        "    generator_model,\n",
        "    tokenizer,\n",
        "    input_string\n",
        "    ):\n",
        "\n",
        "    encoder_input_string = text_normalize(input_string)\n",
        "    encoder_input_sequence = tokenizer.texts_to_sequences([encoder_input_string])\n",
        "    encoder_input_padded_sequence = pad_sequences(encoder_input_sequence, maxlen=MAX_SEQ_LEN, truncating='pre', padding='post')[0]\n",
        "    encoder_input_padded_sequence = np.expand_dims(encoder_input_padded_sequence, axis=0)\n",
        "\n",
        "    decoder_input_string = '<start>'\n",
        "    decoder_input_sequence = tokenizer.texts_to_sequences([decoder_input_string])\n",
        "    decoder_input_padded_sequence = pad_sequences(decoder_input_sequence, maxlen=MAX_SEQ_LEN, truncating='pre', padding='post')[0]\n",
        "    start = decoder_input_padded_sequence[0][tf.newaxis]\n",
        "    end = decoder_input_padded_sequence[1][tf.newaxis]\n",
        "    decoder_input_padded_sequence = np.expand_dims(decoder_input_padded_sequence, axis=0)\n",
        "\n",
        "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "    output_array = output_array.write(0, start)\n",
        "\n",
        "    for i in tf.range(MAX_SEQ_LEN):\n",
        "        output = tf.transpose(output_array.stack())\n",
        "        predictions = generator_model((encoder_input_padded_sequence, output), training=False)\n",
        "\n",
        "        # Select the last token from the `seq_len` dimension.\n",
        "        predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
        "\n",
        "        predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "        # Concatenate the `predicted_id` to the output which is given to the\n",
        "        # decoder as its input.\n",
        "        output_array = output_array.write(i+1, predicted_id[0])\n",
        "\n",
        "        if predicted_id == end:\n",
        "            break\n",
        "\n",
        "    output = tf.transpose(output_array.stack())\n",
        "    output_tokens = output.numpy()\n",
        "    # The output shape is `(1, tokens)`.\n",
        "    text = tokenizer.sequences_to_texts(output_tokens)[0]  # Shape: `()`.\n",
        "\n",
        "\n",
        "    # `tf.function` prevents us from using the attention_weights that were\n",
        "    # calculated on the last iteration of the loop.\n",
        "    # So, recalculate them outside the loop.\n",
        "    generator_model([decoder_input_padded_sequence, output[:, :-1]], training=False)\n",
        "    attention_weights = generator_model.decoder.attention_scores\n",
        "\n",
        "    return text, output_tokens, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9yHWtP_seWU",
        "outputId": "ef88ac7c-1b52-4630-bd7a-47b00a20fb82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chú không biết bơi nhỉ\n",
            " là việc tốt tất nhiên  \n",
            " nhưng còn tốt hơn thế  \n",
            " là cố gắng để quên  \n",
            " có em thoáng vô lượng  \n",
            " không nguyện chúng sinh một  \n",
            " lìa vọng huyễn qui chân  \n",
            " thắp lửa vô lượng quang  \n",
            " sáng soi bảy cửa ngục  \n"
          ]
        }
      ],
      "source": [
        "n_sentences = 7\n",
        "results = ['chú không biết bơi nhỉ']\n",
        "for idx in range(n_sentences + 1):\n",
        "    input_str = results[idx]\n",
        "    text, output_tokens, attention_weights = generate_text(\n",
        "        transformer,\n",
        "        tokenizer,\n",
        "        input_str\n",
        "    )\n",
        "    results.append(text.replace('<start>', '').replace('<end>', ''))\n",
        "\n",
        "print('\\n'.join(results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqQ3EszNseWU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01k0TWadseWU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOJCjmqTseWU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zk-7tIIOseWU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlSSM0DGseWU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6HBDHa93seWF",
        "q0IdvgEDseWF",
        "w2BRnKVYseWF",
        "XlKV63cYseWG"
      ],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}